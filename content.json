{"meta":{"title":"彩虹马的博客","subtitle":"不忘初心 方得始终","description":"总结个人心得，记录个人知识","author":"彩虹马","url":"https://mx-go.github.io","root":"/"},"pages":[{"title":"","date":"2018-10-23T15:32:00.178Z","updated":"2018-10-23T15:32:00.178Z","comments":true,"path":"404.html","permalink":"https://mx-go.github.io/404.html","excerpt":"","text":"404 - rainbowhorse's blog"},{"title":"分类","date":"2017-03-22T01:01:55.000Z","updated":"2018-10-23T15:32:00.194Z","comments":true,"path":"categories/index.html","permalink":"https://mx-go.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-03-22T01:01:22.000Z","updated":"2018-10-23T15:32:00.197Z","comments":true,"path":"tags/index.html","permalink":"https://mx-go.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2018-12-30T06:01:41.007Z","updated":"2018-12-30T05:03:08.000Z","comments":true,"path":"images/2018-3/websocket/stomp.min.js","permalink":"https://mx-go.github.io/images/2018-3/websocket/stomp.min.js","excerpt":"","text":"// Generated by CoffeeScript 1.7.1 /* Stomp Over WebSocket http://www.jmesnil.net/stomp-websocket/doc/ | Apache License V2.0 Copyright (C) 2010-2013 [Jeff Mesnil](http://jmesnil.net/) Copyright (C) 2012 [FuseSource, Inc.](http://fusesource.com) */ (function() { var t, e, n, i, r = {}.hasOwnProperty, o = [].slice; t = { LF : \"\\n\", NULL : \"\\x00\" }; n = function() { var e; function n(t, e, n) { this.command = t; this.headers = e != null ? e : {}; this.body = n != null ? n : \"\" } n.prototype.toString = function() { var e, i, o, s, u; e = [ this.command ]; o = this.headers[\"content-length\"] === false ? true : false; if (o) { delete this.headers[\"content-length\"] } u = this.headers; for (i in u) { if (!r.call(u, i)) continue; s = u[i];e.push(\"\" + i + \":\" + s) } if (this.body && !o) { e.push(\"content-length:\" + n.sizeOfUTF8(this.body)) } e.push(t.LF + this.body);return e.join(t.LF) }; n.sizeOfUTF8 = function(t) { if (t) { return encodeURI(t).match(/%..|./g).length } else { return 0 } }; e = function(e) { var i, r, o, s, u, a, c, f, h, l, p, d, g, b, m, v, y; s = e.search(RegExp(\"\" + t.LF + t.LF)); u = e.substring(0, s).split(t.LF); o = u.shift(); a = {}; d = function(t) { return t.replace(/^\\s+|\\s+$/g, \"\") }; v = u.reverse(); for (g = 0, m = v.length; g < m; g++) { l = v[g]; f = l.indexOf(\":\"); a[d(l.substring(0, f))] = d(l.substring(f + 1)) } i = \"\"; p = s + 2; if (a[\"content-length\"]) { h = parseInt(a[\"content-length\"]); i = (\"\" + e).substring(p, p + h) } else { r = null; for (c = b = p, y = e.length; p"},{"title":"","date":"2018-12-30T06:01:41.003Z","updated":"2018-12-30T05:03:06.000Z","comments":true,"path":"images/2018-3/websocket/sockjs.min.js","permalink":"https://mx-go.github.io/images/2018-3/websocket/sockjs.min.js","excerpt":"","text":"/* SockJS client, version 0.3.4, http://sockjs.org, MIT License Copyright (c) 2011-2012 VMware, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. */ // JSON2 by Douglas Crockford (minified). var JSON;JSON||(JSON={}),function(){function str(a,b){var c,d,e,f,g=gap,h,i=b[a];i&&typeof i==\"object\"&&typeof i.toJSON==\"function\"&&(i=i.toJSON(a)),typeof rep==\"function\"&&(i=rep.call(b,a,i));switch(typeof i){case\"string\":return quote(i);case\"number\":return isFinite(i)?String(i):\"null\";case\"boolean\":case\"null\":return String(i);case\"object\":if(!i)return\"null\";gap+=indent,h=[];if(Object.prototype.toString.apply(i)===\"[object Array]\"){f=i.length;for(c=0;c"}],"posts":[{"title":"微服务架构设计","slug":"微服务架构设计","date":"2022-03-14T06:53:08.000Z","updated":"2022-03-14T08:31:18.116Z","comments":true,"path":"微服务架构设计/","link":"","permalink":"https://mx-go.github.io/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"微服务架构详解微服务VS SOA 微服务架构陷阱与挑战六大陷阱拆分颗粒度太细 服务关系复杂 团队效率下降 问题定位困难 系统性能下降 基础设施不完善 无法快速交付 服务管理混乱 四大挑战 分布式事务 全局幂等 接口兼容 接口循环调用 微服务基础设施选型 核心为服务运行层：服务注册、服务发现、服务路由 嵌入SDK式 反向代理式 网络代理式 微服务拆分技巧按业务拆分 业务边界划分 三个火枪手原则 【定义】 平均3个开发人员负责一个微服务。 【剖析】 为什么不是1个？ 因为没有备份，且一个人思维有局限。 为什么不是2个？ 因为异常情况下剩余1个，压力会很大； 2个人负责维护一个微服务，微服务复杂度偏低。 为什么不是4个或者5个？ 如果4个或4个以上，每个人不一定能掌握单个服务所有细节。 【技巧】 微服务数量 = 服务端开发人数 /3 ； 3 = 1 +2，1个有经验的(P7/P6+)，2个普通的(P5/P6)； 处于维护期的服务，维护人员为2人。 按质量拆分 按性能拆分 按业务重要程度拆分 按可用性拆分 按稳定性拆分 中台深入剖析和实现技巧共享类别 无共享，烟囱模型 Iaas，共享基础设施 PaaS，共享平台能力 SaaS，共享软件能力 中台，共享业务能力","categories":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/"},{"name":"设计","slug":"架构/设计","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"高可用计算架构","slug":"高可用计算架构","date":"2022-02-25T05:49:43.000Z","updated":"2022-03-13T08:37:06.373Z","comments":true,"path":"高可用计算架构/","link":"","permalink":"https://mx-go.github.io/%E9%AB%98%E5%8F%AF%E7%94%A8%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84/","excerpt":"","text":"多级缓存架构缓存设计 缓存内容 缓存时间 缓存系统 更新机制 多级缓存 客户端缓存 CDN缓存 WEB容器缓存 应用缓存 分布式缓存 分布式缓存架构设计分类 数据缓存：实时性要求高，读多写少 结果缓存：计算量大实时性要求不高 缓存问题 缓存穿透 缓存雪崩 缓存热点 负载均衡架构 DNS F5：100万~1000万 LVS：10万~100万 Nginx：5万~10万 服务路由(Gateway)：1000~5000 负载均衡技巧通用算法 轮训 随机 加权轮训 负载有限 性能优先 hash 服务器性能估算接口性能 线上业务服务器接口处理时间分布为 20~100ms； 平均大约为 50ms； 访问存储或者其它系统接口是主要的性能消耗点。 服务器性能线上单个服务器（32核）性能大约为 300~1000 TPS/QPS 服务器数量服务器数量 = (总 TPS+QPS) / 单个服务器性能 接口高可用 限流 排队 降级 熔断","categories":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/"},{"name":"设计","slug":"架构/设计","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"数据库存储架构","slug":"数据库存储架构","date":"2022-02-08T08:36:19.000Z","updated":"2022-03-13T08:58:31.056Z","comments":true,"path":"数据库存储架构/","link":"","permalink":"https://mx-go.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84/","excerpt":"","text":"数据库读写分离复杂度复制延迟 业务分级(常用) 读写绑定 二次读取 任务分解 代码封装 中间件封装 分库分表垂直拆分-提升单机处理性能按照业务将表进行分类，分布到不同的数据库上面。 水平拆分-提升集群处理性能按行切分。 复制架构 设计存储架构 分片架构与分区架构分片架构通过叠加服务器来提升写性能和存储性能。 分区架构通过冗余IDC来避免城市级别的灾难，并提供就近访问。 常见存储系统剖析存储系统学习方法 理解技术本质 明确部署架构 研究数据模型 模拟业务场景","categories":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/"},{"name":"设计","slug":"架构/设计","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"设计合理的架构","slug":"设计合理的架构","date":"2022-01-26T06:18:03.000Z","updated":"2022-03-12T08:42:48.897Z","comments":true,"path":"设计合理的架构/","link":"","permalink":"https://mx-go.github.io/%E8%AE%BE%E8%AE%A1%E5%90%88%E7%90%86%E7%9A%84%E6%9E%B6%E6%9E%84/","excerpt":"","text":"架构师职责架构师是业务与技术之间的桥梁。 核心能力 判断-确定性思维 拆解-创造性思维 取舍-系统性思维 主要职责架构设计前期 澄清不确定性 识别复杂需求 与业务方交流 与利益干系人交流 业务架构图 核心场景流程 架构设计中期 选择、设计备选方案 架构小组讨论 方案评估 方案汇报 架构设计后期 细化架构 完善架构 写文档 架构宣讲 最终的架构文档 架构设计前期 架构设计中期 架构设计后期架构设计文档 业务背景 约束&amp;限制 总体架构设计 详细架构设计 架构质量设计 架构演进规则 详细架构设计 架构规范 架构质量","categories":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/"},{"name":"设计","slug":"架构/设计","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"架构设计关键点","slug":"架构设计关键点","date":"2022-01-10T10:08:20.000Z","updated":"2022-03-11T06:20:33.618Z","comments":true,"path":"架构设计关键点/","link":"","permalink":"https://mx-go.github.io/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%85%B3%E9%94%AE%E7%82%B9/","excerpt":"","text":"可扩展架构设计鸡蛋篮子第一法则拆分法则 拆分颗粒度内部复杂度可以用参与的开发人数来衡量单个拆分对象的复杂度。三个火枪手原则。 外部复杂度可以用业务流程涉及对象数量来衡量外部复杂度。 高性能架构设计鸡蛋篮子第二法则叠加法则 高可用架构设计鸡蛋篮子第三法则冗余法则 分类 计算高可用 存储高可用 架构质量可测试性软件系统在测试环境下能否方便的支持测试各种场景的能力。 可维护性软件系统支持定位问题、修复问题的能力。 可观测性软件系统对外展现内部状态的能力 可观测性是可测试性、可维护性的基础。","categories":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/"},{"name":"设计","slug":"架构/设计","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"架构设计及概念","slug":"架构设计及概念","date":"2021-12-21T10:54:40.000Z","updated":"2022-03-13T08:54:11.351Z","comments":true,"path":"架构设计及概念/","link":"","permalink":"https://mx-go.github.io/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%8F%8A%E6%A6%82%E5%BF%B5/","excerpt":"","text":"架构定义系统拆分 按逻辑拆分：模块 按物理拆分：组件 4R架构定义 Rank：顶层架构 Role：角色组成 Relation：角色关系 Rule：运作规则 架构分类按业务划分 业务架构图 按领域划分 客户端架构图 前端架构图 后端架构图 面向复杂度的架构分析本质架构设计是为了降低软件系统的复杂度。 架构设计三原则合适原则合适优于业界领先。 简单原则简单优于复杂。 演进原则演化优于一步到位。","categories":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"关于服务监控的思考","slug":"关于服务监控的思考","date":"2021-12-11T06:35:38.000Z","updated":"2022-01-13T08:19:06.757Z","comments":true,"path":"关于服务监控的思考/","link":"","permalink":"https://mx-go.github.io/%E5%85%B3%E4%BA%8E%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7%E7%9A%84%E6%80%9D%E8%80%83/","excerpt":"目前开源的组件如Skywalking、Zipkin只能做到横向监控，没法针对某一时间段方法纵向监控和告警。基于这种痛点和对一些组件的了解，自己写了一套可满足自己业务需求的服务监控组件，结合了Grafana、Loki、Promtail、Elasticsearch、Kafka等，可实现服务接口级监控、监控告警、告警日志在线查看等特性。","text":"目前开源的组件如Skywalking、Zipkin只能做到横向监控，没法针对某一时间段方法纵向监控和告警。基于这种痛点和对一些组件的了解，自己写了一套可满足自己业务需求的服务监控组件，结合了Grafana、Loki、Promtail、Elasticsearch、Kafka等，可实现服务接口级监控、监控告警、告警日志在线查看等特性。 基础组件 Grafana：Grafana 搭建 Loki：轻量级日志采集Loki搭建 Elasticsearch：介绍及使用文档 消息中间件：kafka 服务监控组件(未开源)：service-profiler 设计思想 Client收集服务调用信息后生成数据快照(Snapshot)，通过Kafka定时上报到Server端。Client通过Promtail采集错误日志上报到Loki服务器。 Server端统计聚合Client端上报的信息后落库ES。Loki服务端接收到Client端上报的日志后存储至磁盘并生成索引。 通过Grafana整合统计信息和错误日志，通过丰富的仪表盘实时展示相关指标与分析结果。 当相关指标超过自定义阈值时，通过通知平台告警到相关研发人员，及时处理告警。 日志采集日志采集使用的是较为轻量级的Loki。Loki的搭建和使用可参考轻量级日志采集Loki搭建。 需要在Grafana中配置Loki的信息，然后在Explore中展示日志。 效果下面展示图是实际应用到项目中的大屏和监控效果图。 在调用链路视图中，可以查看到整个调用分析中，每一个应用的调用类型、服务名、方法名称、实例名称、耗时区间，以及平均耗时等。能一步定位到哪一个方法存在性能瓶颈。 借助于Grafana的特性，可让数据大屏展示更丰富： 解决服务黑盒问题，让服务调用可视化，纵向分析服务调用； 可及时发现服务调用失败、超时信息并告警，并可进行性能指标分析，让研发人员及时发现并解决问题； 全方位、立体化、可视化监控。可选择具体系统编码、应用、方法进行查看，可根据各列进行排序。无需手动刷新，系统动态进行刷新（刷新时间可自定义）； 可动态调整超时时间设置(应用无需重启)，可自定义设置单个方法的超时时间； 结合Grafana特性可自定义告警阈值。可根据业务调整告警阈值。 性能服务监控组件通过切面捕获服务调用信息，捕获数据后异步存储后通过消息中间件上报到服务端，客户端无阻塞，正常情况下性损极小(微秒级)。","categories":[{"name":"监控","slug":"监控","permalink":"https://mx-go.github.io/categories/%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"异步编程之ExecutorCompletionService","slug":"异步编程之ExecutorCompletionService","date":"2021-11-27T08:54:40.000Z","updated":"2022-01-09T14:03:29.764Z","comments":true,"path":"异步编程之ExecutorCompletionService/","link":"","permalink":"https://mx-go.github.io/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E4%B9%8BExecutorCompletionService/","excerpt":"ExecutorCompletionService是JDK1. 6中新增的异步类，可获取异步执行的结果。有着相同功能的ExcutorService中Future.get方法是阻塞的直到返回结果，也就是顺序执行get方法，即使后续任务先执行完成也会阻塞在前面的任务的get方法。而ExecutorCompletionService执行结果无序且线程池中先执行完成的任务会先执行后续的逻辑，不会发生阻塞。","text":"ExecutorCompletionService是JDK1. 6中新增的异步类，可获取异步执行的结果。有着相同功能的ExcutorService中Future.get方法是阻塞的直到返回结果，也就是顺序执行get方法，即使后续任务先执行完成也会阻塞在前面的任务的get方法。而ExecutorCompletionService执行结果无序且线程池中先执行完成的任务会先执行后续的逻辑，不会发生阻塞。 异步任务获取结果方式多线程异步任务获取结果最常见的方式莫过于重写Callable接口，然后通过future.get()获取结果。但这种方法弊端很明显，get方法会产生阻塞，导致任务耗时增加。当前有三种方法可以实现异步任务获取结果： 重写Callable，通过future.get获取结果。 CompletableFuture异步通过join方法获取结果。 通过ExecutorCompletionService获取结果。 Callable12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * 初始化固定大小为3的线程池 */private final static ExecutorService EXECUTOR = Executors.newFixedThreadPool(3);public static void main(String[] args) &#123; method1(); //method2();&#125;@SneakyThrowsprivate static void method1() &#123; List&lt;Task&gt; tasks = getTasks(); long start = System.currentTimeMillis(); for (Future&lt;Integer&gt; future : EXECUTOR.invokeAll(tasks)) &#123; Integer result = future.get(); // 模拟其他业务逻辑 Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS); System.out.println(&quot;任务返回结果：&quot; + result); &#125; System.out.println(&quot;共耗时：&quot; + (System.currentTimeMillis() - start)); // 关闭线程池 EXECUTOR.shutdown();&#125;@SneakyThrowsprivate static void method2() &#123; List&lt;Task&gt; tasks = getTasks(); long start = System.currentTimeMillis(); List&lt;Future&lt;Integer&gt;&gt; futures = new ArrayList&lt;&gt;(); for (Task task : tasks) &#123; futures.add(EXECUTOR.submit(task)); &#125; // 遍历Future list，通过get()方法获取每个future结果 for (Future&lt;Integer&gt; future : futures) &#123; Integer result = future.get(); // 模拟其他业务逻辑 Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS); System.out.println(&quot;任务返回结果：&quot; + result); &#125; System.out.println(&quot;共耗时：&quot; + (System.currentTimeMillis() - start)); // 关闭线程池 EXECUTOR.shutdown();&#125;public static List&lt;Task&gt; getTasks() &#123; List&lt;Task&gt; tasks = new ArrayList&lt;&gt;(); tasks.add(new Task(5)); tasks.add(new Task(3)); tasks.add(new Task(1)); return tasks;&#125;static class Task implements Callable&lt;Integer&gt; &#123; /** * 秒级时间 */ public int time; public Task(int time) &#123; this.time = time; &#125; @Override public Integer call() &#123; Uninterruptibles.sleepUninterruptibly(time, TimeUnit.SECONDS); return time; &#125;&#125; method1和method2执行结果相同，输出结果如下： 1234任务返回结果：5任务返回结果：3任务返回结果：1共耗时：8039 为什么说future.get()阻塞获取结果，可以通过下图看出，只有等任务1get到任务结果并执行完成后续所有业务逻辑后才会轮到下一个任务执行后续逻辑，且get方法按照提交顺序获取结果。总结为：先添加先处理。 CompletableFuture12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 初始化固定大小为3的线程池 */private final static ExecutorService EXECUTOR = Executors.newFixedThreadPool(3);public static void main(String[] args) &#123; completableFuture();&#125;private static void completableFuture() &#123; List&lt;Task&gt; tasks = getTasks(); long start = System.currentTimeMillis(); tasks.parallelStream().map(task -&gt; CompletableFuture.supplyAsync(task::call, EXECUTOR)) .collect(Collectors.toList()) .parallelStream() .map(CompletableFuture::join) .forEach(result -&gt; &#123; // 模拟其他业务逻辑 Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS); System.out.println(&quot;任务返回结果：&quot; + result); &#125;); System.out.println(&quot;共耗时：&quot; + (System.currentTimeMillis() - start)); // 关闭线程池 EXECUTOR.shutdown();&#125;public static List&lt;Task&gt; getTasks() &#123; List&lt;Task&gt; tasks = new ArrayList&lt;&gt;(); tasks.add(new Task(5)); tasks.add(new Task(3)); tasks.add(new Task(1)); return tasks;&#125;static class Task implements Callable&lt;Integer&gt; &#123; /** * 秒级时间 */ public int time; public Task(int time) &#123; this.time = time; &#125; @Override public Integer call() &#123; Uninterruptibles.sleepUninterruptibly(time, TimeUnit.SECONDS); return time; &#125;&#125; 输出结果如下： 1234任务返回结果：1任务返回结果：3任务返回结果：5共耗时：6078 CompletableFuture把Task.call作为普通方法调用执行，将外层包装为CompletableFuture.supplyAsync获取结果。 ExecutorCompletionService123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 初始化固定大小为3的线程池 */private final static ExecutorService EXECUTOR = Executors.newFixedThreadPool(3);public static void main(String[] args) &#123; executorCompletionService();&#125;@SneakyThrowsprivate static void executorCompletionService() &#123; List&lt;Task&gt; tasks = getTasks(); long start = System.currentTimeMillis(); // 以executor为构造器的参数，新建一个ExecutorCompletionService线程池 ExecutorCompletionService&lt;Integer&gt; completionService = new ExecutorCompletionService&lt;&gt;(EXECUTOR); // 提交任务 for (Task task : tasks) &#123; completionService.submit(task); &#125; for (Task task : tasks) &#123; Integer time = completionService.take().get(); // 模拟其他业务逻辑 Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS); System.out.println(&quot;任务返回结果：&quot; + time); &#125; System.out.println(&quot;共耗时：&quot; + (System.currentTimeMillis() - start)); // 关闭线程池 EXECUTOR.shutdown();&#125;public static List&lt;Task&gt; getTasks() &#123; List&lt;Task&gt; tasks = new ArrayList&lt;&gt;(); tasks.add(new Task(5)); tasks.add(new Task(3)); tasks.add(new Task(1)); return tasks;&#125;static class Task implements Callable&lt;Integer&gt; &#123; /** * 秒级时间 */ public int time; public Task(int time) &#123; this.time = time; &#125; @Override public Integer call() &#123; Uninterruptibles.sleepUninterruptibly(time, TimeUnit.SECONDS); return time; &#125;&#125; 输出结果如下 1234任务返回结果：1任务返回结果：3任务返回结果：5共耗时：6030 可以看到ExecutorCompletionService比Callable在性能有一定提升。ExecutorCompletionService先执行完成线程会继续执行后续业务逻辑，并不会产生阻塞。总结为：谁快谁优先。 小结获取异步线程执行结果性能排行 ExecutorCompletionService CompletableFuture Callable 解析ExecutorCompletionService方法解析ExecutorCompletionService实现了CompletionService接口，且CompletionService只有ExecutorCompletionService一个实现类，CompletionService中只有5个方法。 123456789101112131415161718192021222324public interface CompletionService&lt;V&gt; &#123; /** * 提交一个Callable类型任务，并返回该任务执行结果关联的Future。 */ Future&lt;V&gt; submit(Callable&lt;V&gt; task); /** * 提交一个Runnable类型任务，并返回指定结果。 */ Future&lt;V&gt; submit(Runnable task, V result); /** * 从内部阻塞队列中获取并移除第一个执行完成的任务，阻塞直到有任务完成。 * 如果队列为空，那么调用take()方法的线程会被阻塞 */ Future&lt;V&gt; take() throws InterruptedException; /** * 从内部阻塞队列中获取并移除第一个执行完成的任务，获取不到则返回null，不阻塞。 * 如果队列为空，那么调用poll()方法的线程会返回 null */ Future&lt;V&gt; poll(); /** * 从内部阻塞队列中获取并移除第一个执行完成的任务，阻塞时间为timeout，获取不到则返回null。 */ Future&lt;V&gt; poll(long timeout, TimeUnit unit) throws InterruptedException;&#125; 源码解析三个私有属性 两个构造方法可通过ExecutorCompletionService的构造方法指定已完成队列的类型，默认为LinkedBlockingQueue。 任务提交QueueingFuture继承了FutureTask ，FutureTask重写了Runnable的run()方法，无论是set()正常结果，还是setException()结果，都会调用 finishCompletion()方法。 任务执行流程 这里执行的done方法，实际执行的是QueueingFuture的done方法。至此，当一个任务执行完成或异常的时候，都会被添加到已完成阻塞队列中，进而被取出处理。 获取结果FutureTask的任务完成后执行QueueingFuture.done将已完成的结果存储到队列中，可通过take、poll方法直接从已完成队列中获取结果。 使用场景 多线程执行有返回值的任务。 同类服务调用，优先获取先返回任务的结果(如调用不同厂商的定位服务，使用耗时最短、最先返回的结果)。 获取任务集合的第一个结果后取消其他任务(如多中心文件下载，下载完成后终止其他下载线程)。 ExecutorCompletionService doc中也给出了两个例子： 假设您有一组针对某个问题的求解器，每个求解器都返回某种Result类型的值，并希望同时运行它们，处理它们中每个返回非空值的结果，在某些方法中use(Result r) 。 1234567891011121314void solve(Executor e, Collection&lt;Callable&lt;Result&gt;&gt; solvers) throws InterruptedException, ExecutionException &#123; CompletionService&lt;Result&gt; ecs = new ExecutorCompletionService&lt;Result&gt;(e); for (Callable&lt;Result&gt; s : solvers) ecs.submit(s); int n = solvers.size(); for (int i = 0; i &lt; n; ++i) &#123; Result r = ecs.take().get(); if (r != null) use(r); &#125;&#125; 假设您想使用任务集的第一个非空结果，忽略任何遇到异常的结果，并在第一个任务准备好时取消所有其他任务。 123456789101112131415161718192021222324252627282930void solve(Executor e, Collection&lt;Callable&lt;Result&gt;&gt; solvers) throws InterruptedException &#123; CompletionService&lt;Result&gt; ecs = new ExecutorCompletionService&lt;Result&gt;(e); int n = solvers.size(); List&lt;Future&lt;Result&gt;&gt; futures = new ArrayList&lt;Future&lt;Result&gt;&gt;(n); Result result = null; try &#123; for (Callable&lt;Result&gt; s : solvers) futures.add(ecs.submit(s)); for (int i = 0; i &lt; n; ++i) &#123; try &#123; Result r = ecs.take().get(); if (r != null) &#123; result = r; break; &#125; &#125; catch (ExecutionException ignore) &#123;&#125; &#125; &#125; finally &#123; for (Future&lt;Result&gt; f : futures) f.cancel(true); &#125; if (result != null) use(result); &#125;","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"异步编程之CompletableFuture","slug":"异步编程之CompletableFuture","date":"2021-10-12T15:01:04.000Z","updated":"2022-01-10T00:47:12.323Z","comments":true,"path":"异步编程之CompletableFuture/","link":"","permalink":"https://mx-go.github.io/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E4%B9%8BCompletableFuture/","excerpt":"在Java8中新增了CompletableFuture类，该类实现了Future和CompletionStage接口。提供了强大的Future扩展功能，简化了异步编程的复杂性，提供了函数式编程的能力。可通过异步回调方式处理结果，还可以对任务进行组合处理。","text":"在Java8中新增了CompletableFuture类，该类实现了Future和CompletionStage接口。提供了强大的Future扩展功能，简化了异步编程的复杂性，提供了函数式编程的能力。可通过异步回调方式处理结果，还可以对任务进行组合处理。 概览 创建异步任务CompletableFuture提供了四个静态方法来创建一个异步操作。 123456// 无返回值public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable)public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable, Executor executor)// 有返回值public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier)public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier, Executor executor) 没有指定Executor的话默认会使用ForkJoinPool.commonPool() 作为缺省线程池执行异步代码，其中ForkJoinPool.commonPool()核心线程数量为CPU-1核心数。如果指定线程池，则使用指定的线程池执行任务。 runAsync以Runnable函数式接口类型为参数，无返回值。 123456789private static void runAsync() throws Exception &#123; // runAsync直接执行，无返回值 CompletableFuture&lt;Void&gt; future = CompletableFuture.runAsync(() -&gt; &#123; System.out.println(&quot;runAsync线程名称: &quot; + Thread.currentThread().getName()); &#125;); future.get();&#125;// runAsync线程名称: ForkJoinPool.commonPool-worker-1 supplyAsync以Supplier&lt;U&gt;函数式接口类型为参数,CompletableFuture的计算结果类型为U。 1234567891011private static void supplyAsync() throws Exception &#123; // supplyAsync支持返回值 CompletableFuture&lt;Long&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName()); return System.currentTimeMillis(); &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1// 阻塞获取结果。结果为：1640446068495 以异步场景为例，可与List结合使用。 12345678910// 先将 List&lt;Integer&gt; 转换成 -&gt; List&lt;CompletableFuture&lt;String&gt;&gt;的list 然后对这个list进行join操作List&lt;Integer&gt; collect = Lists.newArrayList(2, 1, 3) .stream() .map(i -&gt; CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS); return i; &#125;)) .collect(Collectors.toList()) .stream() .map(CompletableFuture::join).collect(Collectors.toList()); 异步回调thenRun/thenRunAsync1public CompletableFuture&lt;Void&gt; thenRun(Runnable action); 执行完第一个任务再执行第二个任务，前后两个任务没有参数传递，第二个任务(thenRun)也没有返回值。 123456789101112131415private static void thenRun() throws Exception &#123; // supplyAsync执行完成后执行thenRun(无参数，无返回) CompletableFuture&lt;Void&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; int result = new Random().nextInt(100); System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); return result; &#125;).thenRun(() -&gt; &#123; System.out.println(&quot;thenRun线程名称: &quot; + Thread.currentThread().getName() + &quot;。无参数，无返回值&quot;); &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1。结果为：64// thenRun线程名称: main。无参数，无返回值// 阻塞获取结果。结果为：null thenRun和thenRunAsync区别123456789private static final Executor asyncPool = useCommonPool? ForkJoinPool.commonPool() : new ThreadPerTaskExecutor();public CompletableFuture&lt;Void&gt; thenRun(Runnable action) &#123; return uniRunStage(null, action);&#125;public CompletableFuture&lt;Void&gt; thenRunAsync(Runnable action) &#123; return uniRunStage(asyncPool, action);&#125; 如果在执行第一个任务的时候传入了一个自定义线程池： 调用thenRun方法执行第二个任务时，第二个任务和第一个任务共用一个线程池； 调用thenRunAsync方法执行第二个任务时，第一个任务使用自己传入的线程池，第二个任务使用ForkJoinPool； 后面所说的thenAccept和thenAcceptAsync、thenApply和thenApplyAsync等，它们之间的区别也是如此。 thenAccept/thenAcceptAsync1public CompletableFuture&lt;Void&gt; thenAccept(Consumer&lt;? super T&gt; action) 执行完第一个任务后，将执行结果作为入参传递到回调方法(thenAccept)中，回调方法无返回值。 12345678910111213141516private static void thenAccept() throws Exception &#123; // supplyAsync执行完成后执行thenAccept(参数为上个任务的结果，无返回值) CompletableFuture&lt;Void&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; int result = new Random().nextInt(100); System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); return result; &#125;).thenAccept(arg -&gt; &#123; int result = arg * 10; System.out.println(&quot;thenAccept线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1。结果为：66// thenAccept线程名称: main。结果为：660// 阻塞获取结果。结果为：null thenApply/thenApplyAsync1public &lt;U&gt; CompletableFuture&lt;U&gt; thenApply(Function&lt;? super T,? extends U&gt; fn) 执行完第一个任务后，将执行结果作为入参传递到回调方法(thenApply)中，回调方法有返回值。 1234567891011121314151617private static void thenApply() throws Exception &#123; // 执行完supplyAsync拿到返回结果后执行thenApply(参数为上个任务的结果，有返回值) CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; int result = new Random().nextInt(100); System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); return result; &#125;).thenApply(arg -&gt; &#123; int result = arg * 10; System.out.println(&quot;thenApply线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); return result; &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1。结果为：44// thenApply线程名称: main。结果为：440// 阻塞获取结果。结果为：440 exceptionally1public CompletableFuture&lt;T&gt; exceptionally(Function&lt;Throwable, ? extends T&gt; fn) 某个任务执行异常时，执行的回调方法，并且将抛出异常作为参数，传递到回调方法，exceptionally方法有返回值。 12345678910111213141516171819private static void exceptionally() throws Exception &#123; // supplyAsync中发生异常进入exceptionally块，最终结果为exceptionally中返回值 CompletableFuture&lt;Object&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName()); throw new RuntimeException(); &#125;).exceptionally(e -&gt; &#123; e.printStackTrace(); return &quot;系统异常&quot;; &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1// java.util.concurrent.CompletionException: java.lang.RuntimeException// Caused by: java.lang.RuntimeException// at com.user.provider.utils.Test.lambda$exceptionally$19(Test.java:160)// at java.util.concurrent.CompletableFuture$AsyncSupply.run$$$capture(CompletableFuture.java:1590)// ... 7 more// 阻塞获取结果。结果为：系统异常 whenComplete1public CompletableFuture&lt;T&gt; whenComplete(BiConsumer&lt;? super T, ? super Throwable&gt; action) 某个任务执行完成后，将上个任务的结果和异常传递到回调方法whenComplete中，无返回值。 123456789101112131415private static void whenComplete() throws Exception &#123; // supplyAsync执行完成后执行whenComplete(参数为上个任务的结果，无返回值) CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; int result = new Random().nextInt(100); System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); return result; &#125;).whenComplete((arg, e) -&gt; &#123; System.out.println(&quot;whenComplete线程名称: &quot; + Thread.currentThread().getName() + &quot;。参数为：&quot; + arg); &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1。结果为：66// whenComplete线程名称: main。参数为：66// 阻塞获取结果。结果为：66 handle1public &lt;U&gt; CompletableFuture&lt;U&gt; handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn) 某个任务执行完成后，将上个任务的结果和异常传递到回调方法handle中，有返回值。 1234567891011121314151617private static void handle() throws Exception &#123; // supplyAsync执行完成后执行handle(参数为上个任务的结果，有返回值) CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; int result = new Random().nextInt(100); System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); return result; &#125;).handle((arg, e) -&gt; &#123; int result = arg * 10; System.out.println(&quot;handle线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：&quot; + result); return result; &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1。结果为：45// handle线程名称: ForkJoinPool.commonPool-worker-1。结果为：450// 阻塞获取结果。结果为：450 任务组合AND组合关系123public &lt;U,V&gt; CompletableFuture&lt;V&gt; thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)public &lt;U&gt; CompletionStage&lt;Void&gt; thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action)public CompletionStage&lt;Void&gt; runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action) thenCombine/thenAcceptBoth/runAfterBoth都表示：将两个CompletableFuture组合起来，只有这两个都正常执行完成才会执行某个任务。区别为： thenCombine：将两个任务的执行结果作为方法入参，传递到指定方法中，有返回值 thenAcceptBoth: 会将两个任务的执行结果作为方法入参，传递到指定方法中，无返回值 runAfterBoth：不会把执行结果当做方法入参，没有返回值 123456789101112131415161718192021private static void thenCombine() throws Exception &#123; // supplyAsync1和supplyAsync2都执行完成后执行thenCombine(接收两个参数，有返回值) CompletableFuture&lt;Integer&gt; f1 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;supplyAsync1线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：100&quot;); return 100; &#125;); CompletableFuture&lt;Integer&gt; f2 = CompletableFuture.supplyAsync(() -&gt; &#123; System.out.println(&quot;supplyAsync2线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：200&quot;); return 200; &#125;); CompletableFuture&lt;Integer&gt; future = f1.thenCombine(f2, (arg1, arg2) -&gt; &#123; System.out.println(&quot;thenCombine线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果1为：&quot; + arg1 + &quot;。结果2为：&quot; + arg2); return arg1 + arg2; &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync1线程名称: ForkJoinPool.commonPool-worker-1。结果为：100// supplyAsync2线程名称: ForkJoinPool.commonPool-worker-1。结果为：200// thenCombine线程名称: main。结果1为：100。结果2为：200// 阻塞获取结果。结果为：300 OR组合关系123public &lt;U&gt; CompletionStage&lt;U&gt; applyToEither(CompletionStage&lt;? extends T&gt; other,Function&lt;? super T, U&gt; fn);public CompletableFuture&lt;Void&gt; acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action);public CompletableFuture&lt;Void&gt; runAfterEither(CompletionStage&lt;?&gt; other, Runnable action); applyToEither/acceptEither/runAfterEither都表示：将两个CompletableFuture组合起来，只要其中一个执行完了就会执行下个任务。 区别在于： applyToEither：将已经执行完成的任务结果作为方法入参，传递到指定方法中，有返回值 acceptEither：将已经执行完成的任务结果作为方法入参，传递到指定方法中，无返回值 runAfterEither：不会把执行结果当做方法入参，没有返回值 12345678910111213141516171819202122private static void acceptEither() throws Exception &#123; // supplyAsync1、supplyAsync2其中一个执行完成后执行acceptEither(接收一个参数，为f1、f2先执行完的结果。无返回值) Random random = new Random(); CompletableFuture&lt;Integer&gt; f1 = CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(200), TimeUnit.MILLISECONDS); System.out.println(&quot;supplyAsync1线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：100&quot;); return 100; &#125;); CompletableFuture&lt;Integer&gt; f2 = CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(200), TimeUnit.MILLISECONDS); System.out.println(&quot;supplyAsync2线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：200&quot;); return 200; &#125;); CompletableFuture&lt;Void&gt; future = f1.acceptEither(f2, arg -&gt; &#123; System.out.println(&quot;acceptEither线程名称: &quot; + Thread.currentThread().getName() + &quot;。参数为：&quot; + arg + &quot;。无返回值&quot;); &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync2线程名称: ForkJoinPool.commonPool-worker-2。结果为：200// acceptEither线程名称: ForkJoinPool.commonPool-worker-2。参数为：200。无返回值// 阻塞获取结果。结果为：null anyOf1public static CompletableFuture&lt;Object&gt; anyOf(CompletableFuture&lt;?&gt;... cfs) 任意一个任务执行完，就执行anyOf返回的CompletableFuture。如果执行的任务异常，anyOf的CompletableFuture执行get()方法会抛出异常。 123456789101112131415161718192021private static void anyOf() throws Exception &#123; Random random = new Random(); CompletableFuture&lt;Integer&gt; f1 = CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(200), TimeUnit.MILLISECONDS); System.out.println(&quot;supplyAsync1线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：100&quot;); return 100; &#125;); CompletableFuture&lt;Integer&gt; f2 = CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(100), TimeUnit.MILLISECONDS); System.out.println(&quot;supplyAsync2线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：200&quot;); return 200; &#125;); CompletableFuture&lt;Object&gt; future = CompletableFuture.anyOf(f1, f2).whenComplete((arg, throwable) -&gt; &#123; System.out.println(&quot;anyOf线程名称: &quot; + Thread.currentThread().getName() + &quot;。参数为：&quot; + arg + &quot;。无返回值&quot;); &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync2线程名称: ForkJoinPool.commonPool-worker-2。结果为：200// anyOf线程名称: ForkJoinPool.commonPool-worker-2。参数为：200。无返回值// 阻塞获取结果。结果为：200 allOf1public static CompletableFuture&lt;Void&gt; allOf(CompletableFuture&lt;?&gt;... cfs) 所有任务都执行完成后，才执行allOf返回的CompletableFuture。如果任意一个任务异常，allOf的CompletableFuture执行get()方法都会抛出异常。 1234567891011121314151617181920212223private static void allOf() throws Exception &#123; Random random = new Random(); CompletableFuture&lt;Integer&gt; f1 = CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(200), TimeUnit.MILLISECONDS); System.out.println(&quot;supplyAsync1线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：100&quot;); return 100; &#125;); CompletableFuture&lt;Integer&gt; f2 = CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(100), TimeUnit.MILLISECONDS); System.out.println(&quot;supplyAsync2线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：200&quot;); return 200; &#125;); CompletableFuture&lt;Void&gt; future = CompletableFuture.allOf(f1, f2).whenComplete((unused, throwable) -&gt; &#123; System.out.println(&quot;allOf线程名称: &quot; + Thread.currentThread().getName() + &quot;。参数为：&quot; + unused + &quot;。无返回值&quot;); &#125;); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync2线程名称: ForkJoinPool.commonPool-worker-2。结果为：200// supplyAsync1线程名称: ForkJoinPool.commonPool-worker-1。结果为：100// allOf线程名称: ForkJoinPool.commonPool-worker-1。参数为：null。无返回值// 阻塞获取结果。结果为：null thenCompose1public &lt;U&gt; CompletableFuture&lt;U&gt; thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) 在某个任务执行完成后，将该任务的执行结果作为方法入参去执行指定的方法。该方法会返回一个新的CompletableFuture实例。 1234567891011121314151617private static void thenCompose() throws Exception &#123; Random random = new Random(); CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(200), TimeUnit.MILLISECONDS); System.out.println(&quot;supplyAsync线程名称: &quot; + Thread.currentThread().getName() + &quot;。结果为：100&quot;); return 100; &#125;).thenCompose(arg -&gt; CompletableFuture.supplyAsync(() -&gt; &#123; Uninterruptibles.sleepUninterruptibly(random.nextInt(100), TimeUnit.MILLISECONDS); System.out.println(&quot;thenCompose线程名称: &quot; + Thread.currentThread().getName() + &quot;。接收参数为：&quot; + arg + &quot;。返回：200&quot;); return 200; &#125;)); System.out.println(&quot;阻塞获取结果。结果为：&quot; + future.get());&#125;// supplyAsync线程名称: ForkJoinPool.commonPool-worker-1。结果为：100// thenCompose线程名称: ForkJoinPool.commonPool-worker-2。接收参数为：100。返回：200// 阻塞获取结果。结果为：200 注意事项CompletableFuture.get方法是阻塞的CompletableFuture的get()方法是阻塞的，如果使用它来获取异步调用的返回值，最好添加超时时间。 CompletableFuture.get()：获取返回值抛出异常。 CompletableFuture.join()：获取返回值不抛出异常。 线程池CompletableFuture默认使用ForkJoinPool.commonPool线程池，核心数量为服务器CPU-1。当有大量请求处理且任务耗时较久时就会响应很慢。建议使用自定义线程池，配置自定义线程池参数。 Future需要获取返回值才能获取异常信息123456CompletableFuture&lt;Void&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; return 100 / 0;&#125;).thenAccept(System.out::println);// 不加get()方法这一行，看不到异常信息future.get(); Future需要获取返回值，才能获取到异常信息。如果不加 get()/join()方法，看不到异常信息。使用的时候需要考虑是否加try...catch...或者使用exceptionally方法。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"Docker常用命令总结","slug":"Docker常用命令总结","date":"2021-08-20T12:28:49.000Z","updated":"2021-12-28T15:00:18.115Z","comments":true,"path":"Docker常用命令总结/","link":"","permalink":"https://mx-go.github.io/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/","excerpt":"","text":"图示命令 docker服务 COMMAND DESC docker info 系统级别docker信息。包含镜像和容器数量等。 docker version 查看docker版本信息 docker -v 查看docker简要信息 systemctl enable docker 设置开机自启 systemctl start docker 启动docker systemctl stop docker 关闭docker service docker restart 重启docker服务 service docker stop 停止docker服务 docker镜像docker官方镜像地址：https://hub.docker.com COMMAND DESC docker search &lt;镜像名称&gt; 搜索docker镜像 docker pull &lt;镜像名称&gt; 拉取镜像 docker images 列出所有镜像信息 docker images -qa 列出所有镜像ID docker rmi &lt;镜像ID&gt; 单个删除镜像 docker rmi $(docker rmi -qa) 删除所有镜像 docker容器 COMMAND DESC docker inspect &lt;容器ID&gt; 查看容器元信息 docker ps 查看所有运行中的容器 docker ps -a 查看所有容器 docker run &lt;容器ID&gt; 新建并启动容器 docker start &lt;容器ID |容器名称&gt; 启动已终止容器 docker stop &lt;容器ID |容器名称&gt; 停止运行中容器 docker restart &lt;容器ID |容器名称&gt; 重启容器 docker kill &lt;容器ID |容器名称&gt; 强制杀死容器 docker rm &lt;容器ID |容器名称&gt; 删除单个容器 docker rm $(docker ps -qa) 删除所有容器 docker exec -it &lt;容器ID&gt; /bin/bash 交互式进入容器 docker top &lt;容器ID&gt; 查看容器中的进程信息 docker网络 COMMAND DESC docker network ls 查看docker网络 docker network inspect &lt;网络ID&gt; 查看网络详情 docker network create –driver bridge –subnet –gateway &lt;网络名称&gt; 创建docker自定义网络。例：docker network create –driver bridge –subnet 192.168.0.0/16 –gateway 192.168.0.1 mynet 其他命令 COMMAND DESC docker logs &lt;容器ID&gt; 查看容器日志 docker cp &lt;本机文件&gt; &lt;容器ID&gt;:&lt;容器文件路径&gt; 拷贝宿主机文件到容器 docker cp &lt;容器ID&gt;:&lt;容器文件&gt; &lt;本机路径&gt; 拷贝容器文件到宿主机 docker volume ls 查看挂载卷列表 docker inspect &lt;volume名称&gt; 查看挂载卷详情 docker volume prune 清理无效挂载卷 常用镜像 -d ：表示以后台方式运行 -p ：端口映射。: -P ：随机指定端口 -v ：挂载卷。: --name ：容器名称 --net ：自定义网络 Portainer123# windows环境安装。使用手册见 https://hub.docker.com/r/portainer/portainer-ce# 访问端口为9000docker run -d -p 9000:9000 --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data -v \\\\.\\pipe\\docker_engine:\\\\.\\pipe\\docker_engine --name prtainer portainer/portainer-ce MySQL12# 数据库密码为123456docker run -d -p 3306:3306 -v G:\\volumes\\mysql\\conf:/etc/mysql/conf.d -v G:\\volumes\\mysql\\data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql mysql:8.0.26 Grafana12# 访问端口为3000docker run -d -p 3000:3000 --name grafana grafana/grafana Nacos12# 访问端口为8848docker run -dp 8848:8848 -e MODE=standalone --name nacos nacos/nacos-server:latest Xxl-job 需要在本地新建挂载文件 application.properties。 路径为https://github.com/xuxueli/xxl-job/blob/master/xxl-job-admin/src/main/resources/application.properties 修改MySQL的用户名和密码 12// 访问端口为9090。挂载配置路径为G:\\volumes\\xxl-job\\application.propertiesdocker run -dp 9090:9090 -v G:\\volumes\\xxl-job\\application.properties:/application.properties -e PARAMS=&#x27;--spring.config.location=/application.properties&#x27; --name xxl-job-admin xuxueli/xxl-job-admin:2.3.0 ElasticSearch相关docker-compose.yaml 如下所示 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758version: &#x27;3.8&#x27;services: cerebro: image: lmenezes/cerebro:0.9.3 container_name: cerebro ports: - &quot;9300:9000&quot; command: - -Dhosts.0.host=http://elasticsearch:9200 networks: - es7net elasticsearch-head: image: mobz/elasticsearch-head:5-alpine container_name: es-head ports: - &quot;9100:9100&quot; networks: - es7net kibana: image: kibana:7.9.3 container_name: kibana environment: - I18N_LOCALE=zh-CN - XPACK_GRAPH_ENABLED=true - TIMELION_ENABLED=true - XPACK_MONITORING_COLLECTION_ENABLED=&quot;true&quot; ports: - &quot;5601:5601&quot; networks: - es7net elasticsearch: image: elasticsearch:7.9.3 container_name: elasticsearch environment: - cluster.name=maxTest - node.name=es7_01 - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; - discovery.seed_hosts=es7_01 - cluster.initial_master_nodes=es7_01 ulimits: memlock: soft: -1 hard: -1 volumes: - es7data1:/usr/share/elasticsearch/data ports: - 9200:9200 networks: - es7netvolumes: es7data1: driver: localnetworks: es7net: driver: bridge cerebro访问端口为9300 elasticsearch-head访问端口为9100 kibana访问端口为6501 elasticsearch访问端口为9200 若想要elasticsearch-head连接es，需要在es容器config路径elasticsearch.yml配置文件中添加 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; Apollo官方文档：https://www.apolloconfig.com/#/zh/deployment/quick-start-docker Yapi官方文档：https://github.com/fjc0k/docker-YApi","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://mx-go.github.io/tags/docker/"}]},{"title":"离线安装docker与docker-compose","slug":"离线安装docker与docker-compose","date":"2021-07-23T07:20:10.000Z","updated":"2021-10-10T00:39:48.229Z","comments":true,"path":"离线安装docker与docker-compose/","link":"","permalink":"https://mx-go.github.io/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85docker%E4%B8%8Edocker-compose/","excerpt":"在线安装docker官方详细教程：https://docs.docker.com/engine/install/centos/ 在线安装docker-compose官方详细教程：https://docs.docker.com/compose/install/#install-compose","text":"在线安装docker官方详细教程：https://docs.docker.com/engine/install/centos/ 在线安装docker-compose官方详细教程：https://docs.docker.com/compose/install/#install-compose 安装docker下载安装包官方离线安装包下载地址：https://download.docker.com/linux/static/stable/x86_64/ 目前最新版本为：docker-18.06.3-ce.tgz 脚本准备docker.service 作用：安装和卸载docker脚本需要用到此脚本 123456789101112131415161718192021222324252627282930313233[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerdExecReload=/bin/kill -s HUP $MAINPID# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Uncomment TasksMax if your systemd version supports it.# Only systemd 226 and above support this version.#TasksMax=infinityTimeoutStartSec=0# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=process# restart the docker process if it exits prematurelyRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.target 安装脚本 install.sh123456789101112131415161718192021222324#!/bin/shecho &#x27;解压tar包...&#x27;tar -xvf $1echo &#x27;将docker目录移到/usr/bin目录下...&#x27;cp docker/* /usr/bin/echo &#x27;将docker.service 移到/etc/systemd/system/ 目录...&#x27;cp docker.service /etc/systemd/system/echo &#x27;添加文件权限...&#x27;chmod +x /etc/systemd/system/docker.serviceecho &#x27;重新加载配置文件...&#x27;systemctl daemon-reloadecho &#x27;启动docker...&#x27;systemctl start dockerecho &#x27;设置开机自启...&#x27;systemctl enable docker.serviceecho &#x27;docker安装成功...&#x27;docker -v 卸载脚本 uninstall.sh1234567891011#!/bin/shecho &#x27;删除docker.service...&#x27;rm -f /etc/systemd/system/docker.serviceecho &#x27;删除docker文件...&#x27;rm -rf /usr/bin/docker*echo &#x27;重新加载配置文件&#x27;systemctl daemon-reloadecho &#x27;卸载成功...&#x27; 安装目录中至少包含docker-18.06.3-ce.tgz、docker.service、install.sh、uninstall.sh文件 执行安装脚本12# 安装dockersh install.sh docker-18.06.3-ce.tgz 查看docker版本12# 查看docker版本docker -v 卸载12# 卸载dockersh uninstall.sh 安装docker-compose下载安装包官方离线安装包下载地址：https://github.com/docker/compose/releases 目前最新版本为v2.0.1：docker-compose-linux-x86_64 脚本进入到docker-compose-linux-x86_64所在文件目录 安装脚本 install-compose.sh123456789101112#!/bin/shecho &#x27;拷贝文件到/usr/local/bin目录...&#x27;cp docker-compose-Linux-x86_64 /usr/local/bin/docker-composecd /usr/local/binecho &#x27;授权docker-compose...&#x27;# 执行授权sudo chmod +x docker-composeecho &#x27;安装成功&#x27; 12# 安装docker-composesh install-compose.sh 查看docker-compose版本1docker-compose --version","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"安装","slug":"Linux/安装","permalink":"https://mx-go.github.io/categories/Linux/%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://mx-go.github.io/tags/docker/"}]},{"title":"线程池踩坑","slug":"线程池踩坑","date":"2021-06-04T00:25:58.000Z","updated":"2021-08-04T14:17:58.022Z","comments":true,"path":"线程池踩坑/","link":"","permalink":"https://mx-go.github.io/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%B8%A9%E5%9D%91/","excerpt":"","text":"使用线程池这么久，自认为很熟悉，居然还能踩到坑！问题原因：线程池使用 FutureTask的时候如果拒绝策略设置为了 DiscardPolicy或DiscardOldestPolicy并且在被拒绝的任务 Future对象上调用无参 get方法那么调用线程会一直被阻塞。 问题复现先来看一段代码进行复现 12345678910111213141516171819202122232425262728293031323334353637383940414243public class FutureTest &#123; /** * 创建核心数量为1，队列个数为1的线程池。拒绝策略为DiscardPolicy。 */ private static final ThreadPoolExecutor EXECUTOR = new ThreadPoolExecutor(1, 1, 0, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(1), new NamedThreadFactory(&quot;executor&quot;), new ThreadPoolExecutor.DiscardPolicy()); public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 添加任务一 Future&lt;?&gt; first = EXECUTOR.submit(() -&gt; &#123; System.out.println(&quot;first task start&quot;); Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS); &#125;); // 添加任务二 Future&lt;?&gt; second = EXECUTOR.submit(() -&gt; &#123; System.out.println(&quot;second task start&quot;); Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS); &#125;); // 添加任务、三 Future&lt;?&gt; third = null; try &#123; third = EXECUTOR.submit(() -&gt; &#123; System.out.println(&quot;first task start&quot;); Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS); &#125;); &#125; catch (Exception e) &#123; System.out.println(e.getLocalizedMessage()); &#125; // 等待任务一执行完毕 System.out.println(&quot;first task output. &quot; + first.get()); // 等待任务二执行完毕 System.out.println(&quot;second task output. &quot; + second.get()); // 等待任务三执行完毕 System.out.println(&quot;third task output. &quot; + (third == null ? null : third.get())); // 关闭线程池 EXECUTOR.shutdown(); &#125;&#125; 执行结果为下图所示，third task 一直没有执行，且主线程阻塞在third.get() 1234first task startfirst task output. nullsecond task startsecond task output. null 流程分析 创建一个核心线程数为1且队列大小为1的线程池，设置拒绝策略为DiscardPolicy。 向线程池提交first任务，线程池会使用核心线程池执行该任务，任务将会阻塞3s。 向线程池提交second任务，线程池将任务放到队列中。 向线程池提交third任务，线程池已满，线程池采用DiscardPolicy丢弃任务。 等待first任务执行完毕后主线程打印 first task output. null first任务执行完成关闭后，线程池从队列中取出second任务执行，主线程打印second task output. null third任务会一直阻塞，程序不会结束。如果把拒绝策略修改为DiscardOldestPolicy，也会出现同样的问题。 将拒绝策略修改为AbortPolicy后输出结果如下，线程池正常关闭。 123456first task startTask java.util.concurrent.FutureTask@32c4e8b2 rejected from java.util.concurrent.ThreadPoolExecutor@64bce832[Running, pool size = 1, active threads = 1, queued tasks = 1, completed tasks = 0]first task output. nullsecond task startsecond task output. nullthird task output. null 调用逻辑梳理当提交任务到线程池中时 12345678910111213public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 包装Runnable为Future对象 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); // 返回Future对象 return ftask;&#125;// 包装Runnable为Future对象protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125; 1234567891011121314151617181920212223public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 任务数量小于核心线程池数量时新增线程处理 if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; // 任务数量达到核心线程数量时，将任务放入队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 尝试新增线程处理任务 else if (!addWorker(command, false)) // 新增失败，调用拒绝策略 reject(command);&#125; 上述是任务不断加入线程池的流程处理，其中需要研究的就是最后一步拒绝策略对任务的影响。 1234567public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; // 什么都没做 public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125; 当拒绝策略使用DiscardPolicy时发现什么都没做。但是当把 Runnable包装为Future对象时，Future是有状态的，Future中的状态如下： 1234567private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 在把Runnable包装为Future对象的时候使用newTaskFor方法转换Runnable为FutureTask，而FutureTask的构造函数里面设置的线程状态就是New。所以使用DiscardPolicy策略提交后返回了一个状态为NEW的Future对象。 1234public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 当调用Future的无参get方法时逻辑如下： 123456789101112131415161718public V get() throws InterruptedException, ExecutionException &#123; int s = state; // 当状态值 &lt;= COMPLETING时需要等待，否者调用report返回 if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125;private V report(int s) throws ExecutionException &#123; Object x = outcome; // 状态值为NORMAL正常返回 if (s == NORMAL) return (V)x; // 状态值大于等于CANCELLED则抛异常 if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x);&#125; 也就是说当Future的状态 &gt;COMPLETING时候调用get方法才会正常返回，而DiscardPolicy策略在拒绝任务的时候并没有设置future的状态，后面也没有其他机会可以设置该future的状态，所以future的状态一直是NEW，导致任务阻塞，一直不会返回。同理DiscardOldestPolicy策略也是这样的问题，最老的任务被淘汰时没有设置淘汰任务future的状态。 默认的AbortPolicy策略当任务超出后会直接会抛出RejectedExecutionException异常，也就是submit方法并没有返回future对象，这时候third是null，可以正常返回。 结论当使用Future的时候，尽量使用带超时时间的get方法，这样即使使用了DiscardPolicy拒绝策略也不至于任务一直等待，超时时间到了会自动返回，如果非要使用不带参数的get方法则可以重写DiscardPolicy的拒绝策略，在执行策略时候设置该Future的状态大于COMPLETING即可，但是查看FutureTask提供的方法发现只有cancel方法是public的并且可以设置FutureTask的状态大于COMPLETING，重写拒绝策略的线程池具体代码如下： 123456private static final ThreadPoolExecutor EXECUTOR = new ThreadPoolExecutor(1, 1, 0, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(1), new NamedThreadFactory(&quot;executor&quot;), (r, executor) -&gt; &#123; if (r instanceof FutureTask) &#123; ((FutureTask&lt;?&gt;) r).cancel(true); &#125; &#125;); 使用这个策略后，Future.isCancelled方法可判断线程是否已经取消，所以可以将代码修改为： 12// 等待任务三执行完毕System.out.println(&quot;third task output. &quot; + (third.isCancelled() ? &quot;拒绝了&quot; : third.get()));","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"Nginx条件中的或、与","slug":"Nginx条件中的或、与","date":"2021-05-27T15:31:59.000Z","updated":"2022-01-06T00:40:42.774Z","comments":true,"path":"Nginx条件中的或、与/","link":"","permalink":"https://mx-go.github.io/Nginx%E6%9D%A1%E4%BB%B6%E4%B8%AD%E7%9A%84%E6%88%96%E3%80%81%E4%B8%8E/","excerpt":"在公司的编程马拉松中前端项目部署在NG的镜像中，其中有个需求是通过浏览器访问时，若请求是前端资源则返回前端页面，如果请求的是后端接口则返回后端响应。如：浏览器访问 http://abc.com/apis/name 时，有可能是前端页面路径，也有可能为后端接口路径。通过NG的条件判断可以实现此需求。","text":"在公司的编程马拉松中前端项目部署在NG的镜像中，其中有个需求是通过浏览器访问时，若请求是前端资源则返回前端页面，如果请求的是后端接口则返回后端响应。如：浏览器访问 http://abc.com/apis/name 时，有可能是前端页面路径，也有可能为后端接口路径。通过NG的条件判断可以实现此需求。 正则匹配 符号 描述 = 字符串比较相等 != 字符串比较不相等 ~ 符合指定正则表达式时返回true（匹配时区分大小写） ~* 符合指定正则表达式时返回true（匹配时不区分大小写） !~ 不符合指定正则表达式时返回true（匹配时区分大小写） !~* 不符合指定正则表达式时返回true（匹配时不区分大小写） NG中的表达式和大多数语言一样 1234567if (&lt;condition1&gt;) &#123; # do something1&#125; if (&lt;condition2&gt;) &#123; # do something2 # return;&#125; 不支持多条件表达式 不支持嵌套 不支持else 在NG的条件表达式中没有表达式没有直接”或“、“与”的语法，需要存储变量的状态来实现“或”、“与”的效果。 或场景一123456789101112# 设置flag的初始值set $flag &quot;&quot;;if (&lt;condition1&gt;) &#123; set $flag 1;&#125;if (&lt;condition2&gt;) &#123; set $flag 1;&#125;# 满足 condition1或condition2其中一个条件则会执行if ($flag = 1) &#123; # do something&#125; 上述条件表达式类似Java中的 123if (&lt;condition1&gt; || &lt;condition2&gt;) &#123; // do something&#125; 场景二在判断变量值时，可以直接用|判断 1234# 请求方式为GET、POST、PUT、DELETE其中一种if ($request_method ~ (GET|POST|PUT|DELETE)) &#123; # do something&#125; 与12345678910111213# 设置flag的初始值set $flag &quot;&quot;;if (&lt;condition1&gt;) &#123; set $flag &quot;$&#123;flag&#125;1&quot;;&#125;if (&lt;condition2&gt;) &#123; set $flag &quot;$&#123;flag&#125;2&quot;;&#125;# 同时满足condition1与condition2时执行if ($flag = &quot;12&quot;) &#123; # do something&#125; 条件组合1234567891011121314151617181920212223# 设置flag的初始值set $flag &quot;&quot;;# 或 的关系if (&lt;condition0&gt;) &#123; set $flag &quot;1&quot;;&#125;if (&lt;condition1&gt;) &#123; set $flag &quot;1&quot;;&#125;# 与 的关系if (&lt;condition2&gt;) &#123; set $flag &quot;$&#123;flag&#125;2&quot;;&#125;if (&lt;condition3&gt;) &#123; set $flag &quot;$&#123;flag&#125;3&quot;;&#125;# 或(condition0、condition1) 与(condition2、condition3)if ($flag = &quot;123&quot;) &#123; # do something&#125; flag初始值为空值，若想执行do something逻辑。 或：condition0、condition1只需满足一项； 与：condition2、condition3需要同时满足； 例回到文章描述的需求，可以做如下配置即可实现：当请求前端域名时，满足一定条件直接负载到后端接口获取响应。 12345678910111213141516171819202122location / &#123; set $flag &quot;&quot;; # 限定请求方式 if ($request_method ~ ^(GET|POST|PUT|DELETE)$) &#123; set $flag &quot;$&#123;flag&#125;1&quot;; &#125; # 响应码不为400 if ($status != 400) &#123; set $flag &quot;$&#123;flag&#125;2&quot;; &#125; # 请求uri不为/（为/表示请求域名，直接跳转主页） if ($uri != &#x27;/&#x27;) &#123; set $flag &quot;$&#123;flag&#125;3&quot;; &#125; # 满足以上条件时将请求代理后后端 if ($flag = &quot;123&quot;) &#123; proxy_pass http://bcmls-api.sit.rainbowhorse.com; &#125; root html; index index.html index.htm;&#125;","categories":[{"name":"中间件","slug":"中间件","permalink":"https://mx-go.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"nginx","slug":"nginx","permalink":"https://mx-go.github.io/tags/nginx/"}]},{"title":"命中SpringCloudGateway组件BUG","slug":"命中SpringCloudGateway组件BUG","date":"2021-05-10T02:11:22.000Z","updated":"2021-08-04T00:49:48.661Z","comments":true,"path":"命中SpringCloudGateway组件BUG/","link":"","permalink":"https://mx-go.github.io/%E5%91%BD%E4%B8%ADSpringCloudGateway%E7%BB%84%E4%BB%B6BUG/","excerpt":"","text":"生产环境网关模块偶发的OutOfDirectMemoryError错误排查起来困难且曲折，2021-02-05号也出现过此问题，起初以为是JVM堆内存过小(当时是2g)导致，后调整到8g(2月5号调整)。但是经过上次调整后5月7号又出现此问题，于是猜测可能是由于网关模块存在内存泄露导致。 症状报错详情网关模块偶现OutOfDirectMemoryError错误，两次问题出现相隔大概3个月。两次发生的时机都是正在大批量接收数据(大约500w)，TPS 60左右，网关服务波动不大，完全能抗住，按理不应该出现此错误。 详细报错信息如下： 123456789101112131415161718192021222021-05-06 13:44:18|WARN |[reactor-http-epoll-5]|[AbstractChannelHandlerContext.java : 311]|An exception &#x27;io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 16384 byte(s) of direct memory (used: 8568993562, max: 8589934592)&#x27; [enable DEBUG level for full stacktrace] was thrown by a user handler&#x27;s exceptionCaught() method while handling the following exception:io.netty.util.internal.OutOfDirectMemoryError: failed to allocate 16384 byte(s) of direct memory (used: 8568993562, max: 8589934592) at io.netty.util.internal.PlatformDependent.incrementMemoryCounter(PlatformDependent.java:754) at io.netty.util.internal.PlatformDependent.allocateDirectNoCleaner(PlatformDependent.java:709) at io.netty.buffer.UnpooledUnsafeNoCleanerDirectByteBuf.allocateDirect(UnpooledUnsafeNoCleanerDirectByteBuf.java:30) at io.netty.buffer.UnpooledDirectByteBuf.&lt;init&gt;(UnpooledDirectByteBuf.java:64) at io.netty.buffer.UnpooledUnsafeDirectByteBuf.&lt;init&gt;(UnpooledUnsafeDirectByteBuf.java:41) at io.netty.buffer.UnpooledUnsafeNoCleanerDirectByteBuf.&lt;init&gt;(UnpooledUnsafeNoCleanerDirectByteBuf.java:25) at io.netty.buffer.UnsafeByteBufUtil.newUnsafeDirectByteBuf(UnsafeByteBufUtil.java:625) at io.netty.buffer.PooledByteBufAllocator.newDirectBuffer(PooledByteBufAllocator.java:359) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:187) at io.netty.buffer.AbstractByteBufAllocator.directBuffer(AbstractByteBufAllocator.java:178) at io.netty.channel.unix.PreferredDirectByteBufAllocator.ioBuffer(PreferredDirectByteBufAllocator.java:53) at io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator$MaxMessageHandle.allocate(DefaultMaxMessagesRecvByteBufAllocator.java:114) at io.netty.channel.epoll.EpollRecvByteAllocatorHandle.allocate(EpollRecvByteAllocatorHandle.java:75) at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:777) at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475) at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378) at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:748) JVM配置1-server -Xmx8g -Xms8g -Xmn1024m -XX:PermSize=512m -Xss256k -XX:+DisableExplicitGC -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -Djava.awt.headless=true -Djava.net.preferIPv4Stack=true 版本信息12345spring cloud : Hoxton.SR5spring cloud starter gateway : 2.2.3.RELEASEspring boot starter : 2.3.0.RELEASEnetty : 4.1.54.Finalreactor-netty: 0.9.7.RELEASE 山重水复疑无路 JVM参数详解：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html 报错的信息是OutOfDirectMemoryError，即堆外内存不足，于是复习了下JVM堆外内存的相关知识。 堆外内存是在NIO中使用的； 堆外内存通过 -XX:MaxDirectMemorySize 参数控制大小，注意和 -XX:+DisableExplicitGC 参数的搭配使用； JDK8中堆外内存默认和堆内存一样大（-Xmx）； JDK8如果配置 -XX:MaxDirectMemorySize 参数，则堆外内存大小以设置的参数为准； SpringCloudGateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty。 网上查阅相关资料，有些场景是因为堆外内存没有手动release导致，于是简单查看了网关模块的相关代码发现并无此问题，关键的地方也都调用了相关方法释放内存。堆外内存通过操作堆的命令无法看到，只能监控实例总内存走势判断。 12// 释放内存方法DataBufferUtils.release(dataBuffer); Dump堆内存下来也没有发现有什么问题 柳暗花明又一村抱着试一试的想法到SpringCloudGateway官方仓库issue搜索有没有人遇到相同的问题，果不其然，有人提了类似的issue。https://github.com/spring-cloud/spring-cloud-gateway/issues/1704 在issue中开发人员也给出了回应，确实是SpringCloudGateway的BUG！此问题已在2.2.6.RELEASE版本中修复。而我们项目中使用版本为2.2.3.RELEASE，所以就会出现这个问题。 原因是：包装原生的pool后没有释放内存。 提交记录：https://github.com/spring-cloud/spring-cloud-gateway/pull/2019 变更的代码：https://github.com/spring-cloud/spring-cloud-gateway/pull/2019/commits/4e0f3b0beb51c54e3d5850e00540ff3d19a4264d 出乎意料问题原因已经找到，想着在测试环境复现后升级版本再验证即可。可结果却出乎了我的意料。 测试环境将堆内存调小尝试进行复现生产问题，在压测将近1个小时后出现了同样的问题，复现成功。 升级SpringCloudGateway的版本至2.2.6.RELEASE。 重新压测，问题再次出现。 你没看错，问题再次出现，且报错信息一模一样。我很快又陷入了沉思。 深究原因排除了组件的问题，剩下的就是代码的问题了，最有可能的就是程序中没有显示调用释放内存导致。 网关模块共定义了三个过滤器，一个全局过滤器RequestGatewayFilter implements GlobalFilter。两个自定义过滤器 RequestDecryptGatewayFilterFactory extends AbstractGatewayFilterFactory和ResponseEncryptGatewayFilterFactory extends AbstractGatewayFilterFactory。 依次仔细排查相关逻辑，在全局过滤器RequestGatewayFilter中有一块代码引起了我的注意： 1234567891011121314151617181920212223// 伪代码@Overridepublic Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; HttpHeaders headers = request.getHeaders(); return DataBufferUtils.join(exchange.getRequest().getBody()) .flatMap(dataBuffer -&gt; &#123; DataBufferUtils.retain(dataBuffer); Flux&lt;DataBuffer&gt; cachedFlux = Flux.defer(() -&gt; Flux.just(dataBuffer.slice(0, dataBuffer.readableByteCount()))); ServerHttpRequest mutatedRequest = new ServerHttpRequestDecorator(exchange.getRequest()) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return cachedFlux; &#125; @Override public HttpHeaders getHeaders() &#123; return headers; &#125; &#125;; return chain.filter(exchange.mutate().request(mutatedRequest).build()); &#125;);&#125; 我们知道，Request的Body是只能读取一次的，如果直接通过在Filter中读取，而不封装回去回导致后面的服务无法读取数据。 此全局过滤器的目的就是把原有的request请求中的body内容读出来，并且使用ServerHttpRequestDecorator这个请求装饰器对request进行包装，重写getBody方法，并把包装后的请求放到过滤器链中传递下去。这样后面的过滤器中再使用exchange.getRequest().getBody()来获取body时，实际上就是调用的重载后的getBody方法，获取的最先已经缓存了的body数据。这样就能够实现body的多次读取了。 但是将DataBuffer读取出来后并没有手动释内存，会导致堆外内存持续增长。于是添加了一行代码手动释放堆外内存：DataBufferUtils.release(dataBuffer); 12345678910111213141516171819202122232425262728// 伪代码@Overridepublic Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) &#123; HttpHeaders headers = request.getHeaders(); return DataBufferUtils.join(exchange.getRequest().getBody()) .flatMap(dataBuffer -&gt; &#123; byte[] bytes = new byte[dataBuffer.readableByteCount()]; dataBuffer.read(bytes); // 释放堆外内存 DataBufferUtils.release(dataBuffer); ServerHttpRequest mutatedRequest = new ServerHttpRequestDecorator(exchange.getRequest()) &#123; @Override public Flux&lt;DataBuffer&gt; getBody() &#123; return Flux.defer(() -&gt; &#123; DataBuffer buffer = exchange.getResponse().bufferFactory().wrap(bytes); DataBufferUtils.retain(buffer); return Mono.just(buffer); &#125;); &#125; @Override public HttpHeaders getHeaders() &#123; return headers; &#125; &#125;; return chain.filter(exchange.mutate().request(mutatedRequest).build()); &#125;);&#125; 再次压测未出现堆外内存溢出问题。终究还是自己大意了。。 后在网络上查询到了类似的案例：https://github.com/reactor/reactor-netty/issues/788 总结这个问题排查花费了自己不少的时间，自己也没有想到这么曲折。问题是解决了，但是暴露了自身的很多问题，比如针对不同版本JVM内存分配不够熟悉、对SpringCloudGateway不够熟悉及太过相信官方开源版本。在直接内存中排查了很久，浪费了不少时间。同时自己也学到了不少东西： 遇到问题主要先去思考，要全面且细致，慢慢去分析，抽丝剥茧； 一定要细致再细致，耐心再耐心的去还原问题，思考问题； JVM直接内存的使用和配置、场景； 不要对开源组件过分信任，遇到问题时，对开源组件持怀疑态度；","categories":[{"name":"组件","slug":"组件","permalink":"https://mx-go.github.io/categories/%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"bug","slug":"bug","permalink":"https://mx-go.github.io/tags/bug/"}]},{"title":"Spring反射调用Bean方法","slug":"Spring反射调用Bean方法","date":"2020-12-26T14:49:44.000Z","updated":"2021-12-26T15:04:52.494Z","comments":true,"path":"Spring反射调用Bean方法/","link":"","permalink":"https://mx-go.github.io/Spring%E5%8F%8D%E5%B0%84%E8%B0%83%E7%94%A8Bean%E6%96%B9%E6%B3%95/","excerpt":"","text":"Spring通过ApplicationContextAware反射调用服Bean方法，ApplicationContextAware常用方法封装。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Configurationpublic class SpringReflectUtils implements ApplicationContextAware &#123; /** * Spring容器 spring应用上下文对象 */ private static ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; SpringReflectUtils.applicationContext = applicationContext; &#125; /** * bean名称 * * @param name 要查询的bean的名称 * @return true：包含 */ public static boolean containsBean(String name) &#123; return applicationContext.containsBean(name); &#125; /** * 通过对象名称获取spring bean对象 * * @param name bean的名称 * @return 对象 */ public static Object getBean(String name) throws BeansException &#123; return applicationContext.getBean(name); &#125; /** * 返回与给定对象类型唯一匹配的bean实例(如果有) * * @param requiredType bean 必须匹配的类型； 可以是接口或超 * @return 匹配所需类型的单个 bean 的实例 */ public static &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException &#123; return applicationContext.getBean(requiredType); &#125; /** * 返回与给定对象类型（包括子类）匹配的 bean 实例 * * @param type 要匹配的类或接口 * @return Map&lt;bean名称, bean实例&gt; */ public static &lt;T&gt; Map&lt;String, T&gt; getBeansOfType(Class&lt;T&gt; type) throws BeansException &#123; return applicationContext.getBeansOfType(type); &#125; /** * 根据bean名称、方法名反射调用spring bean中的方法 * * @param serviceName 服务名 * @param methodName 方法名 * @param params 参数 * @return 对象 */ public static Object springInvokeMethod(String serviceName, String methodName, Object[] params) throws Exception &#123; Object service = getBean(serviceName); Class&lt;? extends Object&gt;[] paramClass = null; if (params != null) &#123; int paramsLength = params.length; paramClass = new Class[paramsLength]; for (int i = 0; i &lt; paramsLength; i++) &#123; paramClass[i] = params[i].getClass(); &#125; &#125; // 找到方法 Method method = ReflectionUtils.findMethod(service.getClass(), methodName, paramClass); // 执行方法 return ReflectionUtils.invokeMethod(method, service, params); &#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"Nginx日志无法轮转","slug":"Nginx日志无法轮转","date":"2020-10-02T15:18:39.000Z","updated":"2022-01-05T15:43:06.190Z","comments":true,"path":"Nginx日志无法轮转/","link":"","permalink":"https://mx-go.github.io/Nginx%E6%97%A5%E5%BF%97%E6%97%A0%E6%B3%95%E8%BD%AE%E8%BD%AC/","excerpt":"","text":"症状Nginx刚启动后日志记录正常，一段时间后，Nginx会把已产生的日志压缩为.gz文件。但是一旦压缩后，就不再记录新日志到新生成的access.log文件，但日志文件存在，里面却没有任何日志。旧的日志压缩后没有问题，自从压缩后，新的文件再也不记录新日志了(发现Nginx会很消耗内存，估计日志都存在内存里，不写文件了)。 我们的Nginx部署在k8s中，查看Nginx的配置没有发现任何问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#user nobody;worker_processes 4;error_log /app/openresty/nginx/logs/error.log error;pid /app/openresty/nginx/logs/nginx.pid;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;events &#123; worker_connections 65536 ;&#125;http &#123; include mime.types; include custom_upstream.conf; default_type application/octet-stream; log_format main &#x27;$remote_addr|$remote_user|[$time_local]|&quot;$request&quot;&#x27; &#x27;|$status|$request_time|$body_bytes_sent|&quot;$http_referer&quot;&#x27; &#x27;|&quot;$http_user_agent&quot;|&quot;$http_x_forwarded_for&quot;|$upstream_response_time|$upstream_status&#x27;; access_log /app/openresty/nginx/logs/access.log main; server_tokens off; sendfile on; tcp_nopush on; tcp_nodelay on; client_max_body_size 100m; client_header_buffer_size 100m; keepalive_timeout 60; proxy_buffering off; gzip on; server &#123; listen 80; server_name localhost; listen 443 ssl; #charset koi8-r; include custom_location.conf; location / &#123; root html; index index.html index.htm; &#125; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location = /nstats &#123; check_status; access_log off; allow 10.116.0.0/16; allow 10.110.0.0/16; allow 10.117.0.0/16; allow 10.150.0.0/16; allow 100.0.0.0/8; allow 10.0.0.0/8; deny all; &#125; &#125;&#125; 原因经查询资料在stackoverflow发现了类似的问题，见链接：https://stackoverflow.com/questions/9552930/nginx-cannot-write-into-access-log 原因是当Nginx压缩文件后，需要给master进程发送USR1信号后重新打开文件。 于是查看了Nginx的进程ID为33 12[mwopr@k8s-opc-openapi-nginx-77787494c5-c77s8 logs]$ cat nginx.pid 33 当执行重新打开log文件命令时提示没有权限 12[mwopr@k8s-opc-openapi-nginx-77787494c5-c77s8 logs]$ kill -USR1 33bash: kill: (33) - Operation not permitted 这个时候恍然大悟，登陆shell的默认用户是mwopr，没有权限执行kill命令，需要用root用户执行，当切换为root用户后，执行kill命令成功且日志可以正常写入。 原理原文：http://nginx.org/en/docs/control.html Nginx可以通过信号进行控制。对应Linux系统就是用kill命令。 master进程id默认写入到/nginx/logs/nginx.pid文件中。文件也可以在nginx.conf文件中指定。master进程支持以下信号： 123456kill -TERM pid # 快速停止master进程。 kill -QUIT pid # 优雅的停止。 kill -HUB pid # 改变配置文件。开启一个新的worker进程处理，优雅的停止老的worker进程。相当于nginx -s reload kill -USR1 pid # 重新打开log文件。-s reopen命令 kill -USR2 pid # 升级可执行文件。热部署 kill -WINCH pid # 优雅的关闭worker进程。 每个worker进程也可以接收信号： 123kill -TERM pid # 快速关闭worker进程 kill -QUIT pid # 优雅退出 kill -USR1 pid # 重新打开日志文件,先mv一个，再去执行这个命令。-s reopen命令 日志轮转 重命名log文件。 给master进程发送USR1信号。 重新打开文件。 Rotating Log-files In order to rotate log files, they need to be renamed first. After that USR1 signal should be sent to the master process. The master process will then re-open all currently open log files and assign them an unprivileged user under which the worker processes are running, as an owner. After successful re-opening, the master process closes all open files and sends the message to worker process to ask them to re-open files. Worker processes also open new files and close old files right away. As a result, old files are almost immediately available for post processing, such as compression.","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"nginx","slug":"nginx","permalink":"https://mx-go.github.io/tags/nginx/"}]},{"title":"轻量级日志采集Loki搭建","slug":"轻量级日志采集Loki搭建","date":"2020-09-20T01:44:59.000Z","updated":"2021-12-27T10:10:24.893Z","comments":true,"path":"轻量级日志采集Loki搭建/","link":"","permalink":"https://mx-go.github.io/%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86Loki%E6%90%AD%E5%BB%BA/","excerpt":"","text":"Loki是受Prometheus启发由Grafana Labs团队开源的水平可扩展，高度可用的多租户日志聚合系统。它的设计具有很高的成本效益，并且易于操作。使用标签来作为索引，而不是对全文进行检索，也就是说，通过这些标签既可以查询日志的内容也可以查询到监控的数据签，极大地降低了日志索引的存储。 简介只要在应用程序服务器上安装Promtail来收集日志然后发送给Loki存储，就可以在Grafana UI界面通过添加Loki为数据源进行日志查询(如果Loki服务器性能不够，可以部署多个Loki进行存储及查询）。作为一个日志系统不光只有查询分析日志的能力，还能对日志进行监控和报警。 Loki是主服务器，负责存储日志和处理查询 。 Promtail是客户端代理，负责收集日志并将其发送给Loki。 Grafana用于UI展示。 Loki架构 Promtail收集并将日志发送给Loki的Distributor组件； Distributor会对接收到的日志流进行正确性校验，并将验证后的日志分批并行发送到Ingester； Ingester接受日志流并构建数据块，压缩后存放到所连接的存储后端； Querier收到HTTP查询请求，并将请求发送至Ingester用以获取内存数据 ，Ingester收到请求后返回符合条件的数据 ； 如果Ingester没有返回数据，Querier会从后端存储加载数据并遍历去重执行查询 ，通过HTTP返回查询结果。 安装包下载Loki安装包下载地址【loki-linux-amd64.zip】：https://github.com/grafana/loki/releases Promtail安装包下载地址【promtail-linux-amd64.zip】：https://github.com/grafana/loki/releases Loki配置config.yaml配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354auth_enabled: falseserver: http_listen_port: 3100ingester: lifecycler: address: 127.0.0.1 ring: kvstore: store: inmemory replication_factor: 1 final_sleep: 0s chunk_idle_period: 5m chunk_retain_period: 30sschema_config: configs: - from: 2021-03-01 store: boltdb object_store: filesystem schema: v9 index: prefix: index_ period: 672hstorage_config: boltdb: directory: /tmp/loki/index filesystem: directory: /tmp/loki/chunkslimits_config: enforce_metric_name: false reject_old_samples: true reject_old_samples_max_age: 672hchunk_store_config: max_look_back_period: 0table_manager: chunk_tables_provisioning: inactive_read_throughput: 0 inactive_write_throughput: 0 provisioned_read_throughput: 0 provisioned_write_throughput: 0 index_tables_provisioning: inactive_read_throughput: 0 inactive_write_throughput: 0 provisioned_read_throughput: 0 provisioned_write_throughput: 0 retention_deletes_enabled: true retention_period: 672h start.sh配置12#!/bin/bash./loki --config.file=config.yaml &amp; 启动Loki12345678910mkdir -p /app/lokimv loki-linux-amd64.zip promtail-linux-amd64.zip /app/loki# 启动Lokicd /app/lokiunzip loki-linux-amd64.zip -d lokish start.sh# 验证Loki是否正常启动ps -ef | grep loki 日志及索引存储路径：/tmp/loki promtail配置promtail-config.yaml配置注意：需要修改 clients.url为Loki服务的IP和端口 12345678910111213141516171819202122232425server: http_listen_port: 9080 grpc_listen_port: 0positions: filename: /tmp/positions.yamlclients: ## loki.host为Loki服务地址 - url: http://loki.host/loki/api/v1/pushscrape_configs:- job_name: system static_configs: - targets: - localhost labels: ## 系统编码 systemcode: $&#123;SYSTEM_CODE&#125; ## 服务名称 servicename: $&#123;SERVICE_DLE_NAME&#125; ## 实例名称 instance: $&#123;HOSTNAME&#125; ## 采集日志路径 __path__: /app/deploy/logs/*-warn.log 启动脚本123456789#!/bin/bashPROMTAIL_VERSION=promtail-1.0.1-warncd /app/wget http://maven.com/artifactory/maven-releases-local/promtail/$PROMTAIL_VERSION.zipunzip $PROMTAIL_VERSION.zip -d promtailrm $PROMTAIL_VERSION.zipcd promtailchmod 755 promtailnohup ./promtail -config.expand-env=true -config.file=promtail-config.yaml &amp; 其中-config.expand-env=true标识可从环境变量中取值。 脚本自动从Maven仓库(可换为其他地址)拉取zip包并解压，zip包中需包含 promtail、promtail-config.yaml文件 验证启动后进入实例的app目录下查看是否存在Promtail目录。 12# 验证promtail 是否已经正常启动ps -ef | grep promtail","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"安装","slug":"Linux/安装","permalink":"https://mx-go.github.io/categories/Linux/%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"grafana","slug":"grafana","permalink":"https://mx-go.github.io/tags/grafana/"}]},{"title":"Grafana搭建","slug":"Grafana搭建","date":"2020-08-04T02:07:30.000Z","updated":"2022-03-09T11:06:51.887Z","comments":true,"path":"Grafana搭建/","link":"","permalink":"https://mx-go.github.io/Grafana%E6%90%AD%E5%BB%BA/","excerpt":"引言Grafana是一款可视化工具，有着非常漂亮的图表和布局展示，功能齐全的度量仪表盘和图形编辑器，大多使用在时序数据的监控方面。同时提供监控告警功能。","text":"引言Grafana是一款可视化工具，有着非常漂亮的图表和布局展示，功能齐全的度量仪表盘和图形编辑器，大多使用在时序数据的监控方面。同时提供监控告警功能。 简介Grafana是一个跨平台的开源的度量分析和可视化工具，可以通过将采集的数据查询然后可视化的展示，并及时通知。它主要有以下特点： 1、展示方式：快速灵活的客户端图表，面板插件有许多不同方式的可视化指标和日志，官方库中具有丰富的仪表盘插件，比如热图、折线图、图表等多种展示方式； 2、通知提醒：以可视方式定义最重要指标的警报规则，Grafana将不断计算并发送通知，在数据达到阈值时通过Slack、PagerDuty等获得通知； 3、混合展示：在同一图表中混合使用不同的数据源，可以基于每个查询指定数据源，甚至自定义数据源；支持白天和夜间模式； 4、注释：使用来自不同数据源的丰富事件注释图表，将鼠标悬停在事件上会显示完整的事件元数据和标记； 5、过滤器：Ad-hoc过滤器允许动态创建新的键/值过滤器，这些过滤器会自动应用于使用该数据源的所有查询。 准备工作安装包grafana下载地址：https://grafana.com/grafana/download/7.5.3 piechart(图表)下载地址：https://grafana.com/grafana/plugins/grafana-piechart-panel/ 将 grafana.rpm、grafana.ini、grafana-piechart-panel.zip 复制到 Linux 中 移动将所有文件移动至指定目录，便于管理。 12mkdir -p /app/grafanamv grafana-v7.4.2.rpm grafana.ini grafana-piechart-panel-1.6.1.zip /app/grafana 安装grafana安装12cd /app/grafanarpm -Uvh grafana-v7.4.2.rpm 配置grafana配置详解：https://grafana.com/docs/grafana/latest/administration/configuration/ 1cp grafana.ini /etc/grafana grafana.ini文件主要需要关注的配置为 domain = 当前域名 http_port = 80 enable_gzip = true auth.anonymous enabled = false 服务操作命令12345678# 刚安装完需要重载systemd配置systemctl daemon-reload# 启动服务systemctl start grafana-server# 查看状态systemctl status grafana-server#设置开机启动systemctl enable grafana-server.service 12345678910# 重载systemd配置systemctl daemon-reload# 开启systemctl start grafana-server# 停止systemctl stop grafana-server# 重启systemctl restart grafana-server# 查看状态systemctl status grafana-server 相关文件位置 访问地址IP:3000 默认账号密码admin/admin 环境文件/etc/sysconfig/grafana-server 日志文件/var/log/grafana 数据库/var/lib/grafana/grafana.db 配置文件/etc/grafana/grafana.ini 升级Grafana官方提供的升级文档：Upgrading Grafana 下载新版本Grafana 停止旧版本Grafana 执行命令进行升级(兼容性问题请查看官网) 1rpm -Uvh grafana-latest.rpm Pie插件安装Pie插件，可使用饼图展示数据。 123456# 解压unzip -q grafana-piechart-panel-1.6.1.zip# 移动到grafana插件目录下mv grafana-piechart-panel /var/lib/grafana/plugins/# 重启grafanasystemctl restart grafana-server 检查服务启动服务，打开浏览器，输入IP+端口，3000为Grafana的默认侦听端口。","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"安装","slug":"Linux/安装","permalink":"https://mx-go.github.io/categories/Linux/%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"grafana","slug":"grafana","permalink":"https://mx-go.github.io/tags/grafana/"}]},{"title":"Maven依赖冲突","slug":"Maven依赖冲突","date":"2020-06-10T14:04:30.000Z","updated":"2022-01-05T15:42:59.545Z","comments":true,"path":"Maven依赖冲突/","link":"","permalink":"https://mx-go.github.io/Maven%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81/","excerpt":"","text":"在开发中，比较常用的项目构建工具有Maven、Gradle，自动构建工具可以帮助我们管理项目的外部依赖包、项目编译、打包等。而依赖包冲突又是一个不得不面对的问题，所以了解依赖包的关系传递和构建工具对冲突包的版本选择就很重要了，本文主要介绍下Maven依赖冲突的解决方法。 在Maven中，同一个groupId和artifactId只能使用一个版本。 直接依赖若相同类型但版本不同的依赖存在于同一个pom文件，靠后引用的Jar的版本会覆盖前面的版本，最终会引入最后一个声明的依赖。 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;version&gt;2.8.8&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 如上引入依赖的顺序，项目会使用 2.8.8 版本的caffeine 间接依赖依赖传递直接依赖的逻辑比较简单，出现冲突也比较好发现。而项目中比较常见的错误 ClassNotFoundException、NoSuchMethodError往往是因为间接依赖导致的。 依赖传递有两种方式： 模块之间的继承关系。在继承父模块后继承了父模块中的依赖，可通过&lt;/dependencyManagement&gt;机制让子模块可选。 引入包时附带引入其他的依赖包。这种是依赖冲突的常见方式。 A → B → D 1.0 A → D → D 2.0 例如上述依赖关系图，项目A引入了B和C依赖，但是B和C又依赖了不同版本的D。此时Maven只能选择D其中一个版本进行解析，但是会选择哪个版本进行解析就需要分析一下了。 依赖选择Maven依赖调解遵循两大原则：最短路径优先、声明顺序优先。 最短路径优先 如图所示，把当前当成顶层模块，直接依赖的包作为次层模块，依次类推。最后形成一颗依赖树，其中需要比较的就是冲突依赖到顶层模块的路径，Maven会选择路径短的作为依赖。图中会选择 D 1.0 作为依赖。 第一声明顺序优先如果冲突依赖的层次相同，那么第一原则就不起作用了，如下图所示： 当路径相同时，则需要根据A直接依赖包在pom.xml文件中的先后顺序来判定使用哪条依赖路径，如果次级模块相同则向下级模块推，直至可以判断先后位置为止。 12345678910&lt;!-- A pom.xml --&gt;&lt;dependencies&gt; &lt;dependency&gt; B &lt;/dependency&gt; &lt;dependency&gt; C &lt;/dependency&gt;&lt;/dependencies&gt; 假设在A的pom.xml中，B的依赖位置靠前，C在B之后，则Maven最终引入依赖的版本为 D 1.0 解决依赖冲突在IDEA中可以使用Maven Helper插件查看冲突依赖并进行解决。解决依赖冲突的方法，就是使用Maven提供的&lt;exclusion&gt;标签，&lt;exclusion&gt;标签需要放在&lt;exclusions&gt;标签内部。 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;net.minidev&lt;/groupId&gt; &lt;artifactId&gt;accessors-smart&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt;&lt;/dependencies&gt;","categories":[{"name":"组件","slug":"组件","permalink":"https://mx-go.github.io/categories/%E7%BB%84%E4%BB%B6/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"JVM缓存之Caffeine","slug":"JVM缓存之Caffeine","date":"2020-05-17T01:48:52.000Z","updated":"2021-05-09T10:33:51.463Z","comments":true,"path":"JVM缓存之Caffeine/","link":"","permalink":"https://mx-go.github.io/JVM%E7%BC%93%E5%AD%98%E4%B9%8BCaffeine/","excerpt":"引言Caffeine是一个高性能、高命中率、低内存占用的的本地缓存。它是Guava的加强版，Caffeine使用Window TinyLfu (最近最少频率使用)算法，提供了近乎最佳的命中率。","text":"引言Caffeine是一个高性能、高命中率、低内存占用的的本地缓存。它是Guava的加强版，Caffeine使用Window TinyLfu (最近最少频率使用)算法，提供了近乎最佳的命中率。 Caffeine VS Guava CacheSpring5中将放弃Guava Cache作为默认的缓存机制，而改用Caffeine作为本地缓存组件，Spring作出如此大的改变不是没有原因的。在Caffeine的Benchmarks给出了亮眼的数据，对比其他的缓存组件，Caffeine的读写性能都很优异。 Caffeine的使用Caffeine和Guava Cache的api有很多相似之处，熟悉Guava Cache的话上手Caffeine就很简单了。 引入Maven坐标12345&lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;version&gt;$&#123;lasted-version&#125;&lt;/version&gt;&lt;/dependency&gt; 缓存填充策略Caffeine提供了三种缓存填充策略：手动、同步和异步加载。 手动加载每次通过get key的时候可以指定一个同步的函数，当key不存在时调用函数生成value同时将KV存入Cache中。 1234567891011121314151617Cache&lt;String, Object&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .build(); String key = &quot;hello&quot;; // 使用getIfPresent方法，如果缓存中不存在该值，则此方法将返回null Object o = cache.getIfPresent(key); // 使用put方法手动填充缓存 cache.put(key, &quot;world&quot;); // 通过get方法获取值，如果键在缓存中不存在，则此函数将用于提供备用值，该键将在计算后插入到缓存中 cache.get(key, value -&gt; &quot;world&quot;); // 手动使某些缓存的值无效 cache.invalidate(key); get方法优于getIfPresent，因为get方法是原子操作，即使多个线程同时要求该值，计算也只进行一次。 同步加载构造Cache的时候，build方法中传入CacheLoader的实现类，重写load方法，通过key可以加载value。 12345678910111213141516171819202122232425262728293031/** * 方式一 */ public Object syncLoad(String key) &#123; LoadingCache&lt;String, Object&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .build(new CacheLoader&lt;String, Object&gt;() &#123; @Nullable @Override public Object load(@NonNull String key) throws Exception &#123; return key + &quot; world&quot;; &#125; &#125;); return cache.get(key); &#125; /** * 方式二 */ public Object syncLoad1(String key) &#123; LoadingCache&lt;String, Object&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .build(k -&gt; setValue(key).get()); return cache.get(key); &#125; public Supplier&lt;Object&gt; setValue(String key) &#123; return () -&gt; key + &quot; world&quot;; &#125; 异步加载该策略与同步加载策略相同，但是异步执行操作，并返回保存实际值的CompletableFuture。可以调用get或getAll方法调用获取返回值。 123456789101112131415161718192021222324252627282930/** * 方式一 */ public Object asyncLoad(String key) &#123; AsyncLoadingCache&lt;String, Object&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .buildAsync(new AsyncCacheLoader&lt;String, Object&gt;() &#123; @Override public @NonNull CompletableFuture&lt;Object&gt; asyncLoad(@NonNull String key, @NonNull Executor executor) &#123; return CompletableFuture.supplyAsync(() -&gt; key + &quot; world&quot;, executor); &#125; &#125;); return cache.get(key); &#125; /** * 方式二 */ public Object asyncLoad1(String key) &#123; AsyncLoadingCache&lt;String, Object&gt; cache = Caffeine.newBuilder() .expireAfterWrite(1, TimeUnit.MINUTES) .maximumSize(100) .buildAsync(k -&gt; setValue(key).get()); return cache.get(key); &#125; public CompletableFuture&lt;Object&gt; setValue(String key) &#123; return CompletableFuture.supplyAsync(() -&gt; key + &quot; world&quot;); &#125; 驱逐策略Caffeine提供三种数据驱逐策略：基于大小驱逐、基于时间驱逐、基于引用驱逐。 基于大小(Size-Based)的驱逐策略基于大小的驱逐策略有两种方式：一种是基于缓存数量，一种是基于权重。maximumSize与maximumWeight不可同时使用。 123456789101112public void sizeBasedEviction() &#123; // 根据缓存的数量进行驱逐 LoadingCache&lt;String, Object&gt; cache = Caffeine.newBuilder() .maximumSize(10000) .build(key -&gt; function(key)); // 根据缓存的权重来进行驱逐（权重只是用于确定缓存大小，不会用于决定该缓存是否被驱逐） LoadingCache&lt;String, Object&gt; cache1 = Caffeine.newBuilder() .maximumWeight(10000) .weigher(key -&gt; function1(key)) .build(key -&gt; function(key)); &#125; 基于时间(Time-Based)的驱逐策略基于时间的驱逐策略有三种类型： **expireAfterAccess(long, TimeUnit)**：在最后一次访问或者写入后开始计时，在指定的时间后过期。假如一直有请求访问该key，那么这个缓存将一直不会过期。 expireAfterWrite(long, TimeUnit): 在最后一次写入缓存后开始计时，在指定的时间后过期。 expireAfter(Expiry): 自定义策略，过期时间由Expiry实现独自计算。 缓存的删除策略使用的是惰性删除和定时删除。 12345678910111213141516171819202122232425262728public void timeBasedEviction() &#123; // 基于固定的到期策略进行退出 LoadingCache&lt;String, Object&gt; cache = Caffeine.newBuilder() .expireAfterAccess(5, TimeUnit.MINUTES) .build(key -&gt; function(key)); LoadingCache&lt;String, Object&gt; cache1 = Caffeine.newBuilder() .expireAfterWrite(10, TimeUnit.MINUTES) .build(key -&gt; function(key)); // 基于不同的到期策略进行退出 LoadingCache&lt;String, Object&gt; cache2 = Caffeine.newBuilder() .expireAfter(new Expiry&lt;String, Object&gt;() &#123; @Override public long expireAfterCreate(String key, Object value, long currentTime) &#123; return TimeUnit.SECONDS.toNanos(seconds); &#125; @Override public long expireAfterUpdate(@Nonnull String s, @Nonnull Object o, long l, long l1) &#123; return 0; &#125; @Override public long expireAfterRead(@Nonnull String s, @Nonnull Object o, long l, long l1) &#123; return 0; &#125; &#125;).build(key -&gt; function(key)); &#125; 基于引用(Reference-Based)的驱逐Java中四种引用类型： 引用类型 被垃圾回收时间 用途 生存时间 强引用 Strong Reference 从来不会 对象的一般状态 JVM停止运行时终止 软引用 Soft Reference 在内存不足时 对象缓存 内存不足时终止 弱引用 Weak Reference 在垃圾回收时 对象缓存 gc运行后终止 虚引用 Phantom Reference 从来不会 可以用虚引用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知 JVM停止运行时终止 123456789101112public void referenceBasedEviction() &#123; // 当key和value都没有弱引用时驱逐缓存 LoadingCache&lt;String, Object&gt; cache = Caffeine.newBuilder() .weakKeys() .weakValues() .build(key -&gt; function(key)); // 当垃圾收集器需要释放内存时驱逐 LoadingCache&lt;String, Object&gt; cache1 = Caffeine.newBuilder() .softValues() .build(key -&gt; function(key)); &#125; 注意： AsyncLoadingCache不支持弱引用和软引用。 Caffeine.weakValues()和Caffeine.softValues()不可以一起使用。 移除事件监听123456public void removalListener() &#123; Cache&lt;String, Object&gt; cache = Caffeine.newBuilder() .removalListener((String key, Object value, RemovalCause cause) -&gt; System.out.printf(&quot;Key %s was removed (%s)%n&quot;, key, cause)) .build(); &#125; 刷新可以将缓存配置为在自定义的时间段后自动刷新数据： 123456public void refresh() &#123; Cache&lt;String, Object&gt; cache = Caffeine.newBuilder() .maximumSize(10000) .refreshAfterWrite(1, TimeUnit.MINUTES) .build(); &#125; expireAfter和refreshAfter之间的区别： expireAfter：当请求过期的数据时，请求将会被阻塞，直到build Function将计算出新值为止。 refreshAfter：当数据符合刷新条件，则缓存将返回一个旧值，并异步重新加载该值。 统计123456789101112public void stats() &#123; Cache&lt;String, Object&gt; cache = Caffeine.newBuilder() .maximumSize(10000) .recordStats() .build(); // 缓存命中率 cache.stats().hitRate(); // 回收数量 cache.stats().evictionCount(); // 加载新值的平均时间 cache.stats().averageLoadPenalty(); &#125; 通过使用**Caffeine.recordStats()可以转化成一个统计的集合. 通过Cache.stats()**返回一个CacheStats。CacheStats提供以下统计方法： hitRate : 返回缓存命中率 evictionCount: 缓存回收数量 averageLoadPenalty: 加载新值的平均时间","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"cache","slug":"cache","permalink":"https://mx-go.github.io/tags/cache/"}]},{"title":"网址收藏","slug":"网址收藏","date":"2020-03-05T13:38:30.000Z","updated":"2022-03-10T14:40:04.868Z","comments":true,"path":"网址收藏/","link":"","permalink":"https://mx-go.github.io/%E7%BD%91%E5%9D%80%E6%94%B6%E8%97%8F/","excerpt":"","text":"开发类 名称 地址 Jetbrains系列产品重置试用方法 https://zhile.io/2021/11/29/ja-netfilter-javaagent-lib.html 手册类 名称 地址 Elasticsearch中文文档 https://doc.codingdict.com/elasticsearch/323/ Elasticsearch中文文档 https://learnku.com/docs/elasticsearch73/7.3","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[]},{"title":"Spring之循环依赖","slug":"Spring之循环依赖","date":"2020-03-05T08:21:32.000Z","updated":"2022-02-16T00:50:58.091Z","comments":true,"path":"Spring之循环依赖/","link":"","permalink":"https://mx-go.github.io/Spring%E4%B9%8B%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96/","excerpt":"引言在Spring框架中，针对Bean之间的循环依赖，Spring通过三级缓存的机制已经解决和规避了部分场景Bean的循环依赖。但是仍需了解Spring解决循环依赖的原理和注意Spring无法解决循环依赖的场景，避免出现此类问题。","text":"引言在Spring框架中，针对Bean之间的循环依赖，Spring通过三级缓存的机制已经解决和规避了部分场景Bean的循环依赖。但是仍需了解Spring解决循环依赖的原理和注意Spring无法解决循环依赖的场景，避免出现此类问题。 循环依赖示例12345678910111213@Servicepublic class AServiceImpl implements AService &#123; @Autowired private BService bService;&#125;@Servicepublic class BServiceImpl implements BService&#123; @Autowired private AService aService;&#125; 这个例子是非常经典的Spring Bean循环依赖的场景，在这种循环依赖场景，Spring已经帮我们解决了循环依赖的问题，所以服务可以正常启动和运行。 Spring循环依赖的场景构造器注入12345678910111213141516171819@Servicepublic class AServiceImpl implements AService &#123; private BService bService; public AServiceImpl(BService bService) &#123; this.bService = bService; &#125;&#125;@Servicepublic class BServiceImpl implements BService &#123; private AService aService; public BServiceImpl(AService aService) &#123; this.aService = aService; &#125;&#125; 结果：项目启动失败并抛出BeanCurrentlyInCreationException异常。 12345Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#x27;AServiceImpl&#x27;: Requested bean is currently in creation: Is there an unresolvable circular reference? at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.beforeSingletonCreation(DefaultSingletonBeanRegistry.java:347) at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223) at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:308) at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) 构造器注入无法解决循环依赖问题，Spring只能抛出BeanCurrentlyInCreationException依赖表示循环依赖。 Spring解决循环依赖是依靠Bean的“中间态“的概念，”中间态“是指Bean已经实例化，但还没有初始化的状态，而构造器注入的是初始化后的对象，所以不能解决循环依赖。 Spring解决循环依赖的理论依据基于Java的引用传递，当获得对象的引用时，对象的属性是可以延后设置的。但是构造器必须是在获取引用之前，毕竟引用是靠构造器生成的。 注解注入(field属性注入)这个是最常见的注入方式，通过@Autowired或@Resource注入。 12345678910111213@Servicepublic class AServiceImpl implements AService &#123; @Autowired private BService bService;&#125;@Servicepublic class BServiceImpl implements BService&#123; @Autowired private AService aService;&#125; 项目可以正常启动，说明循环依赖被解决。 prototype field属性注入123456789101112131415@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)@Servicepublic class AServiceImpl implements AService &#123; @Autowired private BService bService;&#125;@Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE)@Servicepublic class BServiceImpl implements BService&#123; @Autowired private AService aService;&#125; 启动没有报错，因为非单例的Bean默认不会初始化，只有在第一次使用时才会初始化。需要手动调用getBean()或者在一个单例Bean内@Autowired就可以触发初始化。此时同样会抛出异常： 12345Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#x27;AServiceImpl&#x27;: Unsatisfied dependency expressed through field &#x27;bService&#x27;; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#x27;BServiceImpl&#x27;: Unsatisfied dependency expressed through field &#x27;aService&#x27;; nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#x27;AServiceImpl&#x27;: Requested bean is currently in creation: Is there an unresolvable circular reference? at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:586) at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:87) at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:364) at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1269) 对于prototype作用域的bean, Spring容器无法完成依赖注入，因为Spring 容器不进行缓存prototype作用域的bean ，因此无法提前暴露一个创建中的bean。 网上有的说法是使用@Lazy注解解决。这样做启动确实不报错了，但是实际这样是解决不了问题的，@Lazy只是延迟初始化，当真正使用到的时候还是会报异常。 123@Autowired@Lazyprivate AService aService; 总结可解决循环依赖场景 注解注入(field属性)注入循环依赖 setter注入 无法解决循环依赖场景 构造器注入循环依赖 prototype field属性注入循环依赖 Spring解决循环依赖原理Spring创建单例Bean流程可以简化如下图： 其中比较核心的方法为： createBeanInstance：实例化，其实是调用对象的构造方法实例化对象。 populateBean：填充Bean属性，主要对Bean的依赖属性进行注入(@Autowired、@Resource) 其中Spring解决循环依赖主要发生在populateBean这一步。 Spring容器的”三级缓存“在Spring容器中大量使用了缓存来加速访问，其中单例Bean也利用了这种手段。其中Spring采用了”三级缓存“来解决循环依赖问题。 123456789101112131415161718192021222324252627282930313233public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; /** 一级缓存 */ /** * Cache of singleton objects: bean name --&gt; bean instance */ private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256); /** 二级缓存 */ /** * Cache of early singleton objects: bean name --&gt; bean instance */ private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16); /** 三级缓存 */ /** * Cache of singleton factories: bean name --&gt; ObjectFactory */ private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16); /** 正在创建中的Bean。Bean开始创建时存入,创建完成时移除。 */ /** * Names of beans that are currently in creation */ private final Set&lt;String&gt; singletonsCurrentlyInCreation = Collections.newSetFromMap(new ConcurrentHashMap&lt;String, Boolean&gt;(16)); /** 创建完成的Bean集合 */ /** * Set of registered singletons, containing the bean names in registration order */ private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;String&gt;(256);&#125; AbstractBeanFactory继承自DefaultSingletonBeanRegistry singletonObjects(一级缓存)：存放完全初始化好的Bean，从该缓存中取出的bean可以直接使用。 earlySingletonObjects(二级缓存)：提前曝光的单例对象的cache，存放原始的Bean对象(已实例化，尚未初始化)，用于解决循环依赖。 singletonFactories(三级缓存)：单例对象工厂的cache，存放Bean工厂对象，用于解决循环依赖。 获取单例Bean的流程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; // ... @Override @Nullable public Object getSingleton(String beanName) &#123; return getSingleton(beanName, true); &#125; /** * 1.从一级缓存singletonObjects中去获取(如果获取到就直接return) * &lt;p&gt; * 2.如果获取不到或者对象正在创建中(isSingletonCurrentlyInCreation(), * 那就再从二级缓存earlySingletonObjects中获取(如果获取到就直接return） * &lt;p&gt; * 3.如果还是获取不到,且允许singletonFactories(allowEarlyReference=true)通过getObject()获取。 * 就从三级缓存singletonFactory.getObject()获取。如果获取到了就从singletonFactories中移除，并且放进earlySingletonObjects。 */ @Nullable protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); // 检查一级缓存中是否存在实例。isSingletonCurrentlyInCreation判断该实例是否在创建中 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; // 如果缓存中实例为null，则锁定全局变量singletonObjects并进行处理 synchronized (this.singletonObjects) &#123; // 尝试从二级缓存earlySingletonObjects(创建中提早曝光的beanFactory) 获取bean singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; // 尝试从三级缓存singletonFactories获取beanFactory ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; // 返回获取到的bean singletonObject = singletonFactory.getObject(); // 增加二级缓存 this.earlySingletonObjects.put(beanName, singletonObject); // 删除三级缓存 this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return singletonObject; &#125; /** * Bean是否正在创建中 */ public boolean isSingletonCurrentlyInCreation(String beanName) &#123; return this.singletonsCurrentlyInCreation.contains(beanName); &#125; // ...&#125; Spring利用singletonFactories这个三级缓存将创建对象的步骤封装到ObjectFactory中，交给自定义的Scope来选择是否需要创建对象来灵活的实现scope。 经过ObjectFactory.getObject()后，此时放进了二级缓存earlySingletonObjects内。这个时候对象已经实例化了，虽然还没有初始化完成，但该对象已经可以被其它对象引用了。 123456789101112131415161718192021222324252627282930313233343536373839public class DefaultSingletonBeanRegistry extends SimpleAliasRegistry implements SingletonBeanRegistry &#123; // ... public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; // 加锁，全局变量需要同步 synchronized (this.singletonObjects) &#123; // 查看单例bean是否已经创建 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; // ... // 调用getObject方法创建bean实例 singletonObject = singletonFactory.getObject(); newSingleton = true; // ... if (newSingleton) &#123; addSingleton(beanName, singletonObject); &#125; &#125; return singletonObject; &#125; &#125; protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; // 添加一级缓存 this.singletonObjects.put(beanName, singletonObject); // 移除二三级缓存 this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; // ...&#125; 创建Bean可以简单分为三个流程： 创建原始bean实例 → createBeanInstance(beanName, mbd, args) 添加原始对象工厂对象到 singletonFactories 缓存中 → addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;&#123;...&#125;) 填充属性，解析依赖 → populateBean(beanName, mbd, instanceWrapper) 1234567891011121314151617181920212223242526272829303132333435363738394041424344public abstract class AbstractAutowireCapableBeanFactory extends AbstractBeanFactory implements AutowireCapableBeanFactory &#123; // ... protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; // 创建bean对象，并将bean对象包裹在 eanWrapper对象中返回 instanceWrapper = createBeanInstance(beanName, mbd, args); // 是否需要提前暴露。单例&amp;允许循环依赖&amp;当前bean正在创建中。 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; // 在bean未实例化之前加入到三级缓存singletonFactories中 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; Object exposedObject = bean; // 对bean进行填充，属性注入，bean依赖 populateBean(beanName, mbd, instanceWrapper); // 调用相关初始化方法 exposedObject = initializeBean(beanName, exposedObject, mbd); // ... return exposedObject; &#125; protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; synchronized (this.singletonObjects) &#123; // 将singletonFactory添加到singletonFactories缓存中 if (!this.singletonObjects.containsKey(beanName)) &#123; this.singletonFactories.put(beanName, singletonFactory); this.earlySingletonObjects.remove(beanName); this.registeredSingletons.add(beanName); &#125; &#125; &#125; // ...&#125; 总结Spring通过三级缓存可以解决部分场景下Bean循环依赖的问题，但是不能解决 1)构造器注入; 2)非单例Bean的循环依赖的问题。 Spring解决循环依赖的流程可以简化如下图所示： 以A、B类使用注解注入为例，对整个流程描述如下： 获取A：调用getBean(beanA)，获取容器内的单例A对象，但此时容器内不存在A的实例，即走创建A的流程。 实例化A(createBeanInstance)：此处仅仅是实例化，并将A放入三级缓存singletonFactories中(此时A已实例化完成，可以被引用)。 初始化A(populateBean)：@Autowired依赖注入B(需要到容器内获取B)。 获取B：为了完成依赖注入B，会通过getBean(B)去容器内寻找B。但此时B在容器内不存在，即走B的创建流程。 实例化B(createBeanInstance)：并将其放入三级缓存singletonFactories中(此时B也能够被引用)。 初始化B(populateBean)：@Autowired依赖注入A(此时需要去容器内获取A) 重要流程：初始化B时会调用getBean(A)去容器内寻找A，而此时候A已经实例化完成了并且在三级缓存中，此时可以通过A的ObjectFactory Bean工厂创建A对象，所以getBean(A)能够正常返回。 B初始化成功：此时B已经注入A成功，已成功持有A的引用了。return(此处return相当于返回最上面的getBean(B)这句代码，回到了初始化A的流程中)。 A初始化成功：因为B实例已经成功返回了，因此最终A也初始化成功。 结束：此时，B持有的已经是初始化完成的A，A持有的也是初始化完成的B。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"Linux中的零拷贝技术","slug":"Linux中的零拷贝技术","date":"2020-02-10T04:02:58.000Z","updated":"2022-01-17T10:40:40.023Z","comments":true,"path":"Linux中的零拷贝技术/","link":"","permalink":"https://mx-go.github.io/Linux%E4%B8%AD%E7%9A%84%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%8A%80%E6%9C%AF/","excerpt":"引言零拷贝(Zero-Copy)技术指在计算机执行操作时，CPU不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及CPU的拷贝时间。作用是在数据从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现CPU的零参与，消除CPU在这方面的负载。","text":"引言零拷贝(Zero-Copy)技术指在计算机执行操作时，CPU不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及CPU的拷贝时间。作用是在数据从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现CPU的零参与，消除CPU在这方面的负载。 零拷贝思想零拷贝是一个通过尽量避免拷贝操作来缓解CPU压力的解决方案。Linux下常见的零拷贝技术可以分为两大类：一是针对特定场景，去掉不必要的拷贝；二是去优化整个拷贝的过程。零拷贝并没有真正做到“0”拷贝，它更多是一种思想，很多的零拷贝技术都是基于这个思想去做的优化。 原始数据拷贝 传统数据拷贝产生了四次数据拷贝，即使使用了DMA(Direct Memory Access)处理了硬件的通讯，CPU仍然需要处理两次数据拷贝。同时，CPU在用户态和内核态也发生了多次上下文切换，增加了CPU的负担。在此过程中，如果没有对数据做任何修改，那么在内核态和用户态间来回拷贝数据就是一种浪费。 零拷贝的几种方法用户态直接IO 对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，但是硬件上的数据不会拷贝一份到内核空间，而是直接拷贝至了用户空间，因此直接I/O不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。 缺陷 只能适用于那些不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统。 这种方法直接操作磁盘I/O，由于CPU和磁盘I/O之间的执行时间差距，会造成资源的浪费，解决这个问题需要和异步I/O结合使用。 mmap这种方法，使用mmap来代替 read，可以减少一次拷贝操作。 12buf = mmap(diskfd, len);write(sockfd, buf, len); 过程 应用进程调用了mmap()之后，数据会先通过DMA拷贝到操作系统内核缓冲区中。接着应用进程跟操作系统共享这个缓冲区。这样，操作系统内核和应用进程空间就不需要再进行任何的数据拷贝操作。 应用进程调用write()，操作系统直接将内核缓冲区的数据拷贝到Socket缓冲区中，这一切都发生在内核态。 Socket缓冲区把数据发到网卡。 缺陷mmap隐藏着一个陷阱，当mmap一个文件时，如果这个文件被另一个进程所截获，那么write系统调用会因为访问非法地址被SIGBUS信号终止，SIGBUS 默认会杀死进程并产生一个coredump，如果服务器被这样终止了，那损失就可能不小了。 解决这个问题通常使用文件的租借锁：首先为文件申请一个租借锁，当其他进程想要截断这个文件时，内核会发送一个实时的RT_SIGNAL_LEASE信号，告诉当前进程有进程在试图破坏文件，这样write在被SIGBUS 杀死之前，会被中断，返回已经写入的字节数，并设置errno为success。 通常的做法是在 mmap 之前加锁，操作完之后解锁。 kafka中Producer到Broker的网络数据接收，应用进程不需要中间处理、直接进行持久化时。使用了mmap内存文件映射。 sendfile为了简化用户接口，同时减少CPU的拷贝次数，Linux 在版本 2.1 中引入了sendfile()系统调用。 过程 sendfile()系统调用利用DMA引擎将文件中的数据拷贝到操作系统内核缓冲区中。 然后数据被拷贝到与Socket相关的内核缓冲区中去。 接下来，DMA引擎将数据从内核Socket缓冲区中拷贝到协议引擎中去。 sendfile() 系统调用不需要将数据拷贝或者映射到应用程序地址空间中去，所以sendfile()只是适用于应用程序地址空间不需要对所访问数据进行处理的情况。相对于mmap()方法来说，因为sendfile传输的数据没有越过用户应用程序/操作系统内核的边界线，所以sendfile()也极大地减少了存储管理的开销。 缺陷 只能适用于那些不需要用户态处理的应用程序。 DMA辅助的sendfile常规sendfile还有一次内核态的拷贝操作，使用DMA辅助的sendfile可以把这次拷贝操作消除。 过程 用户进程通过sendfile()函数向内核(kernel)发起系统调用，上下文从用户态(user space)切换为内核态(kernel space)； CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间(kernel space)的读缓冲区(read buffer)； CPU把读缓冲区(read buffer)的文件描述符(file descriptor)和数据长度拷贝到网络缓冲区(socket buffer)； 基于已拷贝的文件描述符(file descriptor)和数据长度，CPU利用DMA控制器的gather/scatter操作直接批量地将数据从内核的读缓冲区(read buffer)拷贝到网卡进行数据传输； 上下文从内核态(kernel space)切换回用户态(user space)，Sendfile系统调用执行返回； 这种方法借助硬件的帮助，在数据从内核缓冲区到Socket缓冲区这一步操作上，并不是拷贝数据，而是拷贝缓冲区文件描述符(fd)和数据长度。完成后，DMA引擎直接将数据从内核缓冲区拷贝到协议引擎中去，避免了最后一次拷贝。 例如kafka中Broker到Consumer的网络数据发送。 缺陷 同样适用于那些不需要用户态处理的应用程序。还需要硬件以及驱动程序支持。 只适用于将数据从文件拷贝到套接字上。 splicesplice去掉sendfile的使用范围限制，可以用于任意两个文件描述符中传输数据。 过程 用户进程通过splice()函数向内核(kernel)发起系统调用，上下文从用户态(user space)切换为内核态(kernel space)； CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间(kernel space)的读缓冲区(read buffer)； CPU在内核空间的读缓冲区(read buffer)和网络缓冲区(socket buffer)之间建立管道(pipeline)； CPU利用DMA控制器将数据从网络缓冲区(socket buffer)拷贝到网卡进行数据传输； 上下文从内核态(kernel space)切换回用户态(user space)，splice系统调用执行返回； 但是splice也有局限，它使用了Linux的管道缓冲机制，所以，它的两个文件描述符参数中至少有一个必须是管道设备。 缺陷 同样只适用于不需要用户态处理的程序。 传输描述符至少有一个是管道设备。 Java应用Java NIO的FileChannel.transferFrom()、FileChannel.transferTo()底层基于sendfile/splice，不仅可以进行网络文件传输，还可以对本地文件实现零拷贝操作。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"基础","slug":"Linux/基础","permalink":"https://mx-go.github.io/categories/Linux/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Bug简记-长轮训Response","slug":"Bug简记-长轮训Response","date":"2020-01-05T14:29:36.000Z","updated":"2021-05-09T10:33:22.174Z","comments":true,"path":"Bug简记-长轮训Response/","link":"","permalink":"https://mx-go.github.io/Bug%E7%AE%80%E8%AE%B0-%E9%95%BF%E8%BD%AE%E8%AE%ADResponse/","excerpt":"客服系统服务中使用Servlet3.0异步长轮训，服务压力大时，导致消息错乱。","text":"客服系统服务中使用Servlet3.0异步长轮训，服务压力大时，导致消息错乱。 描述对Servlet请求应答对象的生命周期理解不够深入，IM服务在服务压力大，并且Nginx断开请求回收资源后，依然将用户消息进行下发，最后导致消息下发到其他请求中。 原因分析错误代码伪代码服务使用异步的Servlet方法进行长轮训 123456789101112131415161718192021@WebServlet(asyncSupported = true)public class CometServlet extends HttpServlet &#123; @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //启动异步请求 AsyncContext context = request.startAsync(); //设置超时 context.setTimeout(TIMEOUT); //异步执行 context.start(() -&gt; &#123; //这行只是伪代码，具体为业务逻辑 Thread.sleep(27 * 1000); //下发应答。如果接收到消息这返回应答 response.getWriter().write(...); context.complete(); &#125;); &#125;&#125; 问题描述 如果发生超时或者Nginx因为某些原因频繁断开与Tomcat之间的连接，Request以及Response对象会被Tomcat发现并且执行清理。 如果清理只是销毁对象的话也还不会导致问题，但查看源码发现，Tomcat是把对象回收，交给下一个请求使用。当Tomcat回收Repsonse对象，交给下一个请求使用后，回调函数依然会继续执行，Response虽然是同一个对象，但已经是其他请求正在使用的了，继续往里面下发消息则导致了整个事件的发生。 问题分析而在Tomcat提供的AsyncContext里面会感知到连接异常，并且提供清理操作，以下是AsyncContextImpl源码节选。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class AsyncContextImpl implements AsyncContext, AsyncContextCallback &#123; private volatile ServletRequest servletRequest = null; private volatile ServletResponse servletResponse = null; //启动异步时，保存request以及response对象 public void setStarted(Context context, ServletRequest request, ServletResponse response, boolean originalRequestResponse) &#123; ... this.servletRequest = request; this.servletResponse = response; ... &#125; //连接异常、超时等情况，会对这个AsyncContext的资源进行清理 public void recycle() &#123; if (log.isDebugEnabled()) &#123; logDebug(&quot;recycle &quot;); &#125; context = null; dispatch = null; event = null; hasOriginalRequestAndResponse = true; instanceManager = null; listeners.clear(); request = null; clearServletRequestResponse(); timeout = -1; &#125; //清理request以及response对象以免外部调用 private void clearServletRequestResponse() &#123; servletRequest = null; servletResponse = null; &#125; //检查状态机状态，如果不处于正常状态，则抛出异常 private void check() &#123; if (request == null) &#123; // AsyncContext has been recycled and should not be being used throw new IllegalStateException(sm.getString(&quot;asyncContextImpl.requestEnded&quot;)); &#125; &#125; @Override //每次获取request以及response对象，都检查请求以及应答对象是否已经被回收 public ServletRequest getRequest() &#123; check(); if (servletRequest == null) &#123; throw new IllegalStateException(sm.getString(&quot;asyncContextImpl.request.ise&quot;)); &#125; return servletRequest; &#125; @Override //每次获取request以及response对象，都检查请求以及应答对象是否已经被回收 public ServletResponse getResponse() &#123; check(); if (servletResponse == null) &#123; throw new IllegalStateException(sm.getString(&quot;asyncContextImpl.response.ise&quot;)); &#125; return servletResponse; &#125;&#125; 结果及处理以上源码分析可以看到，Tomcat的AsyncContext针对连接断开、超时等情况是有做特殊保护处理的，而IM服务所用的方式并没有用上Tomcat的保护，直接将应答对象写入了错误的应答。 正确的使用方式很简单： **只需要把response.getWriter().write(…); ** 修改为context.getResponse().getWriter().write(…)即可，就是这么一行代码，导致了整个事件的发生。 另外，使用Spring提供的DeferredResult已完全封装了异步请求，可避免此问题。","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"RocketMQ(三)—消息幂等","slug":"RocketMQ-三-—消息幂等","date":"2019-11-12T08:33:29.000Z","updated":"2021-05-09T02:22:36.759Z","comments":true,"path":"RocketMQ-三-—消息幂等/","link":"","permalink":"https://mx-go.github.io/RocketMQ-%E4%B8%89-%E2%80%94%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89/","excerpt":"","text":"引言在MQ中，Producer和Consumer因为各种原因会进行消息重试处理，在消费消息时，会按照一定规则推送消息到消费端进行消息消费。既然有重试，那么就少不了幂等。 幂等概念在消息重试多次时，消费端对该重复消息消费多次与消费一次的结果是相同的，并且多次消费没有对系统产生副作用，那么就称这个过程是消息幂等的。 例如：支付场景下，消费者消费扣款消息，对一笔订单进行扣款操作，该扣款操作需要扣除10元。 这个扣款操作重复多次与执行一次的效果相同，只进行一次真实扣款，用户的扣款记录中对应该笔订单的只有一条扣款流水。不会多扣。那么可以说这个扣款操作是符合要求的，这个消费过程是消息幂等的。 消息幂等的场景Producer发送消息重复​ 生产者发送消息时，消息成功投递到broker，但此时发生网络闪断或者生产者down掉，导致broker发送ACK失败。此时生产者由于未能收到消息发送响应，认为发送失败，因此尝试重新发送消息到broker。当消息发送成功后，在broker中就会存在两条相同内容的消息，最终消费者会拉取到两条内容一样并且Message ID也相同的消息，因此造成了消息的重复。 Consumer消费时重复​ 消费消息时同样会出现重复消费的情况。当消费者在处理业务完成返回消费状态给broker时，由于网络闪断等异常情况导致未能将消费完成的CONSUME_SUCCESS状态返回给broker。broker为了保证消息被至少消费一次的语义，会在网络环境恢复之后再次投递该条被处理的消息，最终造成消费者多次收到内容一样并且Message ID也相同的消息，造成了消息的重复。 所以，无论是发送时重复还是消费时重复，最终的效果均为消费者消费时收到了重复的消息，可以推论出：只需要在消费者端统一进行幂等处理就能够实现消息幂等。 实现幂等方式消息幂等两要素 幂等令牌 处理唯一性的确保 必须保证存在幂等令牌的情况下保证业务处理结果的唯一性，才认为幂等实现是成功的。 幂等令牌幂等令牌是生产者和消费者两者中的既定协议，在业务中通常是具备唯一业务标识的字符串，如：订单号、流水号等。且一般由生产者端生成并传递给消费者端。 处理唯一性的确保服务端应当采用一定的策略保证同一个业务逻辑一定不会重复执行成功多次。如：使用支付宝进行支付，买一个产品支付多次只会成功一笔。较为常用的方式是采用缓存去重并且通过对业务标识添加数据库的唯一索引实现幂等。 具体的思路为：如支付场景下，支付的发起端生成了一个支付流水号，服务端处理该支付请求成功后，数据持久化成功。由于表中对支付流水添加了唯一索引，因此当重复支付时会因为唯一索引的存在报错 duplicate entry，服务端的业务逻辑捕获该异常并返回调用侧“重复支付”提示。这样就不会重复扣款。 在上面场景的基础上，还可以引入Redis等缓存组件实现去重：当支付请求打到服务端，首先去缓存进行判断，根据 key=“支付流水号” 去get存储的值，如果返回为空，表明是首次进行支付操作同时将当前的支付流水号作为key、value可以为任意字符串通过set(key, value, expireTime)存储在redis中。当重复的支付请求到来时，尝试进行*get(支付流水号)*操作，这个操作会命中缓存，因此可以认为该请求是重复的支付请求，服务端业务将重复支付的业务提示返回给请求方。 由于一般都会在缓存使用过程中设置过期时间，缓存可能会失效从而导致请求穿透到持久化存储中(如：MySQL)。因此不能因为引入缓存而放弃使用唯一索引，将二者结合在一起是一个比较好的方案。 RocketMQ下的消息幂等RocketMQ作为一款高性能的消息中间件，能够保证消息不丢失但是不能保证消息不重复。 如果RMQ实现消息去重其实也是可以的，但是考虑到对高可用以及高性能的影响就放弃了。如果RMQ做服务端消息去重，就要对消息做额外的rehash、排序等操作，这会花费较大的空间及时间等代价，收益并不明显。所以RMQ就将消息幂等交给了业务方处理。 在RMQ中，每条消息都会有一个MessageID，那么能否用该ID作为去重依据，也就是幂等令牌呢？ 答案是否定的，因为MessageID可能会出现冲突的情况，因此不建议通过MessageID作为处理依据，应该使用业务唯一标识如：订单号、流水号等作为幂等处理的关键依据。 幂等令牌由消息生产者生成，在发消息消息时，可以通过消息的key设值为该id。对应API为org.apache.rocketmq.common.message.setKeys(String keys) 12Message sendMessage = new Message(&quot;topic&quot;, message.getBytes());sendMessage.setKeys(&quot;OD0000000001&quot;); 当消息消费者收到该消息时，根据该消息的key做幂等处理，API为 org.apache.rocketmq.common.message.getKeys() 。代码如下： 12345678910111213(msgs, context) -&gt; &#123; try &#123; // 默认msgs只有一条消息 for (MessageExt msg : msgs) &#123; String key = msg.getKeys(); return walletCharge(msg); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; catch (Exception e) &#123; LOGGER.error(&quot;钱包扣款消费异常。&quot;, e); return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125;&#125; 消费者通过getKeys()能够读取到生产者设置的幂等依据(如：订单号)，然后业务逻辑围绕该id进行幂等处理即可。 如果觉得每次都需要在生产者侧setkey，在消费者侧getkey有点繁琐。也可以将该幂等依据设置在消息协议中，消费者接收到消息后解析该id进行幂等操作。只需要消息的生产者和消费者约定好如何解析id的协议即可。 消费端常见的幂等操作业务操作前状态查询消费端开始执行业务操作时，通过幂等id首先进行业务状态的查询，如：修改订单状态环节，当订单状态为成功/失败则不需要再进行处理。那么只需要在消费逻辑执行之前通过订单号进行订单状态查询，一旦获取到确定的订单状态则对消息进行提交，通知broker消息状态为：ConsumeConcurrentlyStatus.CONSUME_SUCCESS 。 业务操作前数据检索逻辑与第一点相似，即消费之前进行数据的检索。如果能够通过业务唯一id查询到对应的数据则不需要进行再后续的业务逻辑。如：下单环节中，在消费者执行异步下单之前首先通过订单号查询订单是否已经存在，这里可以查库也可以查缓存。如果存在则直接返回消费成功，否则进行下单操作。 唯一性约束保证最后一道防线上述第二点操作并不能保证一定不出现重复的数据。如：并发插入的场景下，如果没有乐观锁、分布式锁作为保证的前提下，很有可能出现数据的重复插入，因此务必要对幂等id添加唯一性索引，这样就能够保证在并发场景下也能保证数据的唯一性。 锁机制上述的第一点中，如果是并发更新的情况，没有使用悲观锁、乐观锁、分布式锁等机制的前提下，进行更新，很可能会出现多次更新导致状态的不准确。如：对订单状态的更新，业务要求订单只能从初始化-&gt;处理中，处理中-&gt;成功，处理中-&gt;失败，不允许跨状态更新。如果没有锁机制，很可能会将初始化的订单更新为成功，成功订单更新为失败等异常的情况。高并发下，建议通过状态机的方式定义好业务状态的变迁，通过乐观锁、分布式锁机制保证多次更新的结果是确定的，悲观锁在并发环境不利于业务吞吐量的提高因此不建议使用。 消息记录表这种方案和业务层做的幂等操作类似，由于消息id是唯一的，可以借助该id进行消息的去重操作，间接实现消费的幂等。首先准备一个消息记录表，在消费成功的同时插入一条已经处理成功的消息id记录到该表中，注意一定要与业务操作处于同一个事务中，当新的消息到达的时候，根据新消息的id在该表中查询是否已经存在该id，如果存在则表明消息已经被消费过，那么丢弃该消息不再进行业务操作即可。 总结肯定还有更多的场景没有涉及到，这里说到的操作均是互相之间有关联的，将他们配合使用更能够保证消费业务的幂等性。 不论怎样，一定要牢记一个原则：缓存是不可靠的，查询是不可靠的 。 在高并发的场景下，一定要通过持久化存储的唯一索引以及引入锁机制作为共同保障数据准确性和完整性的最后一道防线！ 参考[跟我学RocketMQ之消息幂等]","categories":[{"name":"中间件","slug":"中间件","permalink":"https://mx-go.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://mx-go.github.io/tags/RocketMQ/"}]},{"title":"Javascript Number类型长度溢出","slug":"Javascript-Number类型长度溢出","date":"2019-09-19T02:36:39.000Z","updated":"2021-05-10T00:57:13.993Z","comments":true,"path":"Javascript-Number类型长度溢出/","link":"","permalink":"https://mx-go.github.io/Javascript-Number%E7%B1%BB%E5%9E%8B%E9%95%BF%E5%BA%A6%E6%BA%A2%E5%87%BA/","excerpt":"","text":"引言项目中遇到一个问题，由于后台数据库表ID使用分布式唯一算法生成的Long类型(19位数字)，导致转成json传至前端js使用时报错，因为js的数字类型最大只能表示15位数字长度【JavaScript Number 对象】。 解决方案：使用Spring自定义Json序列化方式，将过长的Long类型转成String类型。 默认序列化配置默认序列化方式会将Long类型不做转换，直接传递给前端。 1234567891011121314151617&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;constructor-arg ref=&quot;utf8charset&quot;/&gt; &lt;property name=&quot;writeAcceptCharset&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot;&gt; &lt;bean class=&quot;com.fasterxml.jackson.databind.ObjectMapper&quot;&gt; &lt;property name=&quot;serializationInclusion&quot;&gt; &lt;value type=&quot;com.fasterxml.jackson.annotation.JsonInclude.Include&quot;&gt;NON_NULL&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; 自定义序列化方式现在需要将Long类型数字达到一定长度才转为String类型传递给前端。实现方式有两种： 局部配置某个字段序列化实现抽象接口JsonSerializer自定义序列化类 12345678910111213141516public class CustomLongConverter extends JsonSerializer&lt;Long&gt; &#123; /** * 超过多少位转换为Long类型 */ private static final int THRESHOLD_LENGTH = 15; @Override public void serialize(Long value, JsonGenerator gen, SerializerProvider serializers) throws IOException, JsonProcessingException &#123; if (value.toString().length() &gt; THRESHOLD_LENGTH) &#123; gen.writeString(value.toString()); &#125; else &#123; gen.writeNumber(value); &#125; &#125;&#125; 用@JsonSerialize(using = CustomLongConverter.class)注解到指定字段上 12@JsonSerialize(using = CustomLongConverter.class)private Long id; 全局配置序注册自定义的序列化类自定义Long类型序列化继承自StdSerializer类的一个自定义序列化 12345678910111213141516171819202122public class CustomLongConverter extends StdSerializer&lt;Long&gt; &#123; /** * 超过多少位转换为Long类型 */ private static final int THRESHOLD_LENGTH = 15; private static final long serialVersionUID = -4532126689403959662L; CustomLongConverter() &#123; super(Long.class); &#125; @Override public void serialize(Long value, JsonGenerator gen, SerializerProvider serializers) throws IOException &#123; if (value.toString().length() &gt;= THRESHOLD_LENGTH) &#123; gen.writeString(value.toString()); &#125; else &#123; gen.writeNumber(value); &#125; &#125;&#125; 需要注册到ObjectMapper中 1234567891011121314151617public class ObjectMapperConverter extends ObjectMapper &#123; private static final long serialVersionUID = 5383113523976711806L; public ObjectMapperConverter() &#123; super(); // 不包含为空的字段 setSerializationInclusion(JsonInclude.Include.NON_NULL); // 不包含空字符串字段 setSerializationInclusion(JsonInclude.Include.NON_EMPTY); SimpleModule simpleModule = new SimpleModule(); simpleModule.addSerializer(Long.class, new CustomLongConverter()); simpleModule.addSerializer(Long.TYPE, new CustomLongConverter()); registerModule(simpleModule); &#125;&#125; xml中配置注册方式SpringMVC配置中需要指定为自定义序列化 12345678910111213&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;constructor-arg ref=&quot;utf8charset&quot;/&gt; &lt;property name=&quot;writeAcceptCharset&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot;&gt; &lt;bean class=&quot;com.rainbowhorse.consult.web.util.ObjectMapperConverter&quot;/&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"RocketMQ(二)—消息重试","slug":"RocketMQ-二-—消息重试","date":"2019-08-13T12:37:29.000Z","updated":"2021-05-09T02:22:40.054Z","comments":true,"path":"RocketMQ-二-—消息重试/","link":"","permalink":"https://mx-go.github.io/RocketMQ-%E4%BA%8C-%E2%80%94%E6%B6%88%E6%81%AF%E9%87%8D%E8%AF%95/","excerpt":"","text":"引言由于MQ经常处于复杂的分布式系统中，考虑网络波动、服务宕机、程序异常因素，很有可能出现消息发送或者消费失败的问题。因此，消息的重试就是所有MQ中间件必须考虑到的一个关键点。如果没有消息重试，就可能产生消息丢失的问题，可能对系统产生很大的影响。 Consumer重试重试条件在RocketMQ中，只有当消费模式为MessageModel.CLUSTERING(集群模式)时，Broker才会自动进行重试，对于MessageModel.BROADCASTING(广播消息)是不会重试的。集群模式下，当消息消费失败时，RMQ会通过消息重试机制重新投递消息，努力使该消息消费成功。对于一直无法消费成功的消息，RMQ会在达到最大重试次数之后，将该消息投递至死信队列。然后我们可以关注死信队列DLQ(Dead Letter Queue)，并对该死信消息业务做人工补偿操作。 当消费者消费该重试消息后，需要返回结果给broker，告知broker消费成功(ConsumeConcurrentlyStatus.CONSUME_SUCCESS)或者需要重新消费(ConsumeConcurrentlyStatus.RECONSUME_LATER) RocketMQ规定，以下三种情况统一按照消费失败处理并会发起重试： 业务消费方返回ConsumeConcurrentlyStatus.RECONSUME_LATER 业务消费方返回null 业务消费方主动/被动抛出异常 前两种情况较容易理解，当返回ConsumeConcurrentlyStatus.RECONSUME_LATER或者null时，broker会知道消费失败，后续就会发起消息重试，重新投递该消息。 注意：对于抛出异常的情况，只要在业务逻辑中显式抛出异常或者非显式抛出异常，broker也会重新投递消息，如果业务对异常做了捕获，那么该消息将不会发起重试。因此对于需要重试的业务，消费方在捕获异常的时候要注意返回ConsumeConcurrentlyStatus.RECONSUME_LATER或null并输出异常日志，打印当前重试次数(推荐返回ConsumeConcurrentlyStatus.RECONSUME_LATER)。 重试时间窗RocketMQ不支持任意频率的延时调用，当消息需要重试时，会按照broker中指定的重试时间窗进行重试。可以在RMQ的源码org.apache.rocketmq.store.config.MessageStoreConfig#messageDelayLevel找到消息重试配置： 12// 消息延时级别默认配置private String messageDelayLevel = &quot;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&quot;; 重试次数 距离第一次发送的时间间隔 1 10s 2 30s 3 1m 4 2m 5 3m 6 4m 7 5m 8 6m 9 7m 10 8m 11 9m 12 10m 13 20m 14 30m 15 1h 16 2h RocketMQ采用了“时间衰减策略”进行消息的重复投递，即重试次数越多，消息消费成功的可能性越小。 源码分析在RMQ的客户端源码DefaultMQPushConsumerImpl.java中，对重试机制做了说明，源码如下： 12345678private int getMaxReconsumeTimes() &#123; // 默认消费次数: 16 if (this.defaultMQPushConsumer.getMaxReconsumeTimes() == -1) &#123; return 16; &#125; else &#123; return this.defaultMQPushConsumer.getMaxReconsumeTimes(); &#125;&#125; 首先判断消费端有没有显式设置最大重试次数 MaxReconsumeTimes， 如果没有，则设置默认重试次数为16，否则以设置的最大重试次数为准。 当消息消费失败，服务端会发起消费重试，具体逻辑在broker的源码org.apache.rocketmq.broker.processor.SendMessageProcessor#consumerSendMsgBack中涉及，源码如下： 12345678910111213141516171819202122// 当前重试次数大于等于最大重试次数或者配置的重试级别小于0，则获取死信队列的Topic。后续将超时的消息send到死信队列中if (msgExt.getReconsumeTimes() &gt;= maxReconsumeTimes || delayLevel &lt; 0) &#123; newTopic = MixAll.getDLQTopic(requestHeader.getGroup()); queueIdInt = Math.abs(this.random.nextInt() % 99999999) % DLQ_NUMS_PER_GROUP; topicConfig = this.brokerController.getTopicConfigManager().createTopicInSendMessageBackMethod(newTopic, DLQ_NUMS_PER_GROUP, PermName.PERM_WRITE, 0 ); if (null == topicConfig) &#123; response.setCode(ResponseCode.SYSTEM_ERROR); response.setRemark(&quot;topic[&quot; + newTopic + &quot;] not exist&quot;); return response; &#125; &#125; else &#123; // 如果delayLevel为0，则默认加3个级别 if (0 == delayLevel) &#123; delayLevel = 3 + msgExt.getReconsumeTimes(); &#125; msgExt.setDelayTimeLevel(delayLevel);&#125; 正常情况会进入else分支，对于首次重试的消息，默认的delayLevel是0，RMQ会将给该level + 3，也就是加到3，这就是说，如果没有显示的配置延时级别，消息消费重试首次，是延迟了第三个级别发起的重试，从表格中看也就是距离首次发送10s后重试。 当延时级别设置完成，刷新消息的重试次数为当前次数加1，broker将该消息刷盘，逻辑如下： 12345678910111213141516171819MessageExtBrokerInner msgInner = new MessageExtBrokerInner(); msgInner.setTopic(newTopic); msgInner.setBody(msgExt.getBody()); msgInner.setFlag(msgExt.getFlag()); MessageAccessor.setProperties(msgInner, msgExt.getProperties()); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgExt.getProperties())); msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(null, msgExt.getTags())); msgInner.setQueueId(queueIdInt); msgInner.setSysFlag(msgExt.getSysFlag()); msgInner.setBornTimestamp(msgExt.getBornTimestamp()); msgInner.setBornHost(msgExt.getBornHost()); msgInner.setStoreHost(this.getStoreHost()); msgInner.setReconsumeTimes(msgExt.getReconsumeTimes() + 1); String originMsgId = MessageAccessor.getOriginMessageId(msgExt); MessageAccessor.setOriginMessageId(msgInner, UtilAll.isBlank(originMsgId) ? msgExt.getMsgId() : originMsgId); PutMessageResult putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner); 对于重试消息，RMQ会创建新的MessageExtBrokerInner对象，继承自MessageExt。继续进入消息刷盘逻辑，即：putMessage(msgInner)方法，实现类为DefaultMessageStore.java，核心代码如下： 12long beginTime = this.getSystemClock().now();PutMessageResult result = this.commitLog.putMessage(msg); 主要关注 this.commitLog.putMessage(msg); 这句代码，通过commitLog可以认为这里是真实刷盘操作，也就是消息被持久化了。继续进入commitLog的putMessage方法，核心代码段： 12345678910111213141516171819202122if (tranType == MessageSysFlag.TRANSACTION_NOT_TYPE || tranType == MessageSysFlag.TRANSACTION_COMMIT_TYPE) &#123; // 处理延时级别 if (msg.getDelayTimeLevel() &gt; 0) &#123; if (msg.getDelayTimeLevel() &gt; this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()) &#123; msg.setDelayTimeLevel(this.defaultMessageStore.getScheduleMessageService().getMaxDelayLevel()); &#125; // 更换Topic topic = ScheduleMessageService.SCHEDULE_TOPIC; // 队列ID为延迟级别-1 queueId = ScheduleMessageService.delayLevel2QueueId(msg.getDelayTimeLevel()); // 备份真实的topic, queueId MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic()); MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId())); msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); // 重置topic及queueId msg.setTopic(topic); msg.setQueueId(queueId); &#125;&#125; ScheduleMessageService.java 123public static int delayLevel2QueueId(final int delayLevel) &#123; return delayLevel - 1;&#125; 如果是重试消息，在进行延时级别判断时候，会进入分支逻辑，通过这段逻辑可以看出对于重试的消息，RMQ并不会从原队列中获取消息，而是创建了一个新的Topic进行消息存储的。也就是代码中的SCHEDULE_TOPIC 1public static final String SCHEDULE_TOPIC = &quot;SCHEDULE_TOPIC_XXXX&quot;; 由此可以看出： 对于所有消费者消费失败的消息，RMQ都会把重试的消息重新new出来(new MessageExtBrokerInner对象)，然后投递到Topic为SCHEDULE_TOPIC_XXXX 下的队列中，然后由定时任务进行调度重试，而重试的周期即是上面的的delayLevel周期。Broker在启动时会创建topic为SCHEDULE_TOPIC_XXXX`，根据延迟level的个数，创建对应数量的队列，也就是说18个level对应了18个队列。注意，这并不是说这个内部主题只会有18个队列，因为Broker通常是集群模式部署的，因此每个节点都有18个队列。 同时为了保证消息可被找到，也会将原先的Topic和队列id存储到properties中做备份： 1234 // Backup real topic, queueIdMessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_TOPIC, msg.getTopic());MessageAccessor.putProperty(msg, MessageConst.PROPERTY_REAL_QUEUE_ID, String.valueOf(msg.getQueueId()));msg.setPropertiesString(MessageDecoder.messageProperties2String(msg.getProperties())); 死信的业务处理方式默认的处理机制中，如果只对消息做重复消费，达到最大重试次数之后消息就进入死信队列了。可以根据业务的需要，定义消费的最大重试次数，每次消费的时候判断当前消费次数是否等于最大重试次数的阈值。 如：重试三次就认为当前业务存在异常，继续重试下去也没有意义了，那么就可以将当前的这条消息进行提交，返回broker状态ConsumeConcurrentlyStatus.CONSUME_SUCCES，让消息不再重发，同时将该消息存入业务自定义的死信消息表，将业务参数入库，相关的运营通过查询死信表来进行对应的业务补偿操作。 RMQ 的处理方式为将达到最大重试次数(16次)的消息标记为死信消息，将该死信消息投递到DLQ死信队列中，业务需要进行人工干预。实现的逻辑在org.apache.rocketmq.broker.processor.SendMessageProcessor#consumerSendMsgBack方法中，大致思路为首先判断重试次数是否超过16或消息发送延时级别是否小于0，如果是则将消息设置为新的死信。死信topic 为：**%DLQ% + consumerGroup**。 死信源码分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private RemotingCommand consumerSendMsgBack(final ChannelHandlerContext ctx, final RemotingCommand request) throws RemotingCommandException &#123; final RemotingCommand response = RemotingCommand.createResponseCommand(null); final ConsumerSendMsgBackRequestHeader requestHeader = (ConsumerSendMsgBackRequestHeader)request.decodeCommandCustomHeader(ConsumerSendMsgBackRequestHeader.class); ...... // 0.首先判断重试次数是否大于等于16，或者消息延迟级别是否小于0 if (msgExt.getReconsumeTimes() &gt;= maxReconsumeTimes || delayLevel &lt; 0) &#123; // 1. 如果满足判断条件，设置死信队列topic= %DLQ%+consumerGroup newTopic = MixAll.getDLQTopic(requestHeader.getGroup()); queueIdInt = Math.abs(this.random.nextInt() % 99999999) % DLQ_NUMS_PER_GROUP; topicConfig = this.brokerController.getTopicConfigManager().createTopicInSendMessageBackMethod(newTopic, DLQ_NUMS_PER_GROUP, PermName.PERM_WRITE, 0 ); if (null == topicConfig) &#123; response.setCode(ResponseCode.SYSTEM_ERROR); response.setRemark(&quot;topic[&quot; + newTopic + &quot;] not exist&quot;); return response; &#125; &#125; else &#123; // 如果延迟级别为0，则设置下一次延迟级别为3+当前重试消费次数，达到时间衰减效果 if (0 == delayLevel) &#123; delayLevel = 3 + msgExt.getReconsumeTimes(); &#125; msgExt.setDelayTimeLevel(delayLevel); &#125; MessageExtBrokerInner msgInner = new MessageExtBrokerInner(); msgInner.setTopic(newTopic); msgInner.setBody(msgExt.getBody()); msgInner.setFlag(msgExt.getFlag()); MessageAccessor.setProperties(msgInner, msgExt.getProperties()); msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgExt.getProperties())); msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(null, msgExt.getTags())); msgInner.setQueueId(queueIdInt); msgInner.setSysFlag(msgExt.getSysFlag()); msgInner.setBornTimestamp(msgExt.getBornTimestamp()); msgInner.setBornHost(msgExt.getBornHost()); msgInner.setStoreHost(this.getStoreHost()); msgInner.setReconsumeTimes(msgExt.getReconsumeTimes() + 1); String originMsgId = MessageAccessor.getOriginMessageId(msgExt); MessageAccessor.setOriginMessageId(msgInner, UtilAll.isBlank(originMsgId) ? msgExt.getMsgId() : originMsgId); // 3.死信消息投递到死信队列中并落盘 PutMessageResult putMessageResult = this.brokerController.getMessageStore().putMessage(msgInner); ...... return response; &#125; 死信队列的处理逻辑 判断消息当前重试次数是否大于等于16，或者消息延迟级别是否小于0 只要满足上述的任意一个条件，设置新的topic(死信topic)为：**%DLQ% + consumerGroup** 进行前置属性的添加 将死信消息投递到步骤2建立的死信topic对应的死信队列中并落盘，使消息持久化 Producer重试当发生网络抖动等异常情况，Producer侧往broker发送消息失败，即：生产者侧没收到broker返回的ACK，导致Consumer无法进行消息消费，这时RMQ会进行发送重试。 使用DefaultMQProducer进行普通消息发送时，可以设置消息发送失败后最大重试次数，并且能够灵活的配合超时时间进行业务重试逻辑的开发，使用的API如下： 123456789101112// 默认重试两次private int retryTimesWhenSendFailed = 2;// 设置消息发送失败时最大重试次数public void setRetryTimesWhenSendFailed(int retryTimesWhenSendFailed) &#123; this.retryTimesWhenSendFailed = retryTimesWhenSendFailed;&#125;// 同步发送消息，并指定超时时间public SendResult send(Message msg, long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; return this.defaultMQProducerImpl.send(msg, timeout);&#125; 通过API可以看出，生产者侧的重试是比较简单的，例如：设置生产者在3s内没有发送成功则重试3次的代码如下： 1234// 同步发送消息，如果3秒内没有发送成功，则重试3次DefaultMQProducer producer = new DefaultMQProducer(&quot;DefaultProducerGroup&quot;);producer.setRetryTimesWhenSendFailed(3);producer.send(msg, 3000L); 参考跟我学RocketMQ之消息重试","categories":[{"name":"中间件","slug":"中间件","permalink":"https://mx-go.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://mx-go.github.io/tags/RocketMQ/"}]},{"title":"logback行号输出问号问题","slug":"logback行号输出问号问题","date":"2019-07-22T05:45:40.000Z","updated":"2021-05-10T15:12:57.154Z","comments":true,"path":"logback行号输出问号问题/","link":"","permalink":"https://mx-go.github.io/logback%E8%A1%8C%E5%8F%B7%E8%BE%93%E5%87%BA%E9%97%AE%E5%8F%B7%E9%97%AE%E9%A2%98/","excerpt":"引言Logback日志输出使用 AsyncAppender 时，输出的文件行号信息是 ?:? ，问题产生原因及解决方案。","text":"引言Logback日志输出使用 AsyncAppender 时，输出的文件行号信息是 ?:? ，问题产生原因及解决方案。 问题在 logback推荐配置 一文中，列举了logback常用的几种配置，使用的是logback异步输出日志AsyncAppender。但在实际的开发中，遇到了日志没有输出类和行号，而输出的文件行号信息是 **?:?**。 输出的日志类似于这种： 12345678framework-server-demo 2017-07-17 14:15:11,876 INFO [main] o.s.j.e.a.AnnotationMBeanExporter [?:?] - Located managed bean &#x27;refreshScope&#x27;: registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]framework-server-demo 2017-07-17 14:15:11,881 INFO [main] o.s.j.e.a.AnnotationMBeanExporter [?:?] - Located managed bean &#x27;configurationPropertiesRebinder&#x27;: registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=43f2f92d,type=ConfigurationPropertiesRebinder]framework-server-demo 2017-07-17 14:15:11,887 INFO [main] o.s.j.e.a.AnnotationMBeanExporter [?:?] - Located managed bean &#x27;refreshEndpoint&#x27;: registering with JMX server as MBean [org.springframework.cloud.endpoint:name=refreshEndpoint,type=RefreshEndpoint]framework-server-demo 2017-07-17 14:15:11,888 INFO [main] o.s.b.a.e.j.EndpointMBeanExporter [?:?] - Registering beans for JMX exposure on startupframework-server-demo 2017-07-17 14:15:12,709 INFO [main] application [?:?] - jolokia: No access restrictor found, access to any MBean is allowedframework-server-demo 2017-07-17 14:15:12,714 INFO [main] application [?:?] - jolokia: jolokia:type=Config is already registered. Adding it with jolokia:type=Config,uuid=43140813-0dc0-413d-96c0-5de1799eadd3, but you should revise your setup in order to either use a qualifier or ensure, that only a single agent gets registered (otherwise history functionality might not work)framework-server-demo 2017-07-17 14:15:12,714 INFO [main] application [?:?] - jolokia: Cannot register (legacy) MBean handler for config store with name jmx4perl:type=Config since it already exists. This is the case if another agent has been already started within the same JVM. The registration is skipped.framework-server-demo 2017-07-17 14:15:12,715 INFO [main] application [?:?] - jolokia: Jolokia Discovery MBean registration is skipped because there is already one registered. 原因分析输出文件以及行号信息需要 stacktrace 获取 callerdata，因为性能原因 logback 的 AsyncAppender 默认是不记录该信息。即默认为false。 官方文档： https://logback.qos.ch/manual/appenders.html#AsyncAppender Property Name Type Description includeCallerData boolean Extracting caller data can be rather expensive. To improve performance, by default, caller data associated with an event is not extracted when the event added to the event queue. By default, only “cheap” data like the thread name and the MDC are copied. You can direct this appender to include caller data by setting the includeCallerData property to true. 解决方案如文档说明，只需要在 logback 配置文件里 AsyncAppender 中添加 includeCallerData 并设置为 true 。 1&lt;includeCallerData&gt;true&lt;/includeCallerData&gt;","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"RocketMQ(一)—角色与术语","slug":"RocketMQ-一-——角色与术语","date":"2019-06-15T15:00:16.000Z","updated":"2021-05-09T02:22:31.055Z","comments":true,"path":"RocketMQ-一-——角色与术语/","link":"","permalink":"https://mx-go.github.io/RocketMQ-%E4%B8%80-%E2%80%94%E2%80%94%E8%A7%92%E8%89%B2%E4%B8%8E%E6%9C%AF%E8%AF%AD/","excerpt":"","text":"引言我们通过缓存和消息队列来化解海量的读请求和写请求对后端数据库服务造成的压力。RocketMQ作为阿里巴巴开源的消息队列中间件，得到不少企业的青睐。在RocketMQ中有四大角色 NameServer、Broker、Producer和Consumer。 RocketMQ 特点灵活可扩展性RocketMQ天然支持集群，其核心四组件（NameServer、Broker、Producer、Consumer）每一个都可以在没有单点故障的情况下进行水平扩展。 海量消息堆积能力RocketMQ采用零拷贝原理实现超大的消息的堆积能力，据说单机已可以支持亿级消息堆积，而且在堆积了这么多消息后依然保持写入低延迟。 支持顺序消息可以保证消息消费者按照消息发送的顺序对消息进行消费。顺序消息分为全局有序和局部有序，一般推荐使用局部有序，即生产者通过将某一类消息按顺序发送至同一个队列来实现。 多种消息过滤方式消息过滤分为在服务器端过滤和在消费端过滤。服务器端过滤时可以按照消息消费者的要求做过滤，优点是减少不必要消息传输，缺点是增加了消息服务器的负担，实现相对复杂。消费端过滤则完全由具体应用自定义实现，这种方式更加灵活，缺点是很多无用的消息会传输给消息消费者。 支持事务消息RocketMQ除了支持普通消息，顺序消息之外还支持事务消息，这个特性对于分布式事务来说提供了又一种解决思路。 回溯消费回溯消费是指消费者已经消费成功的消息，由于业务上需求需要重新消费，RocketMQ支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。 Name ServerNameServer用来保存Broker相关元信息并提供给Producer和Consumer查找Broker信息。NameServer被设计成无状态的，可以横向扩展，节点之间相互之间无通信，通过部署多台机器来标记自己是一个伪集群。每个Broker在启动的时候会到NameServer注册，Producer在发送消息前会根据Topic到NameServer获取到Broker的路由信息，Consumer也会定时获取Topic的路由信息。 Name Server是一个无状态的结点，Name Server之间采取share-nothing的设计，互不通信。 Name Server所有状态都从Broker上报而来，本身不存储任何状态，所有数据均在内存。 Name Server不会有频繁的读写，所以性能开销非常小，稳定性很高。 如果所有Name Server全都挂了，只会影响到Topic到Broker路由信息的更新，不会影响Topic和Broker的通信。 BrokerBroker是消息存储中心，主要作用是接收来自Producer的消息并存储，Consumer从这里取得消息。它还存储与消息相关的元数据，包括用户组、消费进度偏移量、队列信息等。 Broker向所有的NameServer结点建立长连接，注册Topic信息。 Broker分为master和slave。只有master才能进行写入操作，slave不允许。 slave从master中同步数据。同步策略取决于master的配置，可以采用同步刷盘，异步刷盘两种。 客户端消费可以从master和slave消费。在默认情况下，Consumer都从master消费，在master挂后，客户端由于从Name Server中感知到Broker挂机，就会从slave消费。 与Name Server关系 连接。单个Broker和所有NameServer保持长连接。 心跳。每隔30秒（此时间无法更改）向所有NameServer发送心跳，心跳包含了自身的Topic配置信息。 断开。当Broker挂掉时，心跳超时导致NameServer主动关闭连接。一旦连接断开，NameServer会立即感知，更新Topic与队列的对应关系，但不会通知生产者和消费者。 负载均衡 一个Topic分布在多个Broker上，一个Broker可以配置多个Topic，它们是多对多的关系。 如果某个Topic消息量很大，应该多配置几个队列，并尽量分布在不同Broker上，减轻某个Broker的压力。 Topic消息量比较均匀的情况下，如果某个Broker上的队列越多，则该Broker压力越大。 可用性由于消息分布在各个Broker上，一旦某个Broker宕机，则该Broker上的消息读写都会受到影响。所以RocketMQ提供了master/slave的结构，salve定时从master同步数据。如果master宕机，则slave提供消费服务，但是不能写入消息，此过程对应用透明，由RocketMQ内部解决。 一旦某个Broker master宕机，受限于RocketMQ的网络连接机制，默认情况下，生产者和消费者最多需要30秒会发现，但这个时间可由应用设定参数来缩短时间。这个时间段内，发往该Broker的消息都是失败的，而且该Broker的消息无法消费，因为此时消费者不知道该Broker已经挂掉。 消费者得到master宕机通知后，转向slave消费，但是slave不能保证master的消息100%都同步过来了，因此会有少量的消息丢失。但是消息最终不会丢的，一旦master恢复，未同步过去的消息会被消费掉。 ProducerProducer负责产生消息，生产者向消息服务器发送由业务应用程序系统生成的消息。 与Name Server关系 连接。单个生产者者和一台NameServer保持长连接，定时查询Topic配置信息，如果该NameServer挂掉，Producer会自动连接下一个NameServer，直到有可用连接为止，并能自动重连。 轮询时间。生产者每30秒从NameServer获取Topic跟Broker的映射关系，更新到本地内存中。再跟Topic涉及的所有Broker建立长连接，每隔30秒发一次心跳。在Broker端也会每10秒扫描一次当前注册的Producer，如果发现某个Producer超过2分钟都没有发心跳，则断开连接。 与broker关系 连接。单个生产者和该生产者关联的所有Broker保持长连接。 心跳。默认情况下，生产者每隔30秒向所有Broker发送心跳，该时间由DefaultMQProducer的heartbeatBrokerInterval参数决定，可手动配置。Broker每隔10秒钟（此时间无法更改），扫描所有还存活的连接，若某个连接2分钟内（当前时间与最后更新时间差值超过2分钟，此时间无法更改）没有发送心跳数据，则关闭连接。 连接断开。移除Broker上的生产者信息。 假如某个Broker宕机，意味生产者最长需要30秒才能感知到。在这期间会向宕机的Broker发送消息。当一条消息发送到某个Broker失败后，会往该Broker自动再重发2次，假如还是发送失败，则抛出发送失败异常。业务捕获异常，重新发送即可。客户端里会自动轮询另外一个Broker重新发送，这个对于用户是透明的。 负载均衡生产者发送时，会自动轮询当前所有可发送的Broker，一条消息发送成功，下次换另外一个Broker发送，以达到消息平均落到所有的Broker上。 Consumer消费消息的客户端角色。通常是后台处理异步消费的系统。 RocketMQ中Consumer有两种实现：PushConsumer和PullConsumer。 消费者有两种模式消费：集群消费(clustering)，广播消费(broadcast)。 与NameServer关系 连接。单个消费者和一台NameServer保持长连接，定时查询Topic配置信息，如果该NameServer挂掉，消费者会自动连接下一个NameServer，直到有可用连接为止，并能自动重连。 轮询时间。消费者每隔30秒从NameServer获取所有Topic的最新队列情况，这意味着某个Broker如果宕机，客户端最多要30秒才能感知。连接建立后，从NameServer中获取当前消费Topic所涉及的Broker，直连Broker。 与broker关系 连接。单个消费者和该消费者关联的所有Broker保持长连接。 心跳。Consumer跟Broker是长连接，会每隔30秒发心跳信息到Broker。Broker端每10秒检查一次当前存活的Consumer，若发现某个Consumer 2分钟内没有心跳，就断开与该Consumer的连接，并且向该消费组的其他实例发送通知，触发该消费者集群的负载均衡。 断开。一旦连接断开，Broker会立即感知到，并向该消费者分组的所有消费者发出通知，分组内消费者重新分配队列继续消费。 负载均衡集群消费模式下，一个消费者集群多台机器共同消费一个Topic的多个队列，一个队列只会被一个消费者消费。如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。 参数详解 客户端的公共配置类：ClientConfig 参数名 默认值 说明 NamesrvAddr 无 NameServer地址列表，多个nameServer地址用分号隔开 clientIP 本机IP 客户端本机IP地址，某些机器会发生无法识别客户端IP地址情况，需要应用在代码中强制指定 instanceName DEFAULT 客户端实例名称，客户端创建的多个Producer，Consumer实际是共用一个内部实例（这个实例包含网络连接，线程资源等） clientCallbackExecutorThreads 4 通信层异步回调线程数 pollNameServerInteval 30000 轮询Name Server 间隔时间，单位毫秒 heartbeatBrokerInterval 30000 向Broker发送心跳间隔时间，单位毫秒 persistConsumerOffsetInterval 5000 持久化Consumer消费进度间隔时间，单位毫秒 Producer配置 参数名 默认值 说明 producerGroup DEFAULT_PRODUCER Producer组名，多个Producer如果属于一个应用，发送同样的消息，则应该将它们归为同一组。标识发送同一类消息的Producer，通常发送逻辑一致。发送普通消息的时候，仅标识使用，并无特别用处。若事务消息，如果某条发送某条消息的producer-A宕机，使得事务消息一直处于PREPARED状态并超时，则broker会回查同一个group的其 他producer，确认这条消息应该commit还是rollback。 createTopicKey TBW102 在发送消息时，自动创建服务器不存在的topic，需要指定key defaultTopicQueueNums 4 在发送消息时，自动创建服务器不存在的topic，默认创建的队列数 sendMsgTimeout 10000 发送消息超时时间，单位毫秒 compressMsgBodyOverHowmuch 4096 消息Body超过多大开始压缩（Consumer收到消息会自动解压缩），单位字节 retryAnotherBrokerWhenNotStoreOK FALSE 如果发送消息返回sendResult,但是sendStatus!=SEND_OK,是否重试发送 maxMessageSize 131072 客户端限制的消息大小，超过报错，同时服务端也会限制（默认128K） transactionCheckListener 无 事物消息回查监听器，如果发送事务消息，必须设置 checkThreadPoolMinSize 1 Broker回查Producer事务状态时，线程池大小 checkThreadPoolMaxSize 1 Broker回查Producer事务状态时，线程池大小 checkRequestHoldMax 2000 Broker回查Producer事务状态时，Producer本地缓冲请求队列大小 PushConsumer配置 参数名 默认值 说明 consumerGroup DEFAULT_CONSUMER Consumer组名，多个Consumer如果属于一个应用，订阅同样的消息，且消费逻辑一致，则应将它们归为同一组。消费进度以Consumer Group为粒度管理，不同Consumer Group之间消费进度彼此不受影响，即消息A被Consumer Group1消费过，也会再给Consumer Group2消费 messageModel CLUSTERING 消息模型，支持以下两种1.集群消费2.广播消费 consumeFromWhere CONSUME_FROM_LAST_OFFSET Consumer启动后，默认从什么位置开始消费 allocateMessageQueueStrategy AllocateMessageQueueAveragely Rebalance算法实现策略 Subscription {} 订阅关系 messageListener 无 消息监听器 offsetStore 无 消费进度存储 consumeThreadMin 20 消费线程池数量 consumeThreadMax 64 消费线程池数量 consumeConcurrentlyMaxSpan 2000 单队列并行消费允许的最大跨度 pullThresholdForQueue 1000 拉消息本地队列缓存消息最大数 Pullinterval 0 拉消息间隔，由于是长轮询，所以为0，但是如果应用了流控，也可以设置大于0的值，单位毫秒 consumeMessageBatchMaxSize 1 批量消费，一次消费多少条消息 pullBatchSize 32 批量拉消息，一次最多拉多少条 PullConsumer配置 参数名 默认值 说明 consumerGroup 无 Conusmer组名，多个Consumer如果属于一个应用，订阅同样的消息，且消费逻辑一致，则应该将它们归为同一组 brokerSuspendMaxTimeMillis 20000 长轮询，Consumer拉消息请求在Broker挂起最长时间，单位毫秒 consumerPullTimeoutMillis 10000 非长轮询，拉消息超时时间，单位毫秒 consumerTimeoutMillisWhenSuspend 30000 长轮询，Consumer拉消息请求咋broker挂起超过指定时间，客户端认为超时，单位毫秒 messageModel BROADCASTING 消息模型，支持以下两种：1集群消费 2广播模式 messageQueueListener 无 监听队列变化 offsetStore 无 消费进度存储 registerTopics 无 注册的topic集合 allocateMessageQueueStrategy 无 Rebalance算法实现策略","categories":[{"name":"中间件","slug":"中间件","permalink":"https://mx-go.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}],"tags":[{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://mx-go.github.io/tags/RocketMQ/"}]},{"title":"Java和Docker限制的那些事儿","slug":"Java和Docker限制的那些事儿","date":"2019-06-01T01:01:36.000Z","updated":"2021-05-05T03:24:37.607Z","comments":true,"path":"Java和Docker限制的那些事儿/","link":"","permalink":"https://mx-go.github.io/Java%E5%92%8CDocker%E9%99%90%E5%88%B6%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/","excerpt":"","text":"引言Java和Docker不是天然的朋友。 Docker可以设置内存和CPU限制，而Java不能自动检测到。使用Java的Xmx标识（繁琐/重复）或新的实验性JVM标识，可以解决这个问题。自己也是在开发配置上踩了个坑。 采坑记录在开发中使用了线程池，根据计算密集型 VS IO密集型设置线程数量，代码如下： 12345ThreadFactory threadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;service_record&quot;).build();ExecutorService pool = new ThreadPoolExecutor(4, 2 * Runtime.getRuntime().availableProcessors(), 60L, TimeUnit.SECONDS, new LinkedBlockingQueue(1024), threadFactory, new ThreadPoolExecutor.CallerRunsPolicy()); 过不久，发现启动时提示这块有异常。我们的服务一部分部署在虚拟机里面，一部分部署在k8s中。Docker中可以设置CPU个数为小数，当设置CPU个数小于两个时，maximumPoolSize就会小于corePoolSize。会抛出IllegalArgumentException。 123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 虚拟化中的不匹配Java和Docker的结合并不是完美匹配的，最初的时候离完美匹配有相当大的距离。Docker可以把你的程序、设置、特定的JDK、Linux设置和应用服务器，还有其他工具打包在一起，当做一个东西。站在DevOps/Cloud的角度来看，这样一个完整的容器有着更高层次的封装。 内存现在很多产品级应用都在用Java8或是更早的版本，Java 8（update 131之前的版本）和Docker无法很好地一起工作。问题是在机器上，JVM的可用内存和CPU数量并不是Docker允许你使用的可用内存和CPU数量。 比如，如果我们限制Docker容器只能使用100MB内存，但是旧版本的Java并不能识别这个限制。Java看不到这个限制，JVM会要求更多内存，而且远超这个限制。如果使用太多内存，Docker将采取行动并杀死容器内的进程！JAVA进程被干掉了，很明显，这并不是我们想要的。 为了解决这个问题，需要给Java指定一个最大内存限制。在旧版本的Java(8u131之前)，需要在容器中通过设置-Xmx来限制堆大小。这感觉不太对，我们可不想定义这些限制两次，也不太想在容器中来定义。 现在有了更好的方式来解决这个问题。从Java 9之后(8u131+)，JVM增加了如下标志: 1-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap 这些标志强制JVM检查Linux的cgroup配置，Docker是通过cgroup来实现最大内存设置的。如果应用到达了Docker设置的限制（比如500MB），JVM是可以看到这个限制的。JVM将会尝试GC操作。如果仍然超过内存限制，JVM就会做它该做的事情，抛出OutOfMemoryException。也就是说，JVM能够看到Docker的这些设置。 从Java 10之后这些体验标志位是默认开启的，也可以使用-XX:+UseContainerSupport来控制开启或关闭。 CPUk8s可对CPU资源进行严格控制： 正实数，代表分配几颗CPU，可以是小数点，比如0.5代表0.5颗CPU，意思是一颗CPU的一半时间。2代表两颗CPU。 正整数m，也代表1000m=1，所以500m等价于0.5。 JVM将查看硬件并检测CPU的数量。它会优化runtime以使用这些CPUs。但是同样的情况，这里还有另一个不匹配，Docker可能不允许使用所有这些CPUs。这在Java8或Java9中并没有修复，但是在Java10中得到了解决。 从Java 10开始，可用的CPUs的计算将采用以不同的方式（默认情况下）解决此问题（同样是通过UseContainerSupport控制）。 结论简言之：注意资源限制的不匹配。测试内存设置和JVM标志，不要假设任何东西。 如果Docker容器中运行Java，确保设置了Docker内存限制和在JVM中也做了限制，或者JVM能够理解这些限制。 如果无法升级Java版本，需要使用-Xmx设置限制。 对于Java 8和Java 9，可以更新到最新版本并使用： 1-XX：+UnlockExperimentalVMOptions -XX：+UseCGroupMemoryLimitForHeap 对于OpenJ9(强烈建议使用，可以在生产环境中有效减少内存占用量)。 附上自己生产环境k8s中的配置： 12345678root 1 0 1 May29 ? 00:12:20 /usr/lib/jvm/zulu-8/bin/java -Djava.util.logging.config.file=/opt/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -server -XX:+AggressiveOpts -XX:+UseG1GC -XX:ParallelGCThreads=2 -XX:MaxGCPauseMillis=200 -Djava.security.egd=file:/dev/urandom -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap -XX:MaxRAMFraction=1 -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 -XX:-CICompilerCountPerCPU -XX:CICompilerCount=4 -Djava.util.concurrent.ForkJoinPool.common.parallelism=8 -javaagent:/opt/tomcat/lib/jmx_prometheus_javaagent-0.11.0.jar=8090:/opt/tomcat/conf/tomcat_jmx_export.yml -Xmx1228m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -classpath /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar -Dcatalina.base=/opt/tomcat -Dcatalina.home=/opt/tomcat -Djava.io.tmpdir=/opt/tomcat/temp org.apache.catalina.startup.Bootstrap start 参考Java和Docker限制的那些事儿 Improved Docker Container Integration with Java 10","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"动态修改日志级别","slug":"动态修改日志级别","date":"2019-05-11T08:18:56.000Z","updated":"2021-05-05T03:15:58.000Z","comments":true,"path":"动态修改日志级别/","link":"","permalink":"https://mx-go.github.io/%E5%8A%A8%E6%80%81%E4%BF%AE%E6%94%B9%E6%97%A5%E5%BF%97%E7%BA%A7%E5%88%AB/","excerpt":"引言日志是我们定位问题的关键，尤其是在线上。但是有时我们输出的日志信息不够充足，给排查问题带来了极大的困扰。如果能够不重启应用，就能动态调整日志级别的话，无疑给我们排查问题带来了极大的帮助。","text":"引言日志是我们定位问题的关键，尤其是在线上。但是有时我们输出的日志信息不够充足，给排查问题带来了极大的困扰。如果能够不重启应用，就能动态调整日志级别的话，无疑给我们排查问题带来了极大的帮助。 Spring Boot 1.5 从开始，Spring Boot Actuator 组件就已提供动态修改日志级别的能力。在这里基于SpringMVC封装了log-config-core的jar，提供了更丰富的功能。 项目地址在我的GitHub：https://github.com/mx-go/log-config-core/tree/master 项目必须使用logback作为日志输出组件。 引入Maven坐标12345&lt;dependency&gt; &lt;groupId&gt;com.github.mx-go&lt;/groupId&gt; &lt;artifactId&gt;log-config-core&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 使用jar包中的LogbackServlet通过web-fragment会自动注册到服务中，jar包提供以下功能： 获取服务所有logger level信息 获取单个logger level信息 设置指定logger的logger level 获取所有日志文件信息 查询某日志文件最近N行日志 获取服务所有logger level信息通过访问：http://ip:prot/logback/all GET 无参数 1234567891011121314151617181920212223访问：http://localhost:8081/logback/all返回：&#123; &quot;data&quot;: [ &#123; &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;ROOT&quot; &#125;, &#123; &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;com.rainbowhorse.open&quot; &#125;, &#123; &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;org.hibernate&quot; &#125;, &#123; &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;org.springframework&quot; &#125; ], &quot;status&quot;: 0&#125; 获取单个logger level信息通过访问：http://ip:prot/logback/getLogger GET 参数logger[必填] 123456789访问：http://localhost:8081/logback/getLogger?logger=com.rainbowhorse.open返回：&#123; &quot;data&quot;: &#123; &quot;level&quot;: &quot;INFO&quot;, &quot;logger&quot;: &quot;com.rainbowhorse.open&quot; &#125;, &quot;status&quot;: 0&#125; 设置指定logger的logger level通过访问：http://ip:prot/logback/setLevel GET 参数logger[必填]、level[选填]、newLevel[必填] 123456访问：http://localhost:8081/logback/setLevel?newLevel=DEBUG&amp;logger=com.rainbowhorse.open返回：&#123; &quot;data&quot;: &quot;修改日志level成功&quot;, &quot;status&quot;: 0&#125; 获取所有日志文件信息通过访问：http://ip:prot/logback/getLogFiles GET 无参数 12345678910111213访问：http://localhost:8081/logback/getLogFiles返回：&#123; &quot;data&quot;: [ &#123; &quot;parent&quot;: &quot;../logs&quot;, &quot;size&quot;: 36828, &quot;name&quot;: &quot;admin.log&quot;, &quot;lastModified&quot;: &quot;2019-05-11 17:03:59&quot; &#125; ], &quot;status&quot;: 0&#125; 查询某日志文件最近N行日志通过访问：http://ip:prot/logback/peekFile GET 参数file[必填]、num[选填,默认1000] 1234567891011121314151617访问：http://localhost:8081/logback/peekFile?file=admin.log&amp;num=10返回：&#123; &quot;data&quot;: [ &quot;2019-05-11 17:13:00,212 WARN [http-nio-8081-exec-6] change logger level start! logger: com.rainbowhorse.open, oldLevel: , newLevel: DEBUG&quot;, &quot;2019-05-11 17:13:03,778 DEBUG [http-nio-8081-exec-7] debug&quot;, &quot;2019-05-11 17:13:03,778 INFO [http-nio-8081-exec-7] info&quot;, &quot;2019-05-11 17:13:03,778 ERROR [http-nio-8081-exec-7] error&quot;, &quot;2019-05-11 17:13:18,337 INFO [http-nio-8081-exec-9] logback servlet request uri: /setLevel&quot;, &quot;2019-05-11 17:13:18,337 WARN [http-nio-8081-exec-9] change logger level start! logger: com.rainbowhorse.open, oldLevel: , newLevel: INFO&quot;, &quot;2019-05-11 17:13:21,441 INFO [http-nio-8081-exec-10] info&quot;, &quot;2019-05-11 17:13:21,442 ERROR [http-nio-8081-exec-10] error&quot;, &quot;2019-05-11 17:13:25,276 INFO [http-nio-8081-exec-2] logback servlet request uri: /getLogFiles&quot;, &quot;2019-05-11 17:13:30,515 INFO [http-nio-8081-exec-3] logback servlet request uri: /peekFile&quot; ], &quot;status&quot;: 0&#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"详解MongoDB执行计划","slug":"详解MongoDB执行计划","date":"2019-04-21T01:54:43.000Z","updated":"2021-05-05T03:21:40.050Z","comments":true,"path":"详解MongoDB执行计划/","link":"","permalink":"https://mx-go.github.io/%E8%AF%A6%E8%A7%A3MongoDB%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/","excerpt":"引言在RDBMS(Relational Database Management System)中，无论哪种数据库，都提供了SQL剖析工具，用来解决SQL效率低下的问题。在MongoDB中，也有相应的策略来实现剖析。MongoDB提供了**db.collection.explain()、cursor.explain()**方法和explain命令返回查询计划信息和查询计划的执行统计信息。","text":"引言在RDBMS(Relational Database Management System)中，无论哪种数据库，都提供了SQL剖析工具，用来解决SQL效率低下的问题。在MongoDB中，也有相应的策略来实现剖析。MongoDB提供了**db.collection.explain()、cursor.explain()**方法和explain命令返回查询计划信息和查询计划的执行统计信息。 db.collection.explain()简介支持的操作1234aggregate(); count(); distinct(); find(); group(); remove(); update() cursor.explain(verbosity) 为一个游标返回其查询执行计划(Reports on the query execution plan for a cursor)cursor.explain(verbosity) 最通常的行式为db.collection.find().explain()。其中verbosity说明返回信息的粒度。 explain()写操作(remove和update)时，返回是删除和更新操作的信息，并不将修改应用至数据库。 通过db.collection.explain().help()可以获取支持的操作 1234567891011121314&gt; db.collection.explain().help()Explainable operations .aggregate(...) - explain an aggregation operation .count(...) - explain a count operation .distinct(...) - explain a distinct operation .find(...) - get an explainable query .findAndModify(...) - explain a findAndModify operation .group(...) - explain a group operation .remove(...) - explain a remove operation .update(...) - explain an update operationExplainable collection methods .getCollection() .getVerbosity() .setVerbosity(verbosity) 执行模式db.collection.find().explain(verbose) explain(）输出一个以文档形式展现的执行计划，可以包括统计信息(可选)。 verbose：可选参数。缺省值为queryPlanner，用于查看指定执行计划的特定部分。即给定不同的参数则输出信息的详细程度不同。常用的有queryPlanner、executionStats、allPlansExecution。 queryPlanner缺省模式。MongoDB运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划。 executionStatsMongoDB运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划进行执行。在执行完毕后返回这个最佳执行计划执行完成时的相关统计信息。对于写操作db.collection.explain()返回关于更新和删除操作的信息，但是并不将修改应用到数据库。对于那些被拒绝的执行计划(rejectedPlans)，不返回其统计信息。 allPlansExecution该模式是前2种模式的更细化，即会包括上述2种模式的所有信息。即按照最佳的执行计划执行以及列出统计信息，而且还会列出一些候选的执行计划。如果有多个查询计划，executionStats信息包括这些执行计划的部分统计信息。 相关用法先在集合中插入一条数据 12&gt; db.student.insert(&#123;&quot;age&quot; : 90.0,&quot;name&quot; : &quot;rainbowhorse&quot;,&quot;score&quot; : 90.0,&quot;sex&quot; : &quot;M&quot;&#125;);WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 演示db.collection.explain().update()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&gt; db.student.explain(&quot;allPlansExecution&quot;).update(&#123;&quot;name&quot;:&quot;rainbowhorse&quot;&#125;,&#123;$set:&#123;&quot;score&quot;:99&#125;&#125;);&#123; &quot;queryPlanner&quot; : &#123; &quot;plannerVersion&quot; : 1, &quot;namespace&quot; : &quot;TEST.student&quot;, &quot;indexFilterSet&quot; : false, &quot;parsedQuery&quot; : &#123; &quot;name&quot; : &#123; &quot;$eq&quot; : &quot;rainbowhorse&quot; &#125; &#125;, &quot;winningPlan&quot; : &#123; &quot;stage&quot; : &quot;UPDATE&quot;, &quot;inputStage&quot; : &#123; &quot;stage&quot; : &quot;COLLSCAN&quot;, &quot;filter&quot; : &#123; &quot;name&quot; : &#123; &quot;$eq&quot; : &quot;rainbowhorse&quot; &#125; &#125;, &quot;direction&quot; : &quot;forward&quot; &#125; &#125;, &quot;rejectedPlans&quot; : [ ] &#125;, &quot;executionStats&quot; : &#123; &quot;executionSuccess&quot; : true, &quot;nReturned&quot; : 0, &quot;executionTimeMillis&quot; : 0, &quot;totalKeysExamined&quot; : 0, &quot;totalDocsExamined&quot; : 11, &quot;executionStages&quot; : &#123; &quot;stage&quot; : &quot;UPDATE&quot;, &quot;nReturned&quot; : 0, &quot;executionTimeMillisEstimate&quot; : 0, &quot;works&quot; : 13, &quot;advanced&quot; : 0, &quot;needTime&quot; : 12, &quot;needYield&quot; : 0, &quot;saveState&quot; : 0, &quot;restoreState&quot; : 0, &quot;isEOF&quot; : 1, &quot;invalidates&quot; : 0, &quot;nMatched&quot; : 1, &quot;nWouldModify&quot; : 1, &quot;nInvalidateSkips&quot; : 0, &quot;wouldInsert&quot; : false, &quot;fastmodinsert&quot; : false, &quot;inputStage&quot; : &#123; &quot;stage&quot; : &quot;COLLSCAN&quot;, &quot;filter&quot; : &#123; &quot;name&quot; : &#123; &quot;$eq&quot; : &quot;rainbowhorse&quot; &#125; &#125;, &quot;nReturned&quot; : 1, &quot;executionTimeMillisEstimate&quot; : 0, &quot;works&quot; : 12, &quot;advanced&quot; : 1, &quot;needTime&quot; : 11, &quot;needYield&quot; : 0, &quot;saveState&quot; : 1, &quot;restoreState&quot; : 1, &quot;isEOF&quot; : 0, &quot;invalidates&quot; : 0, &quot;direction&quot; : &quot;forward&quot;, &quot;docsExamined&quot; : 11 &#125; &#125;, &quot;allPlansExecution&quot; : [ ] &#125;, &quot;serverInfo&quot; : &#123; &quot;host&quot; : &quot;rainbowhorse&quot;, &quot;port&quot; : 27017, &quot;version&quot; : &quot;4.0.3&quot;, &quot;gitVersion&quot; : &quot;7ea530946fa7880364d88c8d8b6026bbc9ffa48c&quot; &#125;, &quot;ok&quot; : 1&#125; 再次查看文档，文档并没有被更新。正如前文所述，该方式并不将修改应用到数据库。 12&gt; db.student.find(&#123;&quot;name&quot;:&quot;rainbowhorse&quot;&#125;);&#123; &quot;_id&quot; : ObjectId(&quot;5cbbd841525ed310c440610a&quot;), &quot;age&quot; : 90, &quot;name&quot; : &quot;rainbowhorse&quot;, &quot;score&quot; : 90, &quot;sex&quot; : &quot;M&quot; &#125; 注意：将explain()放置到update()之后则会提示错误。 123&gt; db.student.update(&#123;&quot;name&quot;:&quot;rainbowhorse&quot;&#125;,&#123;$set:&#123;&quot;score&quot;:99&#125;&#125;).explain(&quot;allPlansExecution&quot;);2019-04-21T10:53:40.824+0800 E QUERY [js] TypeError: db.student.update(...).explain is not a function :@(shell):1:1 在执行计划中，部分操作符需要放至explain()之前，部分需要放到explain()之后才能正确执行。 聚合查询中使用：collection.explain().aggregate(...) 执行计划相关描述缺省情况下，explain包括2个部分，queryPlanner和serverInfo。如果使用了executionStats或者allPlansExecution，则还会返回executionStats信息。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&gt; db.student.find(&#123;&quot;name&quot;:&quot;rainbowhorse&quot;&#125;).explain(&quot;allPlansExecution&quot;);&#123; &quot;queryPlanner&quot; : &#123; &quot;plannerVersion&quot; : 1, //查询计划版本 &quot;namespace&quot; : &quot;TEST.student&quot;, //被查询对象 &quot;indexFilterSet&quot; : false, //是否使用到了索引过滤 &quot;parsedQuery&quot; : &#123; //解析查询，即过滤条件是什么 &quot;name&quot; : &#123; //此处为name=rainbowhorse &quot;$eq&quot; : &quot;rainbowhorse&quot; &#125; &#125;, &quot;winningPlan&quot; : &#123; //最佳的执行计划 &quot;stage&quot; : &quot;COLLSCAN&quot;, //COLLSCAN为集合扫描 &quot;filter&quot; : &#123; //过滤条件 &quot;name&quot; : &#123; &quot;$eq&quot; : &quot;rainbowhorse&quot; &#125; &#125;, &quot;direction&quot; : &quot;forward&quot; //方向：forward &#125;, &quot;rejectedPlans&quot; : [ ] //拒绝的执行计划，此处没有 &#125;, &quot;executionStats&quot; : &#123; //执行计划相关统计信息 &quot;executionSuccess&quot; : true, //执行成功的状态 &quot;nReturned&quot; : 1, //返回结果集数目 &quot;executionTimeMillis&quot; : 0, //执行所需的时间,毫秒 &quot;totalKeysExamined&quot; : 0, //索引检查的时间 &quot;totalDocsExamined&quot; : 11, //检查文档总数 &quot;executionStages&quot; : &#123; &quot;stage&quot; : &quot;COLLSCAN&quot;, //使用集合扫描方式 &quot;filter&quot; : &#123; //过滤条件 &quot;name&quot; : &#123; &quot;$eq&quot; : &quot;rainbowhorse&quot; &#125; &#125;, &quot;nReturned&quot; : 1, //返回结果集数目 &quot;executionTimeMillisEstimate&quot; : 0, //预估的执行时间，毫秒 &quot;works&quot; : 13, //工作单元数，一个查询会被派生为一些小的工作单元 &quot;advanced&quot; : 1, //优先返回的结果数目 &quot;needTime&quot; : 11, &quot;needYield&quot; : 0, &quot;saveState&quot; : 0, &quot;restoreState&quot; : 0, &quot;isEOF&quot; : 1, &quot;invalidates&quot; : 0, &quot;direction&quot; : &quot;forward&quot;, &quot;docsExamined&quot; : 11 //文档检查数目 &#125;, &quot;allPlansExecution&quot; : [ ] &#125;, &quot;serverInfo&quot; : &#123; //服务器信息，包括主机名，端口，版本等。 &quot;host&quot; : &quot;rainbowhorse&quot;, &quot;port&quot; : 27017, &quot;version&quot; : &quot;4.0.3&quot;, &quot;gitVersion&quot; : &quot;7ea530946fa7880364d88c8d8b6026bbc9ffa48c&quot; &#125;, &quot;ok&quot; : 1&#125; 更详细的描述可以参考官方文档：https://docs.mongodb.com/manual/reference/explain-results/#executionstats Stage状态分析 stage 描述 COLLSCAN 全表扫描 IXSCAN 扫描索引 FETCH 根据索引去检索指定document SHARD_MERGE 将各个分片返回数据进行merge SORT 表明在内存中进行了排序 LIMIT 使用limit限制返回数 SKIP 使用skip进行跳过 IDHACK 针对_id进行查询 SHARDING_FILTER 通过mongos对分片数据进行查询 COUNT 利用db.coll.explain().count()之类进行count运算 COUNTSCAN count不使用Index进行count时的stage返回 COUNT_SCAN count使用了Index进行count时的stage返回 SUBPLA 未使用到索引的$or查询的stage返回 TEXT 使用全文索引进行查询时候的stage返回 PROJECTION 限定返回字段时候stage的返回 比较运算符12345678910111213$eq = &quot;=&quot;$gt (greater than ) &gt;$gte &gt;= (equal)$lt (less than) &lt;$lte &lt;= (equal)$ne (not equal) !=$in in$nin (not in) !in重点：所有的比较运算符都是出现在键与值得中间，示例如下&#123; &lt;field_name&gt;: &#123; $operator: &lt;value&gt; &#125; &#125;&#123; &lt;ename&gt;: &#123; $eq: &quot;robin&quot; &#125; &#125;&#123; &lt;qty&gt;: &#123; $gt: 20 &#125; &#125; 参考MongoDB执行计划获取(db.collection.explain()) https://docs.mongodb.com/manual/reference/explain-results/#executionstats","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://mx-go.github.io/tags/MongoDB/"}]},{"title":"SpringMVC集成Swagger","slug":"SpringMVC集成Swagger","date":"2019-04-15T14:49:48.000Z","updated":"2021-05-09T02:22:14.880Z","comments":true,"path":"SpringMVC集成Swagger/","link":"","permalink":"https://mx-go.github.io/SpringMVC%E9%9B%86%E6%88%90Swagger/","excerpt":"","text":"当前方便管理项目中的API接口，最流行的莫过于Swagger了，功能强大，UI界面漂亮，并且支持在线测试等等。所以仔细研究了下Swagger的使用。在这里记录下SpringMVC集成Swagger。 引入Maven坐标1234567891011121314151617181920212223242526272829&lt;!-- Jackson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Swagger --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt;&lt;!-- Swagger-UI插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt; &lt;version&gt;1.9.2&lt;/version&gt; &lt;/dependency&gt; Spring配置1&lt;mvc:default-servlet-handler /&gt; Swagger配置 对于Swagger的配置，其实是自定义一个与Swagger相关的Config类，可以通过Java编码的实现配置。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * @author max */@Configuration@EnableSwagger2public class SwaggerConfig &#123; // 控制是否展示Swagger @ReloadableProperty(&quot;swagger.show&quot;) private boolean swaggerShow = false; @Bean public Docket createRestApi() &#123; Predicate&lt;RequestHandler&gt; predicate = input -&gt; &#123; Class&lt;?&gt; declaringClass = input.declaringClass(); if (declaringClass == TestController.class) &#123; return false; &#125; // 被注解的类 if (declaringClass.isAnnotationPresent(RestController.class)) &#123; return true; &#125; // 被注解的方法 return input.isAnnotatedWith(ResponseBody.class); &#125;; return new Docket(DocumentationType.SWAGGER_2) .enable(swaggerShow) .apiInfo(apiInfo()) .useDefaultResponseMessages(false) .select() .apis(predicate::test) //过滤的接口 .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; // 大标题 return new ApiInfoBuilder().title(&quot;消息系统接口服务&quot;) .description(&quot;需要提供更多接口请联系 彩虹马&quot;) .contact(new Contact(&quot;max&quot;, &quot;&quot;, &quot;xxx@xxx.com&quot;)) .version(&quot;1.0&quot;) .build(); &#125;&#125; 接口Controller实例如下： Swagger注解常用注解： @Api 该注解将一个Controller（Class）标注为一个swagger资源（API）。在默认情况下，Swagger-Core只会扫描解析具有@Api注解的类，而会自动忽略其他类别资源（JAX-RS endpoints，Servlets等等）的注解。该注解包含以下几个重要属性： tags：API分组标签。具有相同标签的API将会被归并在一组内展示。 value：如果tags没有定义，value将作为Api的tags使用。 @ApiOperation 在指定的（路由）路径上，对一个操作或HTTP方法进行描述。具有相同路径的不同操作会被归组为同一个操作对象。不同的HTTP请求方法及路径组合构成一个唯一操作。此注解的属性有： value：对操作的简单说明，长度为120个字母，60个汉字。 notes：对操作的详细说明。 httpMethod：HTTP请求的动作名，可选值有：”GET”, “HEAD”, “POST”, “PUT”, “DELETE”, “OPTIONS” and “PATCH”。 code：默认为200，有效值必须符合标准的HTTP Status Code Definitions。 @ApiModelProperty 对model属性的注解，主要的属性值有： value：属性简短描述。 example：属性的示例值。 required：是否为必须值。 更多注解可参考：https://mp.weixin.qq.com/s/ZD0i1-lcqRHtgYL-HW1Xpg 效果启动服务后访问http://{ip}:{port}/doc.html即可进入Swagger。 前端UI没有采用默认的，找到了一个更漂亮的：https://github.com/xiaoymin/Swagger-Bootstrap-UI 注解和页面展示对应关系： 环境控制Swagger提供给内部使用的接口稳定，如果在生产环境不想暴露出去，有以下解决办法： 设置了spring.profiles.active 可以通过profile注解来处理。 Swagger的congif类上声明**@Profile({“dev”, “test”})**,发布到生产上使用pro的profile时， swagger是无效的。 无spring.profiles.active 12new Docket(DocumentationType.SWAGGER_2) .enable(false)","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"自定义rest代理(二)","slug":"自定义rest代理-二","date":"2019-04-13T06:45:22.000Z","updated":"2021-05-05T03:21:55.367Z","comments":true,"path":"自定义rest代理-二/","link":"","permalink":"https://mx-go.github.io/%E8%87%AA%E5%AE%9A%E4%B9%89rest%E4%BB%A3%E7%90%86-%E4%BA%8C/","excerpt":"","text":"之前用HttpClient实现了rest代理(自定义rest代理(一))，从网上看了下资料，同时针对公司已有的框架做了一些封装和改造。用Retrofit2另外实现了一套rest代理工具包。其中基本都是都是基于Retrofit2，自己又做了一层简单的封装。 源码在我的GitHub上：https://github.com/mx-go/retrofit-rest-proxy Spring配置引入Maven坐标12345&lt;dependency&gt; &lt;groupId&gt;com.github.mx-go&lt;/groupId&gt; &lt;artifactId&gt;retrofit-rest-proxy&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 在applicationContext.xml文件中加入配置123456789&lt;bean id=&quot;retrofitFactory&quot; class=&quot;com.github.proxy.core.ConfigRetrofitSpringFactory&quot; p:configLocation=&quot;classpath*:rest-proxy.json,classpath*:rest-proxy1.json&quot; init-method=&quot;init&quot;/&gt;// 可针对不同接口配置多个&lt;bean id=&quot;sendHttp&quot; class=&quot;com.github.proxy.RetrofitSpringFactoryBean&quot; p:type=&quot;com.max.open.SendHttp&quot; p:factory-ref=&quot;retrofitFactory&quot;/&gt;&lt;bean id=&quot;xxx&quot; class=&quot;com.github.proxy.RetrofitSpringFactoryBean&quot; p:type=&quot;com.max.open.xxx&quot; p:factory-ref=&quot;retrofitFactory&quot;/&gt; 其中参数： configLocation：配置文件所在路径。支持多个配置文件路径，以英文**,**隔开。 type：接口所在的路径。 基础配置针对Spring配置中的configLocation。有配置中心可修改源码从配置中心获取。以下举个例子： rest-proxy.json 1234567891011&#123; &quot;sendHttp&quot;: &#123; &quot;domain&quot;: &quot;http://localhost:8081&quot;, &quot;desc&quot;: &quot;测试使用&quot;, &quot;readTimeout&quot;: &quot;10000&quot;, &quot;connectTimeout&quot;: &quot;10000&quot; &#125;, &quot;test1&quot;: &#123; &quot;domain&quot;: &quot;127.0.0.1:8080&quot; &#125;&#125; 配置中可以存在多个KV。 domain：HTTP请求的基础域名，同时可指定为IP地址。必填。 desc：功能描述，无其他用处。 readTimeout：读取超时时间(ms)。对应Retrofit2中的readTimeout。缺省5000ms。 connectTimeout：连接超时时间(ms)，对应Retrofit2中的connectTimeout。缺省5000ms。 接口示例中用的是SendHttp测试接口： 12345678910@RetrofitConfig(value = &quot;sendHttp&quot;, desc = &quot;测试&quot;)public interface SendHttp &#123; @POST(&quot;/callback&quot;) Student getResult(@Body Student student); // 返回为void类型时需写为Void @POST(&quot;/update&quot;) Void update(@Body Student student);&#125; 重点说一下**@RetrofitConfig**注解。此注解为自定义注解，其中： value：对应的是基础配置中的Key。 desc：描述。 其余注解和使用与retrofit2一致，使用retrofit2中注解即可。 使用在service层或manager层直接注入配置完成的所需接口： 12@Autowiredprivate SendHttp sendHttp;","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"MongoDB辅助之mongo-spring-support","slug":"MongoDB辅助之mongo-spring-support","date":"2019-04-05T03:57:23.000Z","updated":"2021-05-05T03:27:45.100Z","comments":true,"path":"MongoDB辅助之mongo-spring-support/","link":"","permalink":"https://mx-go.github.io/MongoDB%E8%BE%85%E5%8A%A9%E4%B9%8Bmongo-spring-support/","excerpt":"引言在开发中经常使用到MongoDB，每个项目使用各不相同，既繁琐又好不管理。这里封装了一套MongoDB类似于Mybatis的ORM增强版工具，和Spring无缝结合，只需要简单的配置就可以实现强大的功能。同时扩展了MongoDB的Datastore功能，加了一些自定义方法。其原理离不开之前所说的FactoryBean。","text":"引言在开发中经常使用到MongoDB，每个项目使用各不相同，既繁琐又好不管理。这里封装了一套MongoDB类似于Mybatis的ORM增强版工具，和Spring无缝结合，只需要简单的配置就可以实现强大的功能。同时扩展了MongoDB的Datastore功能，加了一些自定义方法。其原理离不开之前所说的FactoryBean。 源码放在了我的GitHub上：https://github.com/mx-go/mongo-spring-support 源码中有详细使用注释，其原理就是实现FactoryBean生成代理对象并对原本的Datastore进行增强。 在这里记录下使用方法。 MongoDB数据库及集合以下测试在MongoDB的TEST库中，其中有两个集合student、student_1。student_1可以用来测试同库中，根据后缀来切换集合，相当与分表。 引入Maven坐标12345&lt;dependency&gt; &lt;groupId&gt;com.github.mx-go&lt;/groupId&gt; &lt;artifactId&gt;mongo-spring-support&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 配置管理在Spring中配置MongoDB的server地址、dbName等信息，可以配置更多参数，见MongoConfiguration类中属性。jar包中已包含mongo-java-driver和morphia。 123456789101112131415&lt;context:component-scan base-package=&quot;com.rainbowhorse.demo&quot;/&gt;&lt;!--生成代理对象，增强原方法，自定义方法--&gt; &lt;bean id=&quot;datastoreExt&quot; class=&quot;com.github.mongo.support.mongo.MongoDataStoreFactoryBean&quot;&gt; &lt;property name=&quot;configuration&quot; ref=&quot;configuration&quot;/&gt; &lt;/bean&gt; &lt;!--配置属性。可以配置更多属性，详细看MongoConfiguration类--&gt; &lt;bean id=&quot;configuration&quot; class=&quot;com.github.mongo.support.mongo.MongoConfiguration&quot;&gt; &lt;!--数据库连接--&gt; &lt;property name=&quot;servers&quot; value=&quot;mongodb://root:root@localhost:27017/TEST&quot;/&gt; &lt;!--数据库名称--&gt; &lt;property name=&quot;dbName&quot; value=&quot;TEST&quot;/&gt; &lt;!--对应实体所在路径--&gt; &lt;property name=&quot;mapPackage&quot; value=&quot;com.rainbowhorse.demo.mongo&quot;/&gt; &lt;/bean&gt; 简单使用范例简单模式123456789@Serviceclass UserService &#123; @Autowired DatastoreExt datastoreExt; public void save(User user) &#123; datastore.save(user); &#125;&#125; 单实例多库12345678910111213141516171819@Serviceclass UserService &#123; @Autowired DatastoreExt datastoreExt; public void save(User user) &#123; datastore.use(&quot;user_db&quot;).save(user); &#125;&#125;@Serviceclass BlogService &#123; @Autowired DatastoreExt datastoreExt; public void save(Blog blog) &#123; datastore.use(&quot;blog_db&quot;).save(blog); &#125;&#125; 表名添加前缀或者后缀123456789101112131415161718192021@Serviceclass UserService &#123; @Autowired DatastoreExt datastoreExt; public void save(User user) &#123; // user对象会保存到db01.2017_user的表中 datastore.getDatastoreByPrefix(&quot;db01&quot;, &quot;2017&quot;).save(user); &#125;&#125;@Serviceclass BlogService &#123; @Autowired DatastoreExt datastoreExt; public void save(Blog blog) &#123; // blog对象会保存到db02.blog_2017的表中 datastore.getDatastoreBySuffix(&quot;db02&quot;, &quot;2017&quot;).save(blog); &#125;&#125; 集合实体类StudentDOMongoDB是文档型数据库，借助morphia可以把集合映射到到Java中的Bean。 1234567891011121314151617181920212223import lombok.Data;import org.mongodb.morphia.annotations.Entity;import org.mongodb.morphia.annotations.Id;import java.io.Serializable;/** * value中存储集合名字 */@Data@Entity(value = &quot;student&quot;, noClassnameStored = true)public class StudentDO implements Serializable &#123; private static final long serialVersionUID = 2997596487756179430L; /** * 对应mongo中的_id */ @Id private String id; private Integer age; private String name; private Integer score; private String sex;&#125; 接口及实现类接口StudentDAO接口继承mongo-support中的**BaseDao**，可以实现更多方法的调用。 123456789101112131415161718192021222324252627public interface StudentDAO extends BaseDao&lt;StudentDO&gt; &#123; /** * 查询 */ List&lt;StudentDO&gt; getByScore(Integer score); /** * 更新age */ int updateAge(String id, Integer age); /** * 通过name增加score * * @return 更新结果 */ int incrScoreByName(StudentDO tenantQuotaDO); /** * 分页查询 * * @return */ List&lt;StudentDO&gt; getScoreAndPage(StudentDO studentDO, Pager&lt;StudentDO&gt; pager); int getStudentCounts(StudentDO tenantQuotaDO);&#125; 接口实现类StudentDAOImpl继承**BaseDaoImpl**，其中实现基础方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Repositorypublic class StudentDAOImpl extends BaseDaoImpl&lt;StudentDO&gt; implements StudentDAO &#123; @Autowired public StudentDAOImpl(DatastoreExt datastoreExt) &#123; super(datastoreExt, StudentDO.class); &#125; @Override public List&lt;StudentDO&gt; getByScore(Integer score) &#123; Query&lt;StudentDO&gt; query = createQuery(); query.criteria(&quot;score&quot;).equal(score); return query.asList(); &#125; @Override public int updateAge(String id, Integer age) &#123; Query&lt;StudentDO&gt; query = createQuery(); query.field(&quot;_id&quot;).equal(new ObjectId(id)); final UpdateOperations&lt;StudentDO&gt; update = createUpdateOperations(); update.set(&quot;age&quot;, age); return getDatastore().update(query, update).getUpdatedCount(); &#125; @Override public List&lt;StudentDO&gt; getScoreAndPage(StudentDO studentDO, Pager&lt;StudentDO&gt; pager) &#123; return queryList(studentDO, pager.offset(), pager.getPageSize()); &#125; @Override public int getStudentCounts(StudentDO studentDO) &#123; return (int) queryCount(studentDO); &#125; @Override public int incrScoreByName(StudentDO studentDO) &#123; Query&lt;StudentDO&gt; query = createQuery(studentDO); UpdateOperations&lt;StudentDO&gt; updateOperation = createUpdateOperations().inc(&quot;score&quot;, 1); return getDatastore().update(query, updateOperation).getUpdatedCount(); &#125;&#125; 单元测试123456789101112131415161718192021222324252627282930313233343536373839@Autowired private StudentDAO studentDAO;@Test public void test() &#123; List&lt;StudentDO&gt; name1 = studentDAO.getByScore(88); System.out.println(name1.size()); StudentDO studentDO = new StudentDO(); studentDO.setName(&quot;max10&quot;); System.out.println(studentDAO.incrScoreByName(studentDO)); StudentDO studentDO1 = new StudentDO(); studentDO1.setScore(88); Pager&lt;StudentDO&gt; pager = new Pager&lt;&gt;(); pager.setPageSize(2); pager.setCurrentPage(2); List&lt;StudentDO&gt; scoreAndPage = studentDAO.getScoreAndPage(studentDO1, pager); System.out.println(scoreAndPage); System.out.println(studentDAO.getStudentCounts(new StudentDO())); int age = studentDAO.updateAge(&quot;5ca6b118a03b9e0e7f5bb33c&quot;, 20); System.out.println(age); &#125;/** * 测试扩展动态切换集合 */ @Test public void TestDatastore() &#123; DatastoreExt datastore = datastoreExt.getDatastoreBySuffix(&quot;TEST&quot;, &quot;1&quot;); studentDAO = new StudentDAOImpl(datastore); List&lt;StudentDO&gt; name1 = studentDAO.getByScore(66); System.out.println(name1); &#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://mx-go.github.io/tags/MongoDB/"}]},{"title":"自定义rest代理(一)","slug":"自定义rest代理","date":"2019-03-24T01:44:49.000Z","updated":"2021-05-05T03:22:05.983Z","comments":true,"path":"自定义rest代理/","link":"","permalink":"https://mx-go.github.io/%E8%87%AA%E5%AE%9A%E4%B9%89rest%E4%BB%A3%E7%90%86/","excerpt":"","text":"引言在项目中可能我们会调用其他的rest接口，我们会写一个HttpClientSender工具类，返回后然后一大堆的条件判断，既繁琐又不直观。我们可以运用所学的FactoryBean手写一个rest代理，使用时可以像Mybatis那样注入接口就可以，方便又简洁。 此工具类是依据HttpClient编写的。灵活性比较高，代码量也是比较多，还是有一些局限性，比如请求方法只支持GET、POST、PUT、DELETE等。 FactoryBean使用FactoryBean来动态获取代理对象，这里我们定义一个RestServiceProxyFactoryBean&lt;T&gt;实现FactoryBean接口。 12345678910111213141516171819202122232425262728293031/** * @param &lt;T&gt; * @author max */@Datapublic class RestServiceProxyFactoryBean&lt;T&gt; implements FactoryBean&lt;T&gt; &#123; /** * RestServiceProxyFactory路径 */ private RestServiceProxyFactory factory; /** * 接口路径 */ private Class&lt;T&gt; type; @Override public T getObject() throws Exception &#123; return factory.newRestServiceProxy(type); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return type; &#125; @Override public boolean isSingleton() &#123; return true; &#125;&#125; RestServiceProxyFactoryBean有两个参数： RestServiceProxyFactory：创建代理对象的factory，下面会说到。 type：接口所在路径。 代理工厂RestServiceProxyFactory当程序调用rest接口时，会由代理工厂根据各种配置生成代理对象并填充返回结果。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * @author max */@Slf4j@Datapublic class RestServiceProxyFactory &#123; private final static RestClient restClient = new RestClient(); private ServiceConfigManager configManager; /** * 配置文件路径 */ private String location; public RestServiceProxyFactory() &#123; &#125; public void init() &#123; configManager = ServiceConfigManager.build(location); &#125; public &lt;T&gt; T newRestServiceProxy(Class&lt;T&gt; clazz) &#123; return Reflection.newProxy(clazz, new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(this, args); &#125; if (method.isDefault()) &#123; MethodHandle methodHandler = RestServiceProxyFactory.this.getMethodHandler(method); return methodHandler.bindTo(proxy).invokeWithArguments(args); &#125; InvokeParams invokeParams = InvokeParams.getInstance(configManager, method, args); Object ret = null; try &#123; ret = restClient.invoke(invokeParams); &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; return ret; &#125; &#125;); &#125; private MethodHandle getMethodHandler(Method method) throws NoSuchMethodException, IllegalAccessException, InstantiationException, java.lang.reflect.InvocationTargetException &#123; Constructor&lt;MethodHandles.Lookup&gt; constructor = MethodHandles.Lookup.class .getDeclaredConstructor(Class.class, int.class); constructor.setAccessible(true); Class&lt;?&gt; declaringClass = method.getDeclaringClass(); int allModes = (MethodHandles.Lookup.PUBLIC | MethodHandles.Lookup.PRIVATE | MethodHandles.Lookup.PROTECTED | MethodHandles.Lookup.PACKAGE); return constructor.newInstance(declaringClass, allModes) .unreflectSpecial(method, declaringClass); &#125;&#125; 开源地址由代理对象根据配置可以调用HTTP请求反序列化并封装返回结果，这样就不需要自己做其他的工作。项目已经更新到我的GitHub：https://github.com/mx-go/rest-proxy，READM中有使用方法。打成jar放到自己的项目中即可使用。","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Spring之FactoryBean","slug":"Spring之FactoryBean","date":"2019-03-16T09:30:37.000Z","updated":"2021-05-09T02:22:23.380Z","comments":true,"path":"Spring之FactoryBean/","link":"","permalink":"https://mx-go.github.io/Spring%E4%B9%8BFactoryBean/","excerpt":"","text":"引言FactoryBean 与 BeanFactory名字很像，很容易搞混。但其实它们两个是完全不一样的东东。 BeanFactory： 以Factory结尾，表示它是一个工厂类，是用于管理Bean的一个工厂。BeanFactory是 IOC 容器的核心接口。它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。 FactoryBean：以Bean结尾，表示它是一个Bean，不同于普通Bean的是：实现了FactoryBean接口的Bean，根据该Bean的Id从BeanFactory中获取的实际上是FactoryBean的getObject()返回的对象，而不是FactoryBean本身， 如果要获取FactoryBean对象，可以在id前面加一个&amp;符号来获取。 实例需要在调用dubbo接口时加一层自己的逻辑，实现不同的功能。例如判断直接调用别人接口还是调用HTTP接口。 原本有两个dubbo接口，通讯录员工、通讯录企业接口，如下所示： 1234567891011121314151617181920&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:application name=&quot;test&quot;/&gt; &lt;!-- ZK配置 --&gt; &lt;dubbo:registry id=&quot;remote&quot; address=&quot;zookeeper://10.113.29.1:2181?backup=10.113.29.2:2181,10.113.29.3:2181&quot; protocol=&quot;dubbo&quot;/&gt; &lt;!-- 通讯录员工接口 --&gt; &lt;dubbo:reference registry=&quot;remote&quot; id=&quot;employeeService&quot; interface=&quot;com.facishare.open.addressbook.api.EmployeeService&quot; version=&quot;1.1&quot; protocol=&quot;dubbo&quot; timeout=&quot;5000&quot; check=&quot;false&quot;/&gt; &lt;!-- 通讯录企业接口 --&gt; &lt;dubbo:reference registry=&quot;remote&quot; id=&quot;enterpriseService&quot; interface=&quot;com.facishare.open.addressbook.api.EnterpriseService&quot; protocol=&quot;dubbo&quot; timeout=&quot;5000&quot; check=&quot;false&quot; version=&quot;1.1&quot;/&gt;&lt;/beans&gt; 代理对象需要新建一个代理对象，实现上述两个接口： 12345public interface OrganizationServiceProxy extends EmployeeService, EnterpriseService &#123; // 可添加自定义方法 String getCode(String tenantId);&#125; FactoryBean(重点) FactoryBean有三个方法，意义非常明确： getObject希望返回需要注册到Spring容器中去的bean实体。 getObjectType希望返回注册的这个Object的具体类型。 isSingleton方法希望返回这个bean是不是单例的。如果是，那么Spring容器全局将只保持一个该实例对象，否则每次getBean都将获取到一个新的该实例对象。 因为需要动态获取bean，所以同时实现了InitializingBean和ApplicationContextAware接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class OrganizationServiceFactoryBean implements InitializingBean, ApplicationContextAware, FactoryBean&lt;EmployeeServiceProxy&gt; &#123; /** * 代理对象，可直接注入使用 */ private OrganizationServiceProxy organizationServiceProxy; /** * 被代理对象的bean名称，以逗号隔开 */ private String beanNames; public void setBeanName(String beanNames) &#123; this.beanNames = beanNames; &#125; private static ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; OrganizationServiceFactoryBean.applicationContext = applicationContext; &#125; @Override public OrganizationServiceProxy getObject() throws Exception &#123; return organizationServiceProxy; &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return OrganizationServiceProxy.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125; @Override public void afterPropertiesSet() throws Exception &#123; List&lt;String&gt; list = Splitter.on(&quot;,&quot;).splitToList(beanNames); List&lt;Object&gt; instances = Lists.newArrayList(); // 判断bean是否存在走对应的条件 /*if (!applicationContext.containsBean(list.get(0))) &#123; employeeServiceProxy = new EmployeeServiceProxyImpl(); return; &#125;*/ list.forEach(o -&gt; &#123; instances.add(applicationContext.getBean(o)); &#125;); OrganizationHandler handler = new OrganizationHandler(instances); organizationServiceProxy = Reflection.newProxy(OrganizationServiceProxy.class, handler); &#125;&#125; 处理器123456789101112131415161718192021222324252627282930313233343536@Datapublic class OrganizationHandler implements InvocationHandler &#123; /** * 被代理对象实例的List集合 */ private List instances; public OrganizationHandler(List instances) &#123; this.instances = instances; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // OrganizationServiceProxy中的自定义方法可以在这里实现 switch (method.getName()) &#123; case &quot;OrganizationServiceProxy 的toString()方法&quot;: return &quot;&quot;; case &quot;getCode&quot;: System.out.println(args); // dosomething... break; &#125; for (Object instance : instances) &#123; Method[] methods = instance.getClass().getDeclaredMethods(); for (Method method1 : methods) &#123; if (method.getName().equals(method1.getName())) &#123; return method.invoke(instance, args); &#125; &#125; &#125; // something else... return null; &#125;&#125; Spring文件配置123456789101112131415161718192021222324252627282930&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd&quot;&gt; &lt;dubbo:application name=&quot;test&quot;/&gt; &lt;!--ceshi112 ZK--&gt; &lt;dubbo:registry id=&quot;remote&quot; address=&quot;zookeeper://10.113.29.1:2181?backup=10.113.29.2:2181,10.113.29.3:2181&quot; protocol=&quot;dubbo&quot;/&gt; &lt;!-- 通讯录员工 --&gt; &lt;dubbo:reference registry=&quot;remote&quot; id=&quot;employeeService&quot; interface=&quot;com.facishare.open.addressbook.api.EmployeeService&quot; version=&quot;1.1&quot; protocol=&quot;dubbo&quot; timeout=&quot;5000&quot; check=&quot;false&quot;/&gt; &lt;!-- 通讯录企业 --&gt; &lt;dubbo:reference registry=&quot;remote&quot; id=&quot;enterpriseService&quot; interface=&quot;com.facishare.open.addressbook.api.EnterpriseService&quot; protocol=&quot;dubbo&quot; timeout=&quot;5000&quot; check=&quot;false&quot; version=&quot;1.1&quot;/&gt; &lt;!-- 通过beanFactory获取organizationServiceProxy代理对象 --&gt; &lt;bean id=&quot;organizationServiceProxy&quot; class=&quot;com.facishare.open.demo.proxy.OrganizationServiceFactoryBean&quot; p:beanName=&quot;employeeService,enterpriseService&quot;/&gt;&lt;/beans&gt; 单元测试123456789101112131415@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123;&quot;classpath:applicationContext.xml&quot;,&quot;classpath:dubbo-consumer.xml&quot;&#125;)@Slf4jpublic class DubboTest &#123; @Autowired private OrganizationServiceProxy organizationServiceProxy; @Test public void testProxy() &#123; ListResult&lt;Integer&gt; ids = organizationServiceProxy.getAdminIds(&quot;61037&quot;); System.out.println(ids); ListResult&lt;EnterpriseSimpleInfo&gt; list = organizationServiceProxy.getEnterpriseSimpleList(Lists.newArrayList(61037)); System.out.println(list); &#125;&#125; 总结FactoryBean的功能更像是一种代理。有一种场景是，我们使用一个通用的类来在xml文件中注册bean，我们希望通过该通用bean产生另外一个我们希望的bean，而这个需求FactoryBean就可以办到，只需要拦你需要代理的bean，然后转换成希望的bean再注册。一个应用场景就是Rpc服务器端的bean注册，以及Rpc客户端的服务调用，都可以通过一个第三方bean来产生我们真正需要的bean。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"MongoDB索引管理(二)","slug":"MongoDB索引管理","date":"2019-01-26T07:17:03.000Z","updated":"2021-05-05T03:27:54.334Z","comments":true,"path":"MongoDB索引管理/","link":"","permalink":"https://mx-go.github.io/MongoDB%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86/","excerpt":"引言在数据量超大的情形下，任何数据库系统在创建索引时都是一个耗时的大工程。MongoDB也不例外。MongoDB索引的创建有两个选择：一个是前台方式，一个是后台方式。","text":"引言在数据量超大的情形下，任何数据库系统在创建索引时都是一个耗时的大工程。MongoDB也不例外。MongoDB索引的创建有两个选择：一个是前台方式，一个是后台方式。 创建索引索引创建方式前台方式(缺省) 12缺省情况下，当为一个集合创建索引时，这个操作将阻塞其他的所有操作。即该集合上的无法正常读写，直到索引创建完毕任意基于所有数据库申请读或写锁都将等待直到前台完成索引创建操作。 后台方式 12345将索引创建置于到后台，适用于那些需要长时间创建索引的情形这样在创建索引期间，MongoDB依旧可以正常的提供读写操作服务等同于关系型数据库在创建索引的时候指定online,而MongoDB则是指定background,其目的都是相同的即在索引创建期间，尽可能的以一种占用较少的资源方式来实现，同时又可以提供读写服务。后台创建方式的代价：索引创建时间变长。 语法结构MongoDB创建索引使用ensureIndex()方法。 1db.COLLECTION_NAME.ensureIndex(keys[,options]) Keys ： 要创建的索引字段 1 按升序创建索引 -1 按降序来创建索引 可选参数 参数名 类型 描述 background Boolean 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加 “background” 可选参数。 “background” 默认值为false unique Boolean 建立的索引是否唯一。指定为true创建唯一索引。默认值为 false name string 索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称 dropDups Boolean 3.0+版本已废弃。在建立唯一索引时是否删除重复记录，指定 true 创建唯一索引。默认值为false sparse Boolean 对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档。默认值为 false expireAfterSeconds integer 指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。 v index version 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。 weights document 索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重 default_language string 对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 默认为英语 language_override string 对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认的 language，默认值为 language 后台创建范例1db.COLLECTION_NAME.ensureIndex(&#123;name: 1, age: 1&#125;, &#123;background: true&#125;); 通过在创建索引时加 background:true 选项，让创建工作在后台执行。 使用索引和不使用差距很大，合理使用索引，一个集合适合做 4-5 个索引。 查看索引创建进度可使用 db.currentOp() 命令观察索引创建的完成进度。 123456&gt; db.currentOp(&#123; $or: [ &#123; op: &quot;command&quot;, &quot;query.createIndexes&quot;: &#123; $exists: true &#125; &#125;, &#123; op: &quot;insert&quot;, ns: /\\.system\\.indexes\\b/ &#125; ]&#125;); 终止索引的创建1db.killOp(); 查看索引MongoDB提供了查看索引信息的方法： getIndexes()：查看集合的所有索引; totalIndexSize()：查看集合索引的总大小; db.system.indexes.find()：查看数据库中所有索引信息。 查看集合中的索引getIndexes()1db.COLLECTION_NAME.getIndexes(); 查看集合中的索引大小totalIndexSize()1db.COLLECTION_NAME.totalIndexSize(); 查看数据库中所有索引db.system.indexes.find()1db.system.indexes.find(); 删除索引不再需要的索引，可以将其删除。删除索引时，可以删除集合中的某一索引，也可以删除全部索引。 删除指定的索引dropIndex()1db.COLLECTION_NAME.dropIndex(&quot;INDEX-NAME&quot;); 删除所有索引dropIndexes()1db.COLLECTION_NAME.dropIndexes(); 重建索引数据表经多次修改后导致文件产生空洞，索引文件也是如此。因此可通过重建索引来提高索引的查询效率，类似MySQL的optimize表。根据MongoDB文档，通常不需要定期重建索引，且始终在前台构建索引。 官网文档可查看：https://docs.mongodb.com/manual/reference/command/reIndex/ 12// 该方法的调用不接受任何的参数db.COLLECTION_NAME.reIndex();","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://mx-go.github.io/tags/MongoDB/"}]},{"title":"浅谈设计文档","slug":"浅谈设计文档","date":"2019-01-22T14:21:20.000Z","updated":"2022-03-09T10:56:35.309Z","comments":true,"path":"浅谈设计文档/","link":"","permalink":"https://mx-go.github.io/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3/","excerpt":"引言经常听到调侃程序员的一句话”程序员最烦写文档，也最烦别人不写文档”。文档在项目开发中非常重要，首先是自己对产品和设计要非常熟悉才能写出一篇好的设计文档，其次文档可以让别人快速理解技术架构，快速上手。这里总结下自己这几年写概要设计文档的经验。","text":"引言经常听到调侃程序员的一句话”程序员最烦写文档，也最烦别人不写文档”。文档在项目开发中非常重要，首先是自己对产品和设计要非常熟悉才能写出一篇好的设计文档，其次文档可以让别人快速理解技术架构，快速上手。这里总结下自己这几年写概要设计文档的经验。 产品文档产品文档虽然是产品经理编写，但是我们还是要去了解其中详细的信息，尤其是开发背景和整体原型。这样才能开发出符合产品设计的产品。 环境信息记录开发及测试环境的数据库用户名/密码，部署的服务信息及服务部署的主机信息。生产环境的主机信息等。 技术架构技术架构也可设计为整理模型，说明的是后台技术大的框架。 模块设计，可以写以下内容： 1、模块描述：说明哪些模块实现了哪些功能； 2、模块层次结构：可以使用某个视角的软件框架图来表达； 3、模块间的关系：模块间依赖关系的描述，通信机制描述； 4、模块的核心接口：说明模块传递的信息、信息的结构； 5、处理方式设计：说一些满足功能和性能的算法。 下面是个简单的例子： 整体流程图 描述的是整个流程时序图，当然可附带些描述性文字 ER图实体-联系图，描述实体类型、属性和联系的方法。在表设计中也有体现。 时序图描述请求详细流程的时序图。 数据表将设计的数据库文档及语句记录下来。描述每个字段的含义，可包含字段、类型、Enum、描述、备注列，将设计的SQL文件上传，有更新时需及时更新。 缓存将用到的缓存设计记录下来，无论是jvmCache还是中间件。 接口前后端的接口文档，可链接到接口文档页面。 压测报告针对该功能的压测报告。 特殊点及疑问点 将有问题的点记录，后续解决。 迭代记录记录每次迭代的新增功能或修改记录。","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"MongoDB中的索引(一)","slug":"MongoDB中的索引","date":"2019-01-17T02:17:20.000Z","updated":"2021-05-05T03:28:05.319Z","comments":true,"path":"MongoDB中的索引/","link":"","permalink":"https://mx-go.github.io/MongoDB%E4%B8%AD%E7%9A%84%E7%B4%A2%E5%BC%95/","excerpt":"引言在 MongoDB 典型的数据库查询场景中，索引 index 扮演着非常重要的作用，如果没有索引，MongoDB 需要为了找到一个匹配的文档而扫描整个 collection，代价非常高昂。","text":"引言在 MongoDB 典型的数据库查询场景中，索引 index 扮演着非常重要的作用，如果没有索引，MongoDB 需要为了找到一个匹配的文档而扫描整个 collection，代价非常高昂。 实例MongoDB 的索引使用的 B-tree 这一特殊的数据结构，借助索引 MongoDB 可以高效的匹配到需要查询的数据，以下图来为例(来自官方)： score 索引不但可以高效的支持 range 查询，此外也可以让 MongoDB 高效地返回排序之后的数据，MongoDB 的索引同其它数据库系统很相似，MongoDB 的索引是定义在 collection 级别的，支持对任何单个 field 以及任何 sub-field 建立索引。 默认的 _id indexMongoDB 在 collection 创建时会默认建立一个基于_id的唯一性索引作为 document 的 primary key，这个 index 无法被删除。 Mongodb 支持多种方式创建索引，具体创建方式见官方文档 https://docs.mongodb.com/manual/indexes/#create-an-index Single field index - 单索引Single field index 是 MongoDB 最简单的索引类型，不同于 MySQL，MongoDB 的索引是有序的 ascending 或 descending。 但是对于 single field index 来说，索引的顺序无关紧要，因为 MongoDB 支持任意顺序遍历 single field index。 在此创建一个 records collection： 12345&#123; &quot;_id&quot;: ObjectId(&quot;570c04a4ad233577f97dc459&quot;), &quot;score&quot;: 1034, &quot;location&quot;: &#123; state: &quot;NY&quot;, city: &quot;New York&quot; &#125;&#125; 然后创建一个 single field index： 1db.records.createIndex( &#123; score: 1 &#125; ) 上面的语句在 collection 的 score field 上创建了一个 ascending 索引，这个索引支持以下查询： 12db.records.find( &#123; score: 2 &#125; )db.records.find( &#123; score: &#123; $gt: 10 &#125; &#125; ) 可以使用 MongoDB 的 explain 来对以上两个查询进行分析： 1db.records.find(&#123;score:2&#125;).explain(&#x27;executionStats&#x27;) single index on embedded field - 内嵌字段上的单索引此外 MongoDB 还支持对 embedded field 进行索引创建： 1db.records.createIndex( &#123; &quot;location.state&quot;: 1 &#125; ) 上面的 embedded index 支持以下查询： 12db.records.find( &#123; &quot;location.state&quot;: &quot;CA&quot; &#125; )db.records.find( &#123; &quot;location.city&quot;: &quot;Albany&quot;, &quot;location.state&quot;: &quot;NY&quot; &#125; ) sort on single index - 单索引的排序对于 single index 来说，由于 MongoDB index 本身支持顺序查找，所以对于single index 来说: 123db.records.find().sort( &#123; score: 1 &#125; )db.records.find().sort( &#123; score: -1 &#125; )db.records.find(&#123;score:&#123;$lte:100&#125;&#125;).sort( &#123; score: -1 &#125; ) 这些查询语句都是满足使用 index 的。 Compound index - 组合索引Mongodb 支持对多个 field 建立索引，称之为 compound index。Compound index 中 field 的顺序对索引的性能有至关重要的影响，比如索引 {userid:1, score:-1} 首先根据 userid 排序，然后再在每个 userid 中根据 score 排序。 创建 Compound index在此创建一个 products collection： 12345678&#123; &quot;_id&quot;: ObjectId(...), &quot;item&quot;: &quot;Banana&quot;, &quot;category&quot;: [&quot;food&quot;, &quot;produce&quot;, &quot;grocery&quot;], &quot;location&quot;: &quot;4th Street Store&quot;, &quot;stock&quot;: 4, &quot;type&quot;: &quot;cases&quot;&#125; 然后创建一个 compound index： 1db.products.createIndex( &#123; &quot;item&quot;: 1, &quot;stock&quot;: 1 &#125; ) 这个 index 引用的 document 首先会根据 item 排序，然后在 每个 item 中，又会根据 stock 排序，以下语句都满足该索引： 12db.products.find( &#123; item: &quot;Banana&quot; &#125; )db.products.find( &#123; item: &quot;Banana&quot;, stock: &#123; $gt: 5 &#125; &#125; ) 条件 {item: “Banana”} 满足是因为这个 query 满足 prefix 原则。 使用 compound index 需要满足 prefix 原则Index prefix 是指 index fields 的左前缀子集，考虑以下索引： 1&#123; &quot;item&quot;: 1, &quot;location&quot;: 1, &quot;stock&quot;: 1 &#125; 这个索引包含以下 index prefix： 12&#123; item: 1 &#125;&#123; item: 1, location: 1 &#125; 所以只要语句满足 index prefix 原则都是可以支持使用 compound index ： 123db.products.find( &#123; item: &quot;Banana&quot; &#125; )db.products.find( &#123; item: &quot;Banana&quot;,location:&quot;4th Street Store&quot;&#125; )db.products.find( &#123; item: &quot;Banana&quot;,location:&quot;4th Street Store&quot;,stock:4&#125;) 相反如果不满足 index prefix 则无法使用索引，比如以下 field 的查询： the location field the stock field the location and stock fields 由于 index prefix 的存在，如果一个 collection 既有 {a:1, b:1} 索引 ，也有 {a:1} 索引，如果二者没有稀疏或者唯一性的要求，single index 可以移除。 Sort on Compound index - 复合索引的排序前文说过 single index 的 sort 顺序无关紧要，但是 compound index 则完全不同，考虑有如下场景： 1db.events.find().sort( &#123; username: 1, date: -1 &#125; ) 上面的查询首先根据 username 进行 ascending 排序，然后再对结果进行 date descending 。 下面的查询： 1db.events.find().sort( &#123; username: -1, date: 1 &#125; ) 则是首先根据 username 进行 descending 排序，然后再对 date 进行 ascending 排序。 如果想要索引满足以上两种查询和排序，索引类型需要满足如下条件： 1db.events.createIndex( &#123; &quot;username&quot; : 1, &quot;date&quot; : -1 &#125; ） 也就是 username 和 date 的顺序不同，如果顺序相同则没有办法满足以上查询，比如： 1db.events.find().sort( &#123; username: 1, date: 1 &#125;) 也就是说 sort 的顺序必须要和创建索引的顺序是一致的，一致的意思是不一定非要一样，总结起来大致如下： { “username” : 1, “date” : -1 } { “username” : 1, “date” : 1 } sort( { username: 1, date: -1 } ) 支持 不支持 sort( { username: -1, date: 1 } ) 支持 不支持 sort( { username: 1, date: 1 } ) 不支持 支持 sort( { username: -1, date: -1 } ) 不支持 支持 即排序的顺序必须要和索引一致，逆序之后一致也可以，下表清晰的列出了 compound index 满足的 query 语句： query index db.data.find().sort( { a: 1 } ) { a: 1 } db.data.find().sort( { a: -1 } ) { a: 1 } db.data.find().sort( { a: 1, b: 1 } ) { a: 1, b: 1 } db.data.find().sort( { a: -1, b: -1 } ) { a: 1, b: 1 } db.data.find().sort( { a: 1, b: 1, c: 1 } ) { a: 1, b: 1, c: 1 } db.data.find( { a: { $gt: 4 } } ).sort( { a: 1, b: 1 } ) { a: 1, b: 1 } 即排序的 filed 也要满足 index prefix 原则。 非 index prefix 的排序考虑索引 { a: 1, b: 1, c: 1, d: 1 }，即使排序的 field 不满足 index prefix 也是可以的，但前提条件是排序 field 之前的 index field 必须是等值条件， Example Index Prefix r1 db.data.find( { a: 5 } ).sort( { b: 1, c: 1 } ) { a: 1 , b: 1, c: 1 } r2 db.data.find( { b: 3, a: 4 } ).sort( { c: 1 } ) { a: 1, b: 1, c: 1 } r3 db.data.find( { a: 5, b: { $lt: 3} } ).sort( { b: 1 } ) { a: 1, b: 1 } 上面表格 r1 的排序 field 是 b 和 c，a 是 index field 而且在 b 和 c 之前，可以使用索引；r3 的排序中 b 是范围查询，但是 b 之前的 a 用的也是等值条件，也就是只要排序 field 之前的 field 满足等值条件即可，其它的 field 可以任意条件。 如何建立正确索引前文基本覆盖了日常使用 MongoDB 所需要的主要索引知识，但是如何才建立正确的索引？ 使用 explain 分析查询语句MongoDB 默认提供了类似 MySQL explain 的语句来分析查询语句的来对我们正确建立索引提供帮助，在建立索引时我们需要对照 explain 对各种查询条件进行分析。 理解 field 顺序对索引的影响索引的真正作用是帮助我们限制数据的选择范围，比如 Compound index 多个 feild 的顺序如何决定，应该首选可以最大化的缩小数据查找范围的 field，这样如果第一个 field 可以迅速缩小数据的查找范围，那么后续的 feild 匹配的行就会变少很多。考虑语句： 1&#123;&#x27;start_time&#x27;: &#123;&#x27;$lte&#x27;: present&#125;, &#x27;end_time&#x27;: &#123;&#x27;$gt&#x27;: present&#125;, &#x27;origin&#x27;: 1, &#x27;orientation&#x27;: &#x27;quality&#x27;, &#x27;id&#x27;: &#123;&#x27;$gt&#x27;: max_id&#125;&#125; 考虑如下索引 索引 nscanded r1 {start_time:1, end_time: 1, origin: 1, id: 1, orientation: 1} 12959 r2 {start_time:1, end_time: 1, origin: 1, orientation: 1, id: 1} 2700 由于 field id 和 orientation 的顺序不同会导致需要扫描的 documents 数量差异巨大，说明二者对对数据的限制范围差别很大，优先考虑能够最大化限制数据范围的索引顺序。 监控慢查询始终对生成环境产生的慢查询进行第一时间分析，提早发现问题并解决。 参考资料 https://docs.mongodb.com/manual/core/index-compound/ http://www.infoq.com/cn/articles/improve-find-performance-in-mongo","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://mx-go.github.io/tags/MongoDB/"}]},{"title":"protostuff序列化","slug":"protostuff序列化","date":"2019-01-09T05:50:09.000Z","updated":"2021-05-05T03:28:39.983Z","comments":true,"path":"protostuff序列化/","link":"","permalink":"https://mx-go.github.io/protostuff%E5%BA%8F%E5%88%97%E5%8C%96/","excerpt":"引言HTTP通信离不开对象的序列化和反序列化。通过序列化技术，可以跨语言实现数据的传输，将对象转换为字节序列，然后在网络上传送；通过反序列化，可以将字节序列转换为对象。","text":"引言HTTP通信离不开对象的序列化和反序列化。通过序列化技术，可以跨语言实现数据的传输，将对象转换为字节序列，然后在网络上传送；通过反序列化，可以将字节序列转换为对象。 基本原理和网络通信是一致的，通过特殊的编码方式，写入数据将对象以及其内部数据编码，存在在数组或者文件里面然后发送到目的地后，在进行解码，读出数据。 protostuffprotostuff是Google出品的一种轻量并且高效的结构化数据存储格式，性能比 JSON、XML 要高很多。 之所以性能如此好，主要得益于两个：第一，它使用 proto 编译器，自动进行序列化和反序列化，速度非常快，应该比 XML 和 JSON 快上了 20~100 倍；第二，它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。 详细效率对比可参考：java序列化/反序列化之xstream、protobuf、protostuff 的比较与使用例子 maven依赖12345678910&lt;dependency&gt; &lt;groupId&gt;io.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt; &lt;version&gt;1.6.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt; &lt;version&gt;1.6.0&lt;/version&gt;&lt;/dependency&gt; 继承父类方式123456public interface CanProto &#123; byte[] toProto(); void fromProto(byte[] bytes);&#125; 123456789101112public class ProtoBase implements CanProto, Serializable &#123; @Override public byte[] toProto() &#123; Schema schema = RuntimeSchema.getSchema(getClass()); return ProtobufIOUtil.toByteArray(this, schema, LinkedBuffer.allocate(256)); &#125; @Override public void fromProto(byte[] bytes) &#123; Schema schema = RuntimeSchema.getSchema(getClass()); ProtobufIOUtil.mergeFrom(bytes, this, schema); &#125;&#125; 此方式可以使用Javabean继承ProtoBase类实现序列化。 ProtostuffUtil工具类方式ProtostuffUtil.java 12345678910111213141516171819202122232425262728import io.protostuff.LinkedBuffer;import io.protostuff.ProtobufIOUtil;import io.protostuff.ProtostuffIOUtil;import io.protostuff.Schema;import io.protostuff.runtime.RuntimeSchema;public class ProtostuffUtil &#123; public ProtostuffUtil() &#123; &#125; public static &lt;T&gt; byte[] serializer(T o) &#123; Schema schema = RuntimeSchema.getSchema(o.getClass()); return ProtobufIOUtil.toByteArray(o, schema, LinkedBuffer.allocate(256)); &#125; public static &lt;T&gt; T deserializer(byte[] bytes, Class&lt;T&gt; clazz) &#123; T obj = null; try &#123; obj = clazz.newInstance(); Schema schema = RuntimeSchema.getSchema(obj.getClass()); ProtostuffIOUtil.mergeFrom(bytes, obj, schema); &#125; catch (InstantiationException | IllegalAccessException e) &#123; e.printStackTrace(); &#125; return obj; &#125;&#125; 测试beanStudent.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495import io.protostuff.Tag;public class Student &#123; // 关于@Tag,要么所有属性都有@Tag注解,要么都没有,不能一个类中只有部分属性有@Tag注解 @Tag(1) private String name; @Tag(2) private String studentNo; @Tag(3) private int age; @Tag(4) private String schoolName; @Tag(5) private Gender gender; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getStudentNo() &#123; return studentNo; &#125; public void setStudentNo(String studentNo) &#123; this.studentNo = studentNo; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getSchoolName() &#123; return schoolName; &#125; public void setSchoolName(String schoolName) &#123; this.schoolName = schoolName; &#125; public Gender getGender() &#123; return gender; &#125; public void setGender(Gender gender) &#123; this.gender = gender; &#125; @Override public String toString() &#123; return &quot;Student&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, studentNo=&#x27;&quot; + studentNo + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &quot;, schoolName=&#x27;&quot; + schoolName + &#x27;\\&#x27;&#x27; + &quot;, gender=&quot; + gender + &#x27;&#125;&#x27;; &#125;&#125;enum Gender &#123; MAIL(1, &quot;MAIL&quot;), FEMAIL(2, &quot;FEMAIL&quot;); private Integer order; private String gender; Gender(int order, String gender) &#123; this.order = order; this.gender = gender; &#125; public Integer getOrder() &#123; return order; &#125; public String getGender() &#123; return gender; &#125; @Override public String toString() &#123; return &quot;Gender&#123;&quot; + &quot;order=&quot; + order + &quot;, gender=&#x27;&quot; + gender + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; test类ProtostuffUtilTest.java 12345678910111213141516import java.util.Arrays;public class ProtostuffUtilTest &#123; public static void main(String[] args) &#123; Student student = new Student(); student.setName(&quot;rainbowhorse&quot;); student.setAge(24); student.setStudentNo(&quot;20112214010&quot;); student.setSchoolName(&quot;ZNMZDX&quot;); student.setGender(Gender.MAIL); byte[] serializerResult = ProtostuffUtil.serializer(student); System.out.println(&quot;serializer result:&quot; + Arrays.toString(serializerResult)); Student deSerializerResult = ProtostuffUtil.deserializer(serializerResult, Student.class); System.out.println(&quot;deSerializerResult:&quot; + deSerializerResult.toString()); &#125;&#125; 输出12serializer result:[10, 12, 114, 97, 105, 110, 98, 111, 119, 104, 111, 114, 115, 101, 18, 11, 50, 48, 49, 49, 50, 50, 49, 52, 48, 49, 48, 24, 24, 34, 6, 90, 78, 77, 90, 68, 88, 40, 0]deSerializerResult:Student&#123;name=&#x27;rainbowhorse&#x27;, studentNo=&#x27;20112214010&#x27;, age=24, schoolName=&#x27;ZNMZDX&#x27;, gender=Gender&#123;order=1, gender=&#x27;MAIL&#x27;&#125;&#125;","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"自定义StopWatch","slug":"自定义StopWatch","date":"2018-12-22T13:34:34.000Z","updated":"2021-05-05T03:22:16.819Z","comments":true,"path":"自定义StopWatch/","link":"","permalink":"https://mx-go.github.io/%E8%87%AA%E5%AE%9A%E4%B9%89StopWatch/","excerpt":"引言在平时的开发调试工作或线上中，有时会遇到程序执行效率非常慢，通过一般的经验只能判断出部分逻辑有问题，但判断并不直观且效率较低，不知道方法中哪个阶段比较耗时。","text":"引言在平时的开发调试工作或线上中，有时会遇到程序执行效率非常慢，通过一般的经验只能判断出部分逻辑有问题，但判断并不直观且效率较低，不知道方法中哪个阶段比较耗时。目前spring-framework提供了一个StopWatch类可以做类似任务执行时间控制，于是利用此思想重新实现了一套自己的逻辑。 Spring中StopWatch12345678910111213141516171819202122232425262728293031@Slf4jpublic class TestStopWatch &#123; private void test() throws InterruptedException &#123; StopWatch sw = new StopWatch(); sw.start(&quot;起床&quot;); Thread.sleep(1000); sw.stop(); sw.start(&quot;洗漱&quot;); Thread.sleep(2000); sw.stop(); sw.start(&quot;锁门&quot;); Thread.sleep(500); sw.stop(); log.warn(&quot;prettyPrint = &#123;&#125;&quot;, sw.prettyPrint()); log.info(&quot;totalTimeMillis = &#123;&#125;&quot;, sw.getTotalTimeMillis()); log.warn(&quot;lastTaskName = &#123;&#125;&quot;, sw.getLastTaskName()); log.info(&quot;lastTaskInfo = &#123;&#125;&quot;, sw.getLastTaskInfo()); log.warn(&quot;taskCount = &#123;&#125;&quot;, sw.getTaskCount()); &#125; public static void main(String[] args) throws InterruptedException &#123; TestStopWatch testStopWatch = new TestStopWatch(); testStopWatch.test(); &#125;&#125; 输出： 12345678910111212-22 21:43:49.468 WARN c.f.o.d.TestStopWatch - prettyPrint = StopWatch &#x27;&#x27;: running time (millis) = 3505-----------------------------------------ms % Task name-----------------------------------------01004 029% 起床02001 057% 洗漱00500 014% 锁门12-22 21:43:49.476 INFO c.f.o.d.TestStopWatch - totalTimeMillis = 350512-22 21:43:49.476 WARN c.f.o.d.TestStopWatch - lastTaskName = 锁门12-22 21:43:49.477 INFO c.f.o.d.TestStopWatch - lastTaskInfo = org.springframework.util.StopWatch$TaskInfo@5bd03f4412-22 21:43:49.477 WARN c.f.o.d.TestStopWatch - taskCount = 3 可以看到，Spring中的StopWatch可以方便的排查程序执行效率，但是结果并不直观且代码侵入性太大。 自定义StopWatch123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Slf4jpublic class StopWatch &#123; private long startTime; private long lapStartTime; private String tagName; private List&lt;String&gt; steps = new ArrayList&lt;&gt;(); private StopWatch(String tagName) &#123; this.tagName = tagName; long start = System.nanoTime(); this.startTime = start; this.lapStartTime = start; &#125; public static StopWatch create(String tagName) &#123; return new StopWatch(tagName); &#125; public void lap(String stepName) &#123; long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - lapStartTime); int index = steps.size() + 1; String step = String.format(&quot;T%d(%s)/%d&quot;, index, stepName, elapsedTime); steps.add(step); //reset this.lapStartTime = System.nanoTime(); &#125; public void log() &#123; StringBuilder stringBuilder = createLog(); log.warn(stringBuilder.toString()); &#125; public void logSlow(long slow) &#123; long totalElapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime); if (totalElapsedTime &gt; slow) &#123; StringBuilder stringBuilder = createLog(); log.warn(stringBuilder.toString()); &#125; &#125; private StringBuilder createLog() &#123; long totalElapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - startTime); StringBuilder stringBuilder = new StringBuilder(tagName); stringBuilder.append(&#x27; &#x27;); stringBuilder.append(&quot; Total/&quot;); stringBuilder.append(totalElapsedTime); stringBuilder.append(&#x27; &#x27;); for (String step : steps) &#123; stringBuilder.append(step); stringBuilder.append(&#x27; &#x27;); &#125; return stringBuilder; &#125;&#125; 测试： 1234567891011121314151617181920212223@Slf4jpublic class TestStopWatch &#123; private void test() throws InterruptedException &#123; StopWatch stopWatch = StopWatch.create(&quot;test&quot;); Thread.sleep(1000); stopWatch.lap(&quot;起床&quot;); Thread.sleep(2000); stopWatch.lap(&quot;洗漱&quot;); Thread.sleep(500); stopWatch.lap(&quot;锁门&quot;); stopWatch.log(); &#125; public static void main(String[] args) throws InterruptedException &#123; TestStopWatch testStopWatch = new TestStopWatch(); testStopWatch.test(); &#125;&#125; 结果： 112-22 21:53:32.696 WARN c.f.o.r.c.StopWatch - test Total/3509 T1(起床)/1001 T2(洗漱)/2005 T3(锁门)/500 通过对比，可以发现自实现的StopWatch类更为简洁，同时也包含了必要的信息，但是功能不如Spring自带的强大。可针对不同的场景使用。","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"谈谈日志","slug":"谈谈日志","date":"2018-12-13T14:00:03.000Z","updated":"2021-05-05T03:20:23.595Z","comments":true,"path":"谈谈日志/","link":"","permalink":"https://mx-go.github.io/%E8%B0%88%E8%B0%88%E6%97%A5%E5%BF%97/","excerpt":"引言日志用来记录用户操作、系统运行状态等，是一个系统的重要组成部分。 然而，由于日志通常不属于系统的核心功能，所以常常不被团队成员所重视。","text":"引言日志用来记录用户操作、系统运行状态等，是一个系统的重要组成部分。 然而，由于日志通常不属于系统的核心功能，所以常常不被团队成员所重视。对于一些简单的小程序，可能并不需要在如何记录日志的问题上花费太多精力。但是对于作为基础平台为很多产品提供服务的后端程序，就必须要考虑如何依靠良好的日志来保证系统可靠的运行了。 工程配置使用slf4j作为日志门面，logback作为日志实现，把其他日志组件的调用转换到slf4j。 pom.xml 123456789101112131415161718192021222324// 可到https://mvnrepository.com获取最新version版本&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- common-logging 实际调用slf4j --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- java.util.logging 实际调用slf4j --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- log4j实际调用slf4j --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;&lt;/dependency&gt; logback配置详见：logback配置 jrebel配置在本地开发过程中，希望把日志打印到stdout，需要配合jrebel插件来实现。通过jrebel插件来启动tomcat的时候，就会优先找到 target/test­-classes/logback­-test.xml文件，这样就会把日志信息输出到stdout了。当正式打包的时候，不会打包test目录下的资源信息。这样就能实现线上和线下2套配置，互不影响。 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;application generated-by=&quot;intellij&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://www.zeroturnaround.com&quot; xsi:schemaLocation=&quot;http://www.zeroturnaround.com http://update.zeroturnaround.com/jrebel/rebel-2_1.xsd&quot;&gt; &lt;classpath&gt; &lt;!-- 查找资源文件的时候，优先从target/test-classes目录下查找 --&gt; &lt;dir name=&quot;/Users/max/Documents/workSpace/open-msg/target/test-classes&quot;&gt; &lt;/dir&gt; &lt;dir name=&quot;/Users/max/Documents/workSpace/open-msg/target/classes&quot;&gt; &lt;/dir&gt; &lt;/classpath&gt; &lt;web&gt; &lt;link target=&quot;/&quot;&gt; &lt;dir name=&quot;/Users/max/Documents/workSpace/open-msg/src/main/webapp&quot;&gt; &lt;/dir&gt; &lt;/link&gt; &lt;/web&gt;&lt;/application&gt; 合理的日志级别 要用异步日志； 要做日志轮转； 要有上下文信息； 不要疯狂打日志。 日志级别 打印建议 DEBUG（调试） 不建议在线上环境打印DEBUG日志，在需要的时候可以通过开关打开DEBUG日志，默认需要关闭DEBUG日志。过多的DEBUG日志，并不是好事，特别反对通过aop把函数调用的参数和返回值信息都记录到DEBUG日志中的做法。 INFO（通知） 业务日志用来记录业务的主流程的走向。INFO日志级别主要用于记录系统运行状态等关联信息。该日志级别，常用于反馈系统当前状态给最终用户。所以，在这里输出的信息，应该对最终用户具有实际意义，也就是最终用户要能够看得明白是什么意思才行。 WARN（警告） WARN日志常用来表示系统模块发生问题，但并不影响系统运行。 此时，进行一些修复性的工作，还能把系统恢复到正常的状态。参数验证错误类的可以使用WARN。 ERROR（错误） 此信息输出后，主体系统核心模块正常工作，需要修复才能正常工作。 必要的日志元素理想的日志中应该记录不多不少的信息。所谓不多，是指不要在日志中记录无用的信息。实践中常见到的无用的日志有： 能够放在一条日志里的东西，放在多条日志中输出； 预期会发生且能够被正常处理的异常，打印出一堆无用的堆栈； 开发人员在开发过程中为了调试方便而加入的“临时”日志； 所谓不少，是指对于日志的使用者，能够从日志中得到所有需要的信息。在实践中经常发生日志不够的情况，例如： 请求出错时不能通过日志直接来定位问题，而需要开发人员再临时增加日志并要求请求的发送者重新发送同样的请求才能定位问题； 无法确定服务中的后台任务是否按照期望执行； 无法确定服务的内存数据结构的状态； 无法确定服务的异常处理逻辑（如重试）是否正确执行； 无法确定服务启动时配置是否正确加载； ……","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Bug简记-Spring返回字符串加引号","slug":"Bug简记-Spring返回字符串加引号","date":"2018-10-01T14:39:56.000Z","updated":"2021-05-09T10:38:56.865Z","comments":true,"path":"Bug简记-Spring返回字符串加引号/","link":"","permalink":"https://mx-go.github.io/Bug%E7%AE%80%E8%AE%B0-Spring%E8%BF%94%E5%9B%9E%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%A0%E5%BC%95%E5%8F%B7/","excerpt":"引言在开发过程中会遇到这种各样的bug，也是自己吃过的亏。以后在这里会把自己遇到的bug记录下来，吸取教训，避免犯同样的错误。","text":"引言在开发过程中会遇到这种各样的bug，也是自己吃过的亏。以后在这里会把自己遇到的bug记录下来，吸取教训，避免犯同样的错误。 踩坑记录在与第三方对接的接口中，对方推送消息接口定义如果接收成功返回success，反之返回其他字符串，如果不是success字符串就会再重复推送三次。自己在代码中为： 123456@RequestMapping(value = &quot;&quot;, method = RequestMethod.POST)@ResponseBodypublic String callBack() &#123; //...something return &quot;success&quot;;&#125; 这段代码自我感觉没问题，但是线上发现即使返回的是success字符串也会重复推送。让对方排查了下，对方说我们推送的不是success字符串。WTF？看了日志*result[success]*没问题啊，直到自己亲自调试了下接口： 1234// 请求自己接口获取返回值String result = getResult();// 返回trueSystem.out.println(&quot;&quot;\\success\\&quot;&quot;.equals(result)); 发现接口返回值success被加上了双引号。 原因在SpringMVC中使用@ResponseBody注解时会强制返回json格式，在返回字符串时会默认加上双引号。这才导致返回的字符串多了双引号。 解决方法解决方法也很简单。只需要添加字符串解析器，避免String类型直接解析成JSON。 方法一：jackson 123456789101112131415161718&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;!-- 避免string类型直接解析成json--&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;constructor-arg ref=&quot;utf8charset&quot;/&gt; &lt;property name=&quot;writeAcceptCharset&quot; value=&quot;false&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot;&gt; &lt;bean class=&quot;com.fasterxml.jackson.databind.ObjectMapper&quot;&gt; &lt;property name=&quot;serializationInclusion&quot;&gt; &lt;value type=&quot;com.fasterxml.jackson.annotation.JsonInclude.Include&quot;&gt;NON_NULL&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 方法二：fastjson 12345678910111213141516&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters register-defaults=&quot;false&quot;&gt; &lt;!-- 避免String类型直接解析成json--&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;/&gt; &lt;!-- 避免IE执行AJAX时,返回JSON出现下载文件 --&gt; &lt;bean id=&quot;fastJsonHttpMessageConverter&quot; class=&quot;com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot;&gt; &lt;list&gt; &lt;!-- 这里顺序不能反，一定先写text/html,不然ie下出现下载提示 --&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;","categories":[{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"基于Redis的分布式锁","slug":"基于Redis的分布式锁","date":"2018-09-20T05:08:57.000Z","updated":"2021-05-05T03:16:42.575Z","comments":true,"path":"基于Redis的分布式锁/","link":"","permalink":"https://mx-go.github.io/%E5%9F%BA%E4%BA%8ERedis%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"引言目前几乎很多大型网站及应用都是分布式部署的，分布式场景中的数据一致性问题一直是一个比较重要的话题。分布式服务下各个服务同时访问共享资源时，分布式锁就派上用场了。redis用来做缓存很常见，它还有一个非常重要的功能就是做分布式锁。 采坑记录Redis分布式锁大部分人都会想到：setnx+lua，或者set key value px milliseconds nx，自己也是吃了这方面的亏。 事情的发展是，我们的服务是分布式服务，其中有个功能是调用第三方接口进行外呼，外呼接口中有个参数accessToken是需要另外两个参数通过HTTP请求换取。每个租户所有员工共用这一个accessToken，accessToken的有效期为120min。刚开始写的伪代码如下： 123456String redisKey = REDIS_KEY_PREFIX + &quot;_&quot; + accountId + &quot;_&quot; + appId + &quot;_&quot; + secret; String accessToken = jedis.get(redisKey);if (StringUtils.isBlank(accessToken)) &#123; accessToken = this.getAccessToken(accountId, appId, secret); jedis.set(redisKey, accessToken, &quot;nx&quot;, &quot;ex&quot;, 5400);&#125; getAccessToken是获取accessToken的动作。自己还是太年轻，以为一个setnx就可以解决问题(实际等于没加锁)。在高并发的情况下多个请求会同时进入getAccessToken方法获取多个accessToken，但是第三方系统里面存储的是最后一次请求的那个accessToken，由于getAccessToken是HTTP请求且每个请求时间都是不确定的，导致我们这边根本就不知道第三方系统存储的是哪个，结果就是客户反馈外呼电话一直提示“请检查accessToken是否正确”，赶紧排查问题 。 封装redis分布式锁自己当时也是那个着急，就搞了个不太完善的redis分布式锁。 首先有个RedisDistributeLock类，里面提供了分布式加锁和释放锁的方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;/** * redis实现的分布式锁。会阻塞当前线程。 * 只处理了 多个服务访问同一个redis实例， 且该redis实例正常工作的情况。 * 没有处理 redis故障切换的情况。 * 时间漂移的问题也没有很好的解决办法。 */@Servicepublic class RedisDistributeLock &#123; @Autowired public JedisPool jedisPool; public Jedis getRedisClient() &#123; return jedisPool.getResource(); &#125; /** * mini second. * 考虑到时间漂移，这个值应该设置大一些。 * 但是如果设置的过大，当获得lock的线程挂掉以后，别的服务就长时间获取不到该lock, 必须等到该lock过期。 */ private static final int lockTimeOut = 5000; public void requireLock(String lock) &#123; int ret; Jedis jedis = this.getRedisClient(); while (true) &#123; long now = System.currentTimeMillis(); ret = jedis.setnx(lock, String.valueOf(now + RedisDistributeLock.lockTimeOut)).intValue(); if (1 == ret) &#123; /**lock不存在，可以获得锁*/ break; &#125; else &#123; String curLockValue = jedis.get(lock); /**这个时刻有可能lock又被删除了，所以重新做一次检查*/ if (null == curLockValue) &#123; continue; &#125; /**lock过期了*/ if (now &gt; Long.parseLong(curLockValue)) &#123; String oldLockValue = jedis.getSet(lock, String.valueOf(now + RedisDistributeLock.lockTimeOut)); if (null == oldLockValue) &#123; /**要么getset之前lock不存在, 要么getset之前lock存在但没有值， * 我不确定会不会出现第二种情况，所以重新去请求锁。*/ continue; &#125; if (now &gt; Long.parseLong(oldLockValue)) &#123; /**抢到了这个过期的lock, 并且已经已经设置成功*/ break; &#125; &#125; try &#123; Thread.sleep(20); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; jedis.close(); &#125; public void releaseLock(String lock) &#123; long now = System.currentTimeMillis(); Jedis jedis = this.getRedisClient(); //jedis.eva if (now &lt; Long.valueOf(jedis.get(lock))) &#123; jedis.del(lock); &#125; jedis.close(); &#125;&#125; 在分布式下只需将需要同步的代码块放在distributeLock.requireLock和distributeLock.releaseLock中即可。 12345678910111213141516171819String lock_key = REDIS_KEY_PREFIX + &quot;_&quot; + accountId + &quot;_&quot; + appId + &quot;_&quot; + secret;String accessToken;try&#123; distributeLock.requireLock(lock_key); &#123; accessToken = client.get(redis_key); if (StringUtils.isEmpty(accessToken)) &#123; accessToken = this.getAccessToken(); client.set(redis_key, accessToken); client.expire(redis_key, 3); log.info(Thread.currentThread().getName() + &quot; &quot; + accessToken); &#125; distributeLock.releaseLock(lock_key); &#125;&#125;catch(Excetion e)&#123; // do something&#125;finally&#123; distributeLock.releaseLock(lock_key);&#125; 虽然解决了同步获取accessToken的问题，但是对于异常情况的考虑还是欠缺，请求线程同时还是阻塞的，自己测试在TPS为700时还可以扛住，高于单个服务负载或是redis故障时请求被阻塞会导致服务受到影响。 RedissonRedisson是基于Redlock实现同时也是redis官方推荐的分布式JAVA客户端，和Jedis相比它实现了分布式和可扩展的JAVA数据结构。在Redisson中提供了现成的分布式锁的方法。 Maven引入Redisson12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt;&lt;/dependency&gt; 分布式锁用法在分布式下加锁lock和释放锁unlock的伪代码如下 123456789101112131415161718192021222324252627282930private static RedissonClient redisson;String lock_key = REDIS_KEY_PREFIX + accountId + &quot;_&quot; + appId + &quot;_&quot; + secret;String accessToken = client.get(redis_key);static &#123; Config config = new Config(); config.useSingleServer() .setTimeout(1000000) .setAddress(&quot;redis://127.0.0.1:6379&quot;); redisson = Redisson.create(config);&#125;if (StringUtils.isEmpty(accessToken)) &#123; // 1.获得锁对象实例 RLock lock = redisson.getLock(lock_key); // 2.获取分布式锁 lock.lock(); accessToken = client.get(redis_key); if (StringUtils.isEmpty(accessToken)) &#123; try &#123; accessToken = this.getAccessToken(); client.set(redis_key, accessToken); client.expire(redis_key, 2); &#125; finally &#123; // 3.释放锁 lock.unlock(); &#125; &#125;&#125; 总结当然，分布式锁不止基于redis和redisson这两种方案，还有数据库乐观锁、基于ZooKeeper的分布式锁等。但是在基于redis方面，通过自己的分析及测试，Redisson在分布式锁方面是还是首选，同时Redisson不光是针对锁，同时提供了很多客户端操作redis的方法，也需要自己去摸索。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"redis","slug":"redis","permalink":"https://mx-go.github.io/tags/redis/"}]},{"title":"logback推荐配置","slug":"logback推荐配置","date":"2018-08-18T07:51:53.000Z","updated":"2021-05-09T10:40:20.668Z","comments":true,"path":"logback推荐配置/","link":"","permalink":"https://mx-go.github.io/logback%E6%8E%A8%E8%8D%90%E9%85%8D%E7%BD%AE/","excerpt":"引言大约从16年，不管是我参与别人已搭建好的项目还是自己单独搭建的项目，日志框架基本都换成了logback。","text":"引言大约从16年，不管是我参与别人已搭建好的项目还是自己单独搭建的项目，日志框架基本都换成了logback。 # logback优点 内核重写、测试充分、初始化内存加载更小，这一切让logback性能和log4j相比有诸多倍的提升 logback非常自然地直接实现了slf4j，这个严格来说算不上优点，只是这样，再理解slf4j的前提下会很容易理解logback，也同时很容易用其他日志框架替换logback logback有比较齐全的文档 logback当配置文件修改了，支持自动重新加载配置文件，扫描过程快且安全，它并不需要另外创建一个扫描线程 支持自动去除旧的日志文件，可以控制已经产生日志文件的最大数量 配置的正确姿势我们大部分Java后台都是Maven工程，标准目录如下： 包路径 说明 src/main/java java源代码文件，编译到target/classes src/main/resource 正式包资源库，编译时会复制到target/classes src/test/java 测试java源代码文件，编译到target/test-classes src/test/resource 测试时资源库，编译时复制到target/test-classes 建议配置2个logback配置文件： 路径 说明 src/main/resources/logback.xml 异步打印到按天轮转的日志文件中。jar包不要配置，避免污染业务配置。 src/test/resources/logback-test.xml 测试时候使用，打印到stdout 线上和开发环境的配置要分离，对于java项目： src/main/resources 目录下的东西都是正式环境使用的 src/test/resources 目录下的东西才是本机开发环境使用的 如果发现自己本机开发启动程序的时候，经常要修改 src/main/resources 目录下的东东，那就说明用错了。这样做的一个后果就是，当提交代码的时候，忘记修改回来，结果发布到线上去了。轻则日志量暴增，重则引起运营事故。所以一定千万注意！ 推荐的配置内容logback.xml 推荐配置112345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration scan=&quot;false&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;appender name=&quot;RollingFile&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 可让每天产生一个日志文件，最多 7 个，自动回滚 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;catalina.home&#125;/logs/fs-app-%d&#123;yyyyMMdd&#125;.log.zip&lt;/fileNamePattern&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;!-- 异常栈中去掉包含如下字符的行避免打印很多无用的信息--&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;12&#125; %msg%rEx&#123;full, java.lang.Thread, javassist, sun.reflect, org.springframework, org.apache, org.eclipse.jetty, $Proxy, java.net, java.io, javax.servlet, org.junit, com.mysql, com.sun, org.mybatis.spring, cglib, CGLIB, java.util.concurrent, okhttp, org.jboss, &#125;%n &lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 异步输出日志避免阻塞服务 --&gt; &lt;appender name=&quot;ASYNC&quot; class=&quot;ch.qos.logback.classic.AsyncAppender&quot;&gt; &lt;queueSize&gt;512&lt;/queueSize&gt; &lt;appender-ref ref=&quot;RollingFile&quot;/&gt; &lt;includeCallerData&gt;true&lt;/includeCallerData&gt; &lt;/appender&gt; &lt;!-- 配置基础组件为WARN级别，避免打印过多影响服务自己日志 --&gt; &lt;logger name=&quot;druid.sql&quot; level=&quot;INFO&quot;/&gt; &lt;logger name=&quot;org.hibernate&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;org.apache&quot; level=&quot;WARN&quot;/&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;ASYNC&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; logback.xml 推荐配置212345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;appender name=&quot;WARN&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;File&gt;$&#123;catalina.base&#125;/logs/warn.log&lt;/File&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;yyyy/MM/dd-HH:mm:ss.SSS&#125;]-[%level]-[%thread]-[%class:%line]- %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;FileNamePattern&gt;$&#123;catalina.base&#125;/logs/warn.%d&#123;yyyy-MM-dd&#125;.log.zip&lt;/FileNamePattern&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name=&quot;ALL&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;File&gt;$&#123;catalina.base&#125;/logs/all.log&lt;/File&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;yyyy/MM/dd-HH:mm:ss.SSS&#125;]-[%level]-[%thread]-[%class:%line]- %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;FileNamePattern&gt;$&#123;catalina.base&#125;/logs/all.%d&#123;yyyy-MM-dd&#125;.log.zip&lt;/FileNamePattern&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;[%d&#123;yyyy/MM/dd-HH:mm:ss.SSS&#125;]-[%level]-[%thread]-[%class:%line]- %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;logger name=&quot;com.facishare.open&quot; level=&quot;INFO&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;WARN&quot;/&gt; &lt;appender-ref ref=&quot;ALL&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;WARN&quot;/&gt; &lt;appender-ref ref=&quot;ALL&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; logback-test.xml 推荐配置12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration scan=&quot;false&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;12&#125; %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;logger name=&quot;org.hibernate&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;WARN&quot;/&gt; &lt;logger name=&quot;org.apache&quot; level=&quot;WARN&quot;/&gt; &lt;root level=&quot;DEBUG&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;/root&gt;&lt;/configuration&gt; 推荐日志级别极为严格的做法是：只要*log.error()*记录的内容，都需要人及时响应的，有些公司会针对error进行字符串告警。那么，针对一些如：没有权限、参数错误、非法请求等，由于不合理的请求进来的，就建议打印warn而不是error，否则狼来了喊多了就没有用了。也会淹没真正的错误。简单来讲，真正影响到正常用户的正常请求而且需要及时响应的错误，就打印ERROR，否则打印WARN。一般信息打印info，针对调试操作，打印debug。 推荐使用日志占位符 log.info(“this is a={}, b={}”, a, b) 使用占位符，是真正需要打印的时候，才进行字符串拼接；如果不打印就不会拼接字符串。 log.error(“cannot open url={}”, url, e) 针对error，务必把异常栈打印出来，这里有一个exception对象，不需要使用占位符，如果多一个占位符，则只会打印e.getMessage()的内容，就不方便查问题了。","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"PG与MySQL选型分析","slug":"PG与MySQL选型分析","date":"2018-08-07T02:50:58.000Z","updated":"2021-05-05T03:28:28.196Z","comments":true,"path":"PG与MySQL选型分析/","link":"","permalink":"https://mx-go.github.io/PG%E4%B8%8EMySQL%E9%80%89%E5%9E%8B%E5%88%86%E6%9E%90/","excerpt":"引言PostgreSQL(简称pg)是近几年增长率较快的开源数据库，很多企业由原来的MySQL转向pg，在这里对比这两大开源关系型数据库的优劣，以便使用时快速选型。","text":"引言PostgreSQL(简称pg)是近几年增长率较快的开源数据库，很多企业由原来的MySQL转向pg，在这里对比这两大开源关系型数据库的优劣，以便使用时快速选型。 # PG与MySQL的一些特性对比 特性 PG MySQL 口号性特点 最先进的开源数据库 最流行的开源数据库 SQL编程能力 强大的SQL能力，包括丰富的统计函数和统计分析，对BI有很好的支持 没有强大的统计功能支持 数据类型 丰富的数据类型支持，包括地理信息、几何图形、json、数组等，json也可以建立索引 在地理信息支持度上不如PG，不支持几何图形等数据类型 事务能力 完整的ACID事务支持 不是完整的支持ACID事务特性 join 支持nested-loop, sort-merge, hash三种类型 只支持nested-loop Text类型 没有长度限制，可以直接访问，可以索引，可以全文索引 有长度限制 复杂查询 支持窗口函数，支持递归，支持with语句 不支持窗口函数、递归等 索引 多种索引类型，包括b-tree，hash，gin，gist等，可以对模糊查询、正则表达式、地理信息系统等建立索引 主要是b-tree索引 数据复制 支持同步复制，支持流复制 支持异步复制 查询优化器 功能更强大，对子查询的支持更高效 子查询效率不高 7*24 隔一段时间需要进行VACUUM 适用7*24 性能和适用场景 复杂查询 简单业务场景，更高的TPS 运维资源 专业DBA相对较少 众多DBA有丰富的运维经验 大小写 大小写敏感 大小写不敏感 行大小限制 无限制 65535 PG存在的问题和解决方案 序号 问题描述 问题分析 解决方案 1 主从同步WAL方式，主库挂掉，从库有时会启动失败，或者很慢 应该是主库没有保留足够远的xlog数据，导致主从时间线不一致 主库的wal_keep_segments要设置的足够大，个人推荐要保证允许从库挂48小时：wal_keep_segments=（48小时*log增量大小)/16M 2 在大数据量情况下，PG对地理位置信息（附近客户）的查询效率较慢 关系数据库在处理大数据方面天然有劣势 可以进行分库处理，尽量保证单库的数据量在PG的处理能力之内；如果效率还满足不了，采用ES来处理 3 WAL从库只能是只读的，报表比较难处理 如果是双主或者是多主，数据同步是大问题 根据业务进行调整，业务架构不需要双主，BI对从库只有读的需求 4 基于XID的MVCC实现机制，导致需要定时触发VACUUM，导致性能的抖动 基于MVCC的方式导致会产生垃圾，这些垃圾需要在合适的时间被回收 这个需要根据实际情况调整回收的策略，需要DBA配合调优；就像JVM的GC一样 5 大小写敏感，这对于习惯于原来大小写不敏感的编程方式，可能会很不习惯 PG对对象和数据都是大小写敏感的 对象的大小写敏感问题：PG在分析SQL脚本时，对不加双引号的所有对象名转化为小写字母；数据的大小写敏感问题：可以在存储的时候进行转换，或者查询的时候进行转换，可能需要配合建立表达式索引 6 MVCC机制带来的SSD写放大和索引写放大 支持并发读写的数据库都会有写放大问题，不是PG独有 PG的HOT技术，以及基于Heap的存储技术，对写入和索引可以调优写放大的问题；实测也部分验证了这一点 7 PG的复制低效，有写放大 PG的流式复制复制非常高效，支持流的加密和压缩；并且从9.4开始支持逻辑复制 8 备库的MVCC支持较差，查询会与恢复堵塞 基于物理复制或逻辑复制，只要备库拿来使用，都有可能出现查询与恢复冲突的情况。PG对于冲突的处理非常的人性化，你可以选择恢复优先 or 查询优先，设置时间窗口即可。同时PG还支持备库的QUERY反馈机制，主库可以根据备库的QUERY，控制垃圾回收的延迟窗口，避免QUERY和垃圾回收的冲突。 9 跨版本升级较难，跨版本不支持复制 现在的PG对大版本升级已经有很好的支持 10 调优比较复杂 PG的调优参数较多，各个参数还有联动 补充专业DBA，专业指导，积累经验 部分问题可在https://yq.aliyun.com/articles/58421查看。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"},{"name":"pg","slug":"pg","permalink":"https://mx-go.github.io/tags/pg/"}]},{"title":"分布式数据库和缓存双写一致性解析","slug":"分布式数据库和缓存双写一致性解析","date":"2018-07-15T03:05:23.000Z","updated":"2021-05-05T03:16:09.042Z","comments":true,"path":"分布式数据库和缓存双写一致性解析/","link":"","permalink":"https://mx-go.github.io/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E8%A7%A3%E6%9E%90/","excerpt":"引言缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，都是按照先从缓存中读取，缓存中不存在再从数据库加载同时存入缓存的流程操作。但是在更新缓存方面，对于更新完数据库，是更新缓存还是删除缓存。又或是先删除缓存再更新数据库，其实都有很大的争议。","text":"引言缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，都是按照先从缓存中读取，缓存中不存在再从数据库加载同时存入缓存的流程操作。但是在更新缓存方面，对于更新完数据库，是更新缓存还是删除缓存。又或是先删除缓存再更新数据库，其实都有很大的争议。 策略说明：从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。因此， 接下来的讨论的思路不依赖于给缓存设置过期时间这个方案。 在这里讨论三种更新策略： 先更新数据库，再更新缓存 先删除缓存，再更新数据库 先更新数据库，再删除缓存 先更新数据库，再更新缓存这套方案普遍反对，有如下两种原因： 线程安全角度同时有请求A和请求B进行更新操作，那么会出现 （1）线程A更新了数据库（2）线程B更新了数据库（3）线程B更新了缓存（4）线程A更新了缓存 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。 业务场景角度（1）如果是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。 （2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。 先删缓存，再更新数据库该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形： （1）请求A进行写操作，删除缓存（2）请求B查询发现缓存不存在（3）请求B去数据库查询得到旧值（4）请求B将旧值写入缓存（5）请求A将新值写入数据库 上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。 解决方案就是采用延时双删策略。伪代码如下： 123456public void write(String key,Object data)&#123; redis.delKey(key); db.updateData(data); Thread.sleep(1000); redis.delKey(key);&#125; 转化为中文描述就是： （1）先淘汰缓存（2）再写数据库（这两步和原来一样）（3）休眠1秒，再次淘汰缓存 这么做，可以将1秒内所造成的缓存脏数据，再次删除。那么这个睡眠时间如何确定呢？ 针对上面的情形，应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。 如果用了mysql的读写分离架构怎么办？ 在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。 （1）请求A进行写操作，删除缓存（2）请求A将数据写入数据库了，（3）请求B查询缓存发现，缓存没有值（4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值（5）请求B将旧值写入缓存（6）数据库完成主从同步，从库变为新值 上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。 采用这种同步淘汰策略，吞吐量降低怎么办？ 那就将第二次删除作为异步的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。 第二次删除,如果删除失败怎么办？ 第二次删除失败，就会出现如下情形。还是有两个请求，一个请求A进行更新操作，另一个请求B进行查询操作，为了方便，假设是单库： （1）请求A进行写操作，删除缓存（2）请求B查询发现缓存不存在（3）请求B去数据库查询得到旧值（4）请求B将旧值写入缓存（5）请求A将新值写入数据库（6）请求A试图去删除请求B写入对缓存值，结果失败了。 这也就是说。如果第二次删除缓存失败，会再次出现缓存和数据库不一致的问题。 如何解决呢？ 具体解决方案，就是第三种方案。 先更新数据库，再删除缓存老外提出了一个缓存更新套路，名为《Cache-Aside pattern》。其中指出 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 另外，知名社交网站facebook也在论文《Scaling Memcache at Facebook》中提出，他们用的也是先更新数据库，再删缓存的策略。 这种情况不存在并发问题么？ 不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生： （1）缓存刚好失效（2）请求A查询数据库，得一个旧值（3）请求B将新值写入数据库（4）请求B删除缓存（5）请求A将查到的旧值写入缓存 如果发生上述情况，确实是会发生脏数据。 然而，发生这种情况的概率又有多少呢？ 发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。 如何解决上述并发问题？ 首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。 还有其他造成不一致的原因么？ 有的，这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。 如何解决？ 提供一个保障的重试机制即可，这里给出两套方案。方案一： 如下图所示 流程如下所示（1）更新数据库数据；（2）缓存因为种种问题删除失败（3）将需要删除的key发送至消息队列（4）自己消费消息，获得需要删除的key（5）继续重试删除操作，直到成功 然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。 方案二： 流程如下图所示： （1）更新数据库数据（2）数据库会将操作信息写入binlog日志当中（3）订阅程序提取出所需要的数据以及key（4）另起一段非业务代码，获得该信息（5）尝试删除缓存操作，发现删除失败（6）将这些信息发送至消息队列（7）重新从消息队列中获得该数据，重试操作。 备注说明：上述的订阅binlog程序在mysql中有现成的中间件叫canal，可以完成订阅binlog日志的功能。另外，重试机制，采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这里只是提供一个思路。 参考分布式之数据库和缓存双写一致性方案解析","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"cache","slug":"cache","permalink":"https://mx-go.github.io/tags/cache/"}]},{"title":"数据库主从不一致","slug":"数据库主从不一致","date":"2018-07-08T13:21:13.000Z","updated":"2021-05-05T03:17:59.131Z","comments":true,"path":"数据库主从不一致/","link":"","permalink":"https://mx-go.github.io/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E4%BB%8E%E4%B8%8D%E4%B8%80%E8%87%B4/","excerpt":"引言在开发过程中，进场遇到数据库主从分离来降低读写的压力，但是数据库主从同步是有延时的，这里聊一聊数据库主库与从库的一致性问题。","text":"引言在开发过程中，进场遇到数据库主从分离来降低读写的压力，但是数据库主从同步是有延时的，这里聊一聊数据库主库与从库的一致性问题。 常见的数据库集群架构一主多从，主从同步，读写分离 如上图所示 一个主库提供写服务 多个从库提供读服务，可以增加从库提升读性能 主从之间同步 任何方案不要忘了本心，增加从库的本心是提升读性能 为什么会出现不一致主从同步有时延，这个时延期间读从库，可能读到不一致的数据。 如上图 服务发齐了一个写请求 服务又发起了一个读请求，此时同步未完成，读到一个不一致的脏数据 数据库主从同步最后才完成 任何数据冗余，必将引发一致性问题。 解决方法忽略任何脱离业务的架构设计都是耍流氓，绝大部分业务，例如：百度搜索，淘宝订单，QQ消息，58帖子都允许短时间不一致。 如果业务能接受，最推崇此法。 如果业务能够接受，别把系统架构搞得太复杂。 强制读主 如上图 使用一个高可用主库提供数据库服务 读和写都落到主库上 采用缓存来提升系统读性能 这是很常见的微服务架构，可以避免数据库主从一致性问题。 选择性读主强制读主过于粗暴，毕竟只有少量写请求，很短时间，可能读取到脏数据。 有没有可能实现，只有这一段时间，可能读到从库脏数据的读请求读主，平时读从呢？ 可以利用一个缓存记录必须读主的数据。 如上图，当写请求发生时： 写主库 将哪个库，哪个表，哪个主键三个信息拼装一个key设置到cache里，这条记录的超时时间，设置为“主从同步时延” key的格式为“db:table:PK”，假设主从延时为1s，这个key的cache超时时间也为1s。 如上图，当读请求发生时： 这是要读哪个库，哪个表，哪个主键的数据呢，也将这三个信息拼装一个key，到cache里去查询，如果： cache里有这个key，说明1s内刚发生过写请求，数据库主从同步可能还没有完成，此时就应该去主库查询。 cache里没有这个key，说明最近没有发生过写请求，此时就可以去从库查询。 以此，保证读到的一定不是不一致的脏数据。 总结数据库主库和从库不一致，常见有这么几种优化方案： 业务可以接受，系统不优化； 强制读主，高可用主库，用缓存提高读性能； 在cache里记录哪些记录发生过写请求，来路由读主还是读从。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"MySQL清除表空间碎片","slug":"MySQL清除表空间碎片","date":"2018-05-22T03:12:17.000Z","updated":"2021-05-09T10:41:16.102Z","comments":true,"path":"MySQL清除表空间碎片/","link":"","permalink":"https://mx-go.github.io/MySQL%E6%B8%85%E9%99%A4%E8%A1%A8%E7%A9%BA%E9%97%B4%E7%A2%8E%E7%89%87/","excerpt":"引言MySQL在数据表使用很长时间后，表上的B-Tree索引可能会碎片化，会降低查询的效率。碎片化的索引可能会以很差或者无序的方式存储在磁盘上，这时就需要对表进行碎片化整理。","text":"引言MySQL在数据表使用很长时间后，表上的B-Tree索引可能会碎片化，会降低查询的效率。碎片化的索引可能会以很差或者无序的方式存储在磁盘上，这时就需要对表进行碎片化整理。 碎片产生原因1、表的存储会出现碎片化，每当删除了一行内容，该段空间就会变为空白、被留空，而在一段时间内的大量删除操作，会使这种留空的空间变得比存储列表内容所使用的空间更大； 2、当执行插入操作时，MySQL会尝试使用空白空间，但如果某个空白空间一直没有被大小合适的数据占用，仍然无法将其彻底占用，就形成了碎片； 3、当MySQL对数据进行扫描时，它扫描的对象实际是列表的容量需求上限，也就是数据被写入的区域中处于峰值位置的部分； 例：一个表有1万行，每行10字节，会占用10万字节存储空间，执行删除操作，只留一行，实际内容只剩下10字节，但MySQL在读取时，仍看做是10万字节的表进行处理，所以，碎片越多，就会越来越影响查询性能。 查看表碎片大小1、查看某个表的碎片大小 1SHOW TABLE STATUS LIKE &#x27;表名&#x27;; 结果中’Data_free’列的值就是碎片大小 2、列出所有已经产生碎片的表 123select table_schema db, table_name, data_free, engine from information_schema.tables where table_schema not in (&#x27;information_schema&#x27;, &#x27;mysql&#x27;) and data_free &gt; 0; 清除表碎片1、MyISAM表 1OPTIMIZE TABLE 表名; 2、InnoDB表 1ALTER TABLE 表名 ENGINE INNODB; 这其实是一个NULL操作，表面上看什么也不做，实际上重新整理碎片了。当执行优化操作时，实际执行的是一个空的 ALTER 命令，但是这个命令也会起到优化的作用，它会重建整个表，删掉未使用的空白空间。 Engine不同，OPTIMIZE 的操作也不一样。MyISAM 因为索引和数据是分开的，所以 OPTIMIZE 可以整理数据文件，并重排索引。如果针对 INNODB 的表做 OPTIMIZE TABLE 的操作，系统将返回：Table does not support optimize, doing recreate + analyze instead。 OPTIMIZE 操作会暂时锁住表，而且数据量越大，耗费的时间也越长。它毕竟不是简单查询操作，所以把 OPTIMIZE 命令放在程序中是不妥当的。不管设置的命中率多低，当访问量增大的时候，整体命中率也会上升，这样肯定会对程序的运行效率造成很大影响，比较好的方式就是做个shell，定期检查MySQL中 information_schema.TABLES字段，查看 DATA_FREE 字段，大于0话就表示有碎片。 建议清除碎片操作会暂时锁表，数据量越大，耗费的时间越长，可以做个脚本，定期在访问低谷时间执行，例如每月1号凌晨，检查 DATA_FREE 字段，大于自己认为的警戒值的话，就清理一次。 MySQL 清除表空间碎片","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"计算密集型 VS IO密集型","slug":"计算密集型-VS-IO密集型","date":"2018-05-17T10:56:06.000Z","updated":"2018-12-30T14:46:22.544Z","comments":true,"path":"计算密集型-VS-IO密集型/","link":"","permalink":"https://mx-go.github.io/%E8%AE%A1%E7%AE%97%E5%AF%86%E9%9B%86%E5%9E%8B-VS-IO%E5%AF%86%E9%9B%86%E5%9E%8B/","excerpt":"引言 在开发过程中，经常会遇到多线程的问题，解决多线程的其中一种方式就是利用线程池，其中需要开启线程的数量便成为了我们关注的焦点。JAVA中有两种并发类型：计算密集型（CUP-bound）和IO密集型（I/O-bound）。","text":"引言 在开发过程中，经常会遇到多线程的问题，解决多线程的其中一种方式就是利用线程池，其中需要开启线程的数量便成为了我们关注的焦点。JAVA中有两种并发类型：计算密集型（CUP-bound）和IO密集型（I/O-bound）。 计算密集型（CPU-bound） 计算密集型，顾名思义就是应用需要非常多的CPU计算资源，CPU大部份时间用来做计算、逻辑判断等CPU动作的程序称之CPU bound。在多核CPU时代，我们要让每一个CPU核心都参与计算，将CPU的性能充分利用起来，这样才算是没有浪费服务器配置，如果在非常好的服务器配置上还运行着单线程程序，那将是非常大的浪费。对于计算密集型的应用，完全是靠CPU的核数来工作，所以为了让它的优势完全发挥出来，避免过多的上下文切换，比较理性的方案是： 1线程数 = CPU核数 + 1 为什么是 +1？因为即使当计算密集型的线程偶尔由于缺失故障或者其他原因而暂停时，这个额外的线程也能确保CPU的时钟周期不会被浪费。 也可以设置成CPU核数 x 2，这还是要看JDK的使用版本，以及CPU配置(服务器的CPU有超线程)。对于JDK1.8来说，里面增加了一个并行计算，计算密集型的较理想线程数 = CPU内核线程数 x 2 以下是一个计算文件夹大小的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * 计算文件夹大小 * ClassName: FileSizeCalc */public class FileSizeCalc &#123; static class SubDirsAndSize &#123; public final long size; public final List&lt;File&gt; subDirs; public SubDirsAndSize(long size, List&lt;File&gt; subDirs) &#123; this.size = size; this.subDirs = Collections.unmodifiableList(subDirs); &#125; &#125; private SubDirsAndSize getSubDirsAndSize(File file) &#123; long total = 0; List&lt;File&gt; subDirs = new ArrayList&lt;File&gt;(); if (file.isDirectory()) &#123; File[] children = file.listFiles(); if (children != null) &#123; for (File child : children) &#123; if (child.isFile()) total += child.length(); else subDirs.add(child); &#125; &#125; &#125; return new SubDirsAndSize(total, subDirs); &#125; private long getFileSize(File file) throws Exception &#123; final int cpuCore = Runtime.getRuntime().availableProcessors(); final int poolSize = cpuCore + 1; ExecutorService service = Executors.newFixedThreadPool(poolSize); long total = 0; List&lt;File&gt; directories = new ArrayList&lt;File&gt;(); directories.add(file); SubDirsAndSize subDirsAndSize = null; try &#123; while (!directories.isEmpty()) &#123; List&lt;Future&lt;SubDirsAndSize&gt;&gt; partialResults = new ArrayList&lt;Future&lt;SubDirsAndSize&gt;&gt;(); for (final File directory : directories) &#123; partialResults.add(service.submit(new Callable&lt;SubDirsAndSize&gt;() &#123; @Override public SubDirsAndSize call() throws Exception &#123; return getSubDirsAndSize(directory); &#125; &#125;)); &#125; directories.clear(); for (Future&lt;SubDirsAndSize&gt; partialResultFuture : partialResults) &#123; subDirsAndSize = partialResultFuture.get(100, TimeUnit.SECONDS); total += subDirsAndSize.size; directories.addAll(subDirsAndSize.subDirs); &#125; &#125; return total; &#125; finally &#123; service.shutdown(); &#125; &#125; public static void main(String[] args) throws Exception &#123; for (int i = 0; i &lt; 10; i++) &#123; final long start = System.currentTimeMillis(); long total = new FileSizeCalc().getFileSize(new File(&quot;D:/DevTools&quot;)); final long end = System.currentTimeMillis(); System.out.format(&quot;文件夹大小: %dMB%n&quot;, total / (1024 * 1024)); System.out.format(&quot;所用时间: %.3fs%n&quot;, (end - start) / 1.0e3); &#125; &#125;&#125; 执行结果如下： 1234567891011121314151617181920文件夹大小: 15987MB所用时间: 2.005s文件夹大小: 15987MB所用时间: 1.879s文件夹大小: 15987MB所用时间: 2.142s文件夹大小: 15987MB所用时间: 2.089s文件夹大小: 15987MB所用时间: 1.996s文件夹大小: 15987MB所用时间: 2.258s文件夹大小: 15987MB所用时间: 2.198s文件夹大小: 15987MB所用时间: 1.968s文件夹大小: 15987MB所用时间: 2.105s文件夹大小: 15987MB所用时间: 2.071s 在上面的例子中，线程池设置为CPU核心数 + 1个，结果如上图。如果在这里把线程池加大，比如调到100，会发现所用的时间变多了。虽然增加的时间不是太多，但是对于CPU来说可是相当长的，因为CPU里面是以纳秒为计算单位，1毫秒=1000000纳秒。所以加大线程池会增加CPU上下文的切换成本，有时程序的优化就是从这些微小的地方积累起来的。 I/O密集型（I/O-bound） 对于IO密集型的应用，就很好理解了，现在做的开发大部分都是WEB应用，涉及到大量的网络传输，不仅如此，与数据库、缓存（网络、磁盘）间的交互也涉及到IO，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。一旦发生IO，线程就会处于等待状态，当IO结束，数据准备好后，线程才会继续执行。因此从这里可以发现，对于IO密集型的应用，可以多设置一些线程池中线程的数量，这样就能让在等待IO的这段时间内，线程可以去做其它事，提高并发处理效率。 那么这个线程池的数据量是不是可以随便设置呢？当然不是的，一定要记得，线程上下文切换是有代价的。目前总结了一套公式，对于IO密集型应用： 1线程数 = CPU核心数/(1-阻塞系数) 这个阻塞系数一般为0.8~0.9之间，也可以取0.8或者0.9。套用公式，对于双核CPU来说，它比较理想的线程数就是20，当然这都不是绝对的，需要根据实际情况以及实际业务来调整。 1final int poolSize = (int) (cpuCore / (1 - 0.9)); 浅谈Java两种并发类型——计算密集型与IO密集型","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Git-VS-SVN","slug":"Git-VS-SVN","date":"2018-05-14T06:04:08.000Z","updated":"2021-05-09T10:42:22.476Z","comments":true,"path":"Git-VS-SVN/","link":"","permalink":"https://mx-go.github.io/Git-VS-SVN/","excerpt":"引言在软件开发过程中，版本控制是非常重要的一环。常用的版本控制工具有Git和SVN。","text":"引言在软件开发过程中，版本控制是非常重要的一环。常用的版本控制工具有Git和SVN。 Git是目前世界上最先进的分布式版本控制系统，其实 Git 跟 SVN 一样有自己的集中式版本库或服务器，但是Git 更倾向于被使用于分布式模式，也就是每个开发人员从中心版本库/服务器上chect out代码后会在自己的机器上克隆一个跟中心版本库一模一样的本地版本库。可以这样说，如果你被困在一个不能连接网络的地方时，你仍然能够提交文件，查看log（历史版本记录），创建项目分支等。 Git和SVN的差别1、Git只关心文件数据的整体是否发生变化，而SVN这类版本控制系统则只关心文件内容的具体差异。 ​ 这类系统（如SVN）每次记录有哪些文件做了更新，以及都更新了哪些行的什么内容，然而Git 并不保存这些前后变化的差异数据。实际上，Git更像是把变化的文件作快照后，记录在一个微型的文件系统中。每次提交更新时，它会纵览一遍所有文件的指纹信息并对文件作一快照，然后保存一个指向这次快照的索引。为提高性能，若文件没有变化，Git 不会再次保存，而只对上次保存的快照作一链接。 2、在Git 中的绝大多数操作都只需要访问本地文件和资源，不必联网就可以看到所有的历史版本记录，而SVN 却需要联网。 ​ 因为 Git 在本地磁盘上就保存着所有当前项目的历史更新，所以处理起来速度飞快，但我们需要浏览项目的历史更新摘要，Git 不用跑到外面的服务器上去取数据回来，而直接从本地数据库读取后展示给你看。如果想要看当前版本的文件和一个月前的版本之间有何差异，Git 会取出一个月前的快照和当前文件作一次差异运算。 3、SVN 断开网络或者断开VPN就无法commit代码，但是Git 可以先commit到本地仓库。 ​ 用SVN的话，没有网络或者断开VPN时，你当然也可以继续在本地开发，但是无法commit代码，因为SVN 每次commit都必须联网，长时间不commit代码会丢失大量开发进程的历史纪录。有个比喻是：不能commit就像用word写文档不能save一样危险。而且有网络的情况下每一次commit都会花上数秒甚至更长时间。但用 Git 的话，就算你在飞机或者火车上，都可以非常愉快地频繁提交更新，因为是在本地仓库commit所以几乎不需要时间，而且commit一定要频繁，不然无法记录你的改动，如果你一天commit一次，中间的修改你就找不回来，然后等到了有网络的时候再将版本纪录和代码一起上传到远程仓库。 4、Git 的内容完整性要优于SVN。 分支Git上的分支远比SVN上的强大。 分支是什么SVN 在 SVN 这类的版本控制系统上，分支（branch）是一个完整的目录，且这个目录拥有完整的实际文件。如果工作成员想要开启新的分支，那将会影响“全世界”！每个人都会拥有和你一样的分支。如果你的分支是用来对系统模块进行安全检查测试的，那将会像传染病一样，你改一个分支，还得让其他人重新切分支重新下载，而且这些代码很可能对稳定版本还是具有破坏性的。 Git 在 Git上，每个工作成员可以任意在自己的本地版本库开启无限个分支。举例：当我想尝试破坏自己的程序（安检测试），并且想保留这些被修改的文件供日后使用， 我可以开一个分支，做我喜欢的事。完全不需担心妨碍其他工作成员。只要我不合并及提交到主要版本库，没有一个工作成员会被影响。等到我不需要这个分支时， 我只要把它从我的本地版本库删除即可，无痛无痒。 什么时候需要创建分支 举个例子：我们需要开发一个新的网站，我们已经在主分支（master分支）上开发出了1.0发布版本，这个时候我们需要开发某个新的功能模块，那就需要创建一个分支（dev分支），而不是在主分支上继续开发，这样做有两个好处： 我们在开发新的功能模块时，可能会遇到各种bug或者冲突，如果我们还在主分支上开发，万一冲突很严重，造成当前稳定版本的分支出问题，就会很麻烦。如果主分支始终保留着最新的稳定版本，在新的分支上开发，冲突严重时，最多也就是把当前分支删掉，从那个稳定分支重新分一支出来，这样处理起来就方便了，而且分支还可以保留开发中可能出现的各种bug方便修复但不影响主分支多的使用。 当我们需要切换分支，例如切换到主分支（master）时候，会保存当前分支（dev）的状态，以便日后继续开发，防止丢失开发进度。举个例子：你突然接到一个电话说1.0发布版本有个很严重的问题需要紧急修补，而我们正在dev分支上开发新的功能模块，这时我们先返回到主分支，为这次紧急修补建立一个新分支（repair分支），并在其中修复问题。通过测试后，回到主分支，将repair分支合并进来，然后push到远程仓库。最后，我们切换到之前开发新需求的dev分支，继续工作而不会丢失掉已经开发的进度。 可以在Git的任意一个提交点（commit point）开启分支！（其中一个方法是使用gitk –all 可观察整个提交记录，然后在任意点开啟分支） Git具有以下特点 Git 中每个克隆(clone)的版本库都是平等的。可以从任何一个版本库的克隆来创建属于自己的版本库，同时你的版本库也可以作为源提供给他人，只要你愿意。 Git 的每一次提取操作，实际上都是一次对代码仓库的完整备份。 提交完全在本地完成，无须别人给你授权，你的版本库你作主，并且提交总是会成功。 Git 的提交不会被打断，直到你的工作完全满意了，PUSH给他人或者他人PULL你的版本库，合并会发生在PULL和PUSH过程中，不能自动解决的冲突会提示你手工完成。 Git缺点 Git 没有严格的权限管理控制，一般通过系统设置文件读写权限的方式来做权限控制。 工作目录只能是整个项目。比如 check out、建分支，都是基于整个项目的。而 SVN 可以基于项目中的某一个目录。 参考详细透彻解读Git与SVN的区别（集中式VS分布式）","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://mx-go.github.io/tags/tools/"}]},{"title":"深入理解Spring","slug":"深入理解Spring","date":"2018-05-11T04:31:22.000Z","updated":"2021-05-05T03:17:45.532Z","comments":true,"path":"深入理解Spring/","link":"","permalink":"https://mx-go.github.io/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Spring/","excerpt":"引言Spring在当前Java项目开发中可谓是核心，无论是SpringMVC、SpringBoot、SpringCloud都离不开Spring这个核心。自己对Spring的了解也停留在一知半解状态。","text":"引言Spring在当前Java项目开发中可谓是核心，无论是SpringMVC、SpringBoot、SpringCloud都离不开Spring这个核心。自己对Spring的了解也停留在一知半解状态。 说起Spring，都知道是一个轻量级开源企业开发框架，包含控制反转（IOC）和面向切面（AOP）两大特性。 IOC什么是IOC（DI） IOC（Inversion Of Control，控制反转）。对于Spring框架来说，就是由Spring来负责控制对象的生命周期和对象间的关系。在一个对象中，如果要使用其他的对象，就必须得到它（自己new一个或者JNDI中查询一个），使用完对象之后还要将对象销毁（比如Connection等），对象始终会和其他的接口或类耦合起来。 所有的类都会在Spring容器中登记，告诉Spring自己是什么，需要什么，然后Spring会在系统运行到适当的时候，把你需要的东西主动给你，同时也把你交给其他需要你的东西。所有类的创建、销毁都由Spring来控制，也就是说控制对象生命周期的不再是引用它的对象，而是Spring容器。对于某个具体的对象而言，以前是它控制其他对象，现在是所有对象都被Spring控制，所以这叫做控制反转。 IOC的一个重点是在系统运行中，动态的向某个对象提供它所需要的其他对象。这一点是通过DI（Dependency Injection，依赖注入）来实现的。比如对象A需要操作数据库，本来需要在A中自己编写代码来获得一个Connection对象，有了Spring我们就只需要告诉Spring，A中需要一个Connection，至于这个Connection怎么构造，何时构造，A不需要知道。在系统运行时，Spring会在适当的时候制造一个Connection，然后像打针一样注射到A中，这样就完成了各个对象之间关系的控制。A需要依赖Connection才能正常运行，而这个Connection是由Spring注入到A中的，依赖注入的名字就是这么来的。那么DI是如何实现的呢？Java1.3之后一个重要特征就是反射（reflection），它允许程序在运行的时候动态的生成对象、执行对象的方法、改变对象的属性，Spring就是通过反射来实现注入的。 在没有使用Spring的时候，每个对象在需要使用他的合作对象时，自己均要使用像new object() 这样的语法来将合作对象创建出来，这个合作对象是由自己主动创建出来的，创建合作对象的主动权在自己手上，自己需要哪个合作对象，就主动去创建，创建合作对象的主动权和创建时机是由自己把控的，而这样就会使得对象间的耦合度高了，A对象需要使用合作对象B来共同完成一件事，A要使用B，那么A就对B产生了依赖，也就是A和B之间存在一种耦合关系，并且是紧密耦合在一起，而使用了Spring之后就不一样了，创建合作对象B的工作是由Spring来做的，Spring创建好B对象，然后存储到一个容器里面，当A对象需要使用B对象时，Spring就从存放对象的那个容器里面取出A要使用的那个B对象，然后交给A对象使用，至于Spring是如何创建那个对象，以及什么时候创建好对象的，A对象不需要关心这些细节问题(你是什么时候生的，怎么生出来的我可不关心，能帮我干活就行)，A得到Spring给我们的对象之后，两个人一起协作完成要完成的工作即可。 所以控制反转IOC（Inversion Of Control）是说创建对象的控制权进行转移，以前创建对象的主动权和创建对象的时机是由自己把控的，而现在这种权利转移到了第三方。比如交给了IOC容器，它就是一个专门来创建对象的工厂，你需要什么对象，它就给你什么对象，有了IOC容器，依赖关系就变了，原来的依赖关系就没了，他们都依赖IOC容器，通过IOC容器来建立它们之间的关系。 IOC的优点可维护性比较好 便于进行单元测试，便于调试程序和诊断故障。代码中的每一个Class都可以单独测试，彼此之间互不影响，只要保证自身的功能无误即可，这就是组件之间低耦合或者无耦合带来的好处。 可复用性好 可以把具有普遍性的常用组件独立出来，反复利用到项目中的其它部分，或者是其它项目，当然这也是面向对象的基本特征。IOC不仅更好地贯彻了这个原则，提高了模块的可复用性。 分层、解耦 IOC生成对象的方式转为外置方式，也就是把对象生成放在配置文件里进行定义，这样，当我们更换一个实现子类将会变得很简单，只要修改配置文件就可以了，完全具有热插拨的特性。 AOP AOP（Aspect-OrientedProgramming，面向切面编程）。例如日志功能，日志代码往往水平地散布在所有对象层次中，而与它所散布到的对象的核心功能毫无关系。对于其他类型的代码，如安全性、异常处理和透明的持续性也是如此。这种散布在各处的无关的代码被称为横切（cross-cutting）代码，在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 而AOP技术则恰恰相反，它利用一种称为“横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其名为“Aspect”，即切面。所谓“切面”，简单地说，就是将那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可操作性和可维护性。AOP代表的是一个横向的关系。 使用“横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处都基本相似。比如权限认证、日志、事务处理。Aop 的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 实现AOP的技术，主要分为两大类：一是采用动态代理技术，利用截取消息的方式，对该消息进行装饰，以取代原有对象行为的执行；二是采用静态织入（静态代理）的方式，引入特定的语法创建“方面”，从而使得编译器可以在编译期间织入有关“Aspect”的代码。 AOP的优点：便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可操作性和可维护性。 具体代理模式可参见Spring之动态代理 Spring单例、线程安全Spring中的线程安全 Spring中管理bean实例默认情况下都是单例的【singleton】，还有prototype类型，按其作用域来讲有singleton、prototype、request、session、global、session。 Spring中的单例与设计模式里面的单例略有不同，设计模式的单例是在整个应用中只有一个实例，而Spring中的单例是在一个IOC容器中就有一个实例。但Spring中的单例也不会影响应用的并发访问【不会出现各个线程之间的等待问题或是死锁问题】，因为大多数时候客户端都在访问我们应用中的业务对象，而这些业务对象并没有做线程的并发限制，只是在这个时候我们不应该在业务对象中设置那些容易出错的成员变量，在并发访问的时候这些成员变量将会是并发线程中的共享对象，那么这个时候就会出现意外情况。 实体bean不是单例的，并没有交给Spring来管理，每次我们要手动new出来的【Item item = new Item()】，所以即使是那些处理我们提交数据的业务处理类是被多线程共享的，但是他们处理的数据并不是共享的，数据是每一个线程都有自己的一份，所以在数据这个方面是不会出现线程同步方面的问题的。但是那些在Dao中的xxxDao或Controller中的xxxService，这些对象都是单例的，那么就会出现线程同步的问题。但是这些对象虽然会被多个线程并发访问，可我们访问的是他们里面的方法，这些类里面通常不会含有成员变量，Dao里面的ibatisDao是框架里面封装好的，已经被测试，不会发生线程同步问题。所以出现问题的地方就是我们自己系统里面的业务对象，所以一定要注意这些业务对象里面千万不能独立成员变量，否则会出问题。 Spring中容器托管的类如果没有特殊声明（scope=“prototype”），则默认为单例模式。当多个用户同时请求一个服务时，容器会给每一个请求分配一个线程，这是多个线程并发执行该请求多对应的业务逻辑（成员方法）。此时就要注意，如果该处理逻辑中有对该单列状态的修改（成员变量），则必须考虑线程同步问题；否则由于在业务逻辑中执行所需的局部变量会分配在栈空间中，所以不需要同步。 其实函数本身是代码，代码是只读的，无论多少个线程同时调都无所谓（因为只是读的），但是函数中肯定是要用到数据的，如果数据是函数参数、局部变量，那么这些数据都是存在每个线程自己的栈上的，同时调用是没有关系的，不会涉及到线程安全资源共享的问题。 但是如果使用到了全局静态变量或者类的成员变量的时候。就会出现数据安全的问题，还有，如果我们的成员变量在函数体内如果只进行读操作，不进行写操作，也是线程安全的。 总而言之，单例的方法在同一个时刻是可以被多个线程同时调用的。在写程序的时候要尽可能少的使用类的成员变量，如果使用成员变量，尽量保证只对成员变量进行读操作。 当很多用户去修改自己信息的时候，用户线程会通过调用dao（dao都是给注入有配链接池的数据源的），dao会拿到链接池中的一个链接，将我们要处理的信息（SQL语句等）交付给数据库，数据库会按照自己的多线程处理机制完成线程的同步，然后进行数据安全处理，线程在完成数据处理后会将占有的链接放回到链接池中。 Spring中同步机制 单例模式的意思就是只有一个实例。单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例。这个类称为单例类。 当多用户同时请求一个服务时，容器会给每一个请求分配一个线程，这是多个线程会并发执行该请求多对应的业务逻辑（成员方法），此时就要注意了，如果该处理逻辑中有对该单列状态的修改（体现为该单列的成员属性），则必须考虑线程同步问题。 同步机制比较ThreadLocal和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。 在同步机制中，通过对象的锁机制保证同一时间只有一个线程访问变量。这时该变量是多个线程共享的，使用同步机制要求程序慎密地分析什么时候对变量进行读写，什么时候需要锁定某个对象，什么时候释放对象锁等繁杂的问题，程序设计和编写难度相对较大。 而ThreadLocal则从另一个角度来解决多线程的并发访问。ThreadLocal会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进ThreadLocal。由于ThreadLocal中可以持有任何类型的对象，低版本JDK所提供的*get()*返回的是Object对象，需要强制类型转换。但JDK 5.0通过泛型很好的解决了这个问题，在一定程度地简化ThreadLocal的使用 。 概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 Spring使用ThreadLocal解决线程安全问题 在一般情况下，只有无状态的Bean才可以在多线程环境下共享。在Spring中，绝大部分Bean都可以声明为singleton作用域。就是因为Spring对一些Bean（如RequestContextHolder、TransactionSynchronizationManager、LocaleContextHolder等）中非线程安全状态采用ThreadLocal进行处理，让它们也成为线程安全的状态，这样有状态的Bean就可以在多线程中共享了。 一般的Web应用划分为表现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程。ThreadLocal是解决线程安全问题一个很好的思路，它通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题。在很多情况下，ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。 线程安全问题都是由成员变量引起的 若每个线程中对成员变量（全局变量、静态变量）只有读操作，而无写操作，一般来说，这个全局变量是线程安全的；若有多个线程同时执行写操作，一般都需要考虑线程同步，否则就可能影响线程安全。1） 常量始终是线程安全的，因为只存在读操作。2）每次调用方法前都新建一个实例是线程安全的，因为不会访问共享的资源。3）局部变量是线程安全的。因为每执行一个方法，都会在独立的空间创建局部变量，它不是共享的资源。局部变量包括方法的参数变量和方法内变量。 有状态就是有数据存储功能。有状态对象(Stateful Bean)，就是有实例变量的对象，可以保存数据，是非线程安全的。在不同方法调用间不保留任何状态。 无状态就是一次操作，不能保存数据。无状态对象(Stateless Bean)，就是没有实例变量的对象，不能保存数据，是不变类，是线程安全的。 无状态的Bean适合用不变模式，技术就是单例模式，这样可以共享实例，提高性能。有状态的Bean，多线程环境下不安全，那么适合用Prototype原型模式。Prototype: 每次对bean的请求都会创建一个新的bean实例。 总结 Spring中DAO和Service都是以单实例的bean形式存在，Spring通过ThreadLocal类将有状态的变量（例如数据库连接Connection）本地线程化，从而做到多线程状况下的安全。在一次请求响应的处理线程中， 该线程贯通展示、服务、数据持久化三层，通过ThreadLocal使得所有关联的对象引用到的都是同一个变量。 在事务属性为REQUIRED时，在相同线程中进行相互嵌套调用的事务方法工作于相同的事务中。如果互相嵌套调用的事务方法工作在不同线程中，则不同线程下的事务方法工作在独立的事务中。 程序只要使用SpringDAO模板，例如JdbcTemplate进行数据访问，一定没有数据库连接泄露问题！如果程序中显式的获取了数据连接Connection，则需要手工关闭它，否则就会泄露！ 当Spring事务方法运行时，就产生一个事务上下文，它在本事务执行线程中对同一个数据源绑定了一个唯一的数据连接，所有被该事务上下文传播的方法都共享这个连接。要获取这个连接，如要使用Spirng的资源获取工具类DataSourceUtils。 事务管理上下文就好比一个盒子，所有的事务都放在里面。如果在某个事务方法中开启一个新线程，新线程中执行另一个事务方法，则由上面第二条可知这两个方法运行于两个独立的事务中，但是：如果使用DataSourcesUtils，则新线程中的方法可以从事务上下文中获取原线程中的数据连接！ 参考Spring容器深入 Spring单例、线程安全、事务等疑惑 收集","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"说说Spring中的事务","slug":"说说Spring中的事务","date":"2018-05-09T13:24:58.000Z","updated":"2021-05-05T03:20:01.456Z","comments":true,"path":"说说Spring中的事务/","link":"","permalink":"https://mx-go.github.io/%E8%AF%B4%E8%AF%B4Spring%E4%B8%AD%E7%9A%84%E4%BA%8B%E5%8A%A1/","excerpt":"引言在开发过程中，合理的使用事务是非常重要的。使用事务常常是为了维护高度的数据完整性和一致性。如果不关心数据的质量，就不必使用事务。毕竟，Java平台中的事务支持会降低性能，引发锁定问题和数据库并发性问题，而且会增加应用程序的复杂性。最近在面试中也是频频出现，在这里回顾加深一下。","text":"引言在开发过程中，合理的使用事务是非常重要的。使用事务常常是为了维护高度的数据完整性和一致性。如果不关心数据的质量，就不必使用事务。毕竟，Java平台中的事务支持会降低性能，引发锁定问题和数据库并发性问题，而且会增加应用程序的复杂性。最近在面试中也是频频出现，在这里回顾加深一下。 四大特性数据库中事务有四大特性，简称为 ACID 特性。 原子性(Atomicity)事务的原子性是指事务是一个不可分割的工作单位，这组操作要么全部发生，否则全部不发生。 一致性(Consistency)一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 隔离性(Isolation)隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。 持久性(Durability)持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 隔离级别事务并发带来的问题脏读(Dirty Reads)脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。 当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。 例如：用户A向用户B转账100元，对应SQL命令如下： 123update account set money = money + 100 where name=&#x27;B&#x27;; (此时A通知B)update account set money = money - 100 where name=&#x27;A&#x27;; 当只执行第一条SQL时，A通知B查看账户，B发现确实钱已到账（此时即发生了脏读），而之后无论第二条SQL是否执行，只要该事务不提交，则所有操作都将回滚，那么当B以后再次查看账户时就会发现钱其实并没有转。 不可重复读(Non-Repeatable Reads)不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发生了不可重复读。 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。 幻读(虚读)(Phantom Reads)幻读是事务非独立执行时发生的一种现象。 例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。 不可重复读是指同一查询在同一事务中多次进行，由于其他提交事务所做的修改或删除，每次返回不同的结果集，此时发生非重复读。 幻像读是指同一查询在同一事务中多次进行，由于其他提交事务所做的插入操作，每次返回不同的结果集，此时发生幻像读。 四种隔离级别(Isolation Level) Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 Read committed (读已提交)：可避免脏读的发生。 Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁) 使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。**MySQL数据库中默认的隔离级别为Repeatable read (可重复读)**。 在MySQL数据库中查看当前事务的隔离级别： 1SELECT @@tx_isolation; 传播方式(Propagation)REQUIRED（默认）如果存在一个事务，则支持当前事务。如果没有事务则开启一个新的事务(Support a current transaction, create a new one if none exists.)。 被设置成这个级别时，会为每一个被调用的方法创建一个逻辑事务域。如果前面的方法已经创建了事务，那么后面的方法支持当前的事务，如果当前没有事务会重新建立事务。 REQUIRES_NEW新建事务，如果当前存在事务，把当前事务挂起(Create a new transaction, suspend the current transaction if one exists.)。 SUPPORTS支持当前事务，如果当前没有事务，就以非事务方式执行(Support a current transaction, execute non-transactionally if none exists.)。 NOT_SUPPORTED以非事务方式执行操作，如果当前存在事务，就把当前事务挂起(Execute non-transactionally, suspend the current transaction if one exists.)。 NEVER以非事务方式执行，如果当前存在事务，则抛出异常(Execute non-transactionally, throw an exception if a transaction exists.)。 NESTED支持当前事务，新增Savepoint点，与当前事务同步提交或回滚(Execute within a nested transaction if a current transaction exists, behave like PROPAGATION_REQUIRED else.)。 MANDATORY支持当前事务，如果当前没有事务，就抛出异常(Support a current transaction, throw an exception if none exists.)。 REQUIRES_NEW和NESTED区别**REQUIRES_NEW*启动一个新的，不依赖于环境的 “内部” 事务。这个事务将被完全commited*或rolledback而不依赖于外部事务，它拥有自己的隔离范围，自己的锁等等。当内部事务开始执行时，外部事务将被挂起，内务事务结束时，外部事务将继续执行。REQUIRES_NEW常用于日志记录、交易失败仍需留痕等场景。 ***PROPAGATION_NESTED*开始一个”嵌套”的事务，它是已经存在事务的一个真正的子事务。嵌套事务开始执行时，它将取得一个savepoint*。 如果这个嵌套事务失败，将回滚到此savepoint*.。嵌套事务是外部事务的一部分,，只有外部事务结束后它才会被提交。 由此可见，PROPAGATION_REQUIRES_NEW和PROPAGATION_NESTED的最大区别在于，PROPAGATION_REQUIRES_NEW完全是一个新的事务，而PROPAGATION_NESTED则是外部事务的子事务，如果外部事务commit，嵌套事务也会被commit，这个规则同样适用于rollback。 Spring事务陷阱同一方法中执行多次表更新（无事务）1234567891011// 例一public TradeData placeTrade(TradeData trade) throws Exception &#123; try &#123; insertTrade(trade); updateAcct(trade); return trade; &#125; catch (Exception up) &#123; //log the error throw up; &#125;&#125; insertTrade() 和 updateAcct() 方法使用不带事务的标准 JDBC 代码。insertTrade() 方法结束后，数据库保存（并提交了）交易订单。如果 updateAcct() 方法由于任意原因失败，交易订单仍然会在 placeTrade() 方法结束时保存在 TRADE 表内，这会导致数据库出现不一致的数据。如果 placeTrade() 方法使用了事务，这两个活动都会包含在一个事务中，如果帐户更新失败，交易订单就会回滚。 利用@Transaction注解事务例二：将只读标志与 SUPPORTS 传播模式结合使用 12345// 例二@Transactional(readOnly = true, propagation=Propagation.SUPPORTS)public long insertTrade(TradeData trade) throws Exception &#123; insert(trade);&#125; 执行到例二的 insertTrade() 方法时，结果是：正确插入交易订单并提交数据。 交易订单会被正确地插入到数据库中，即使只读标志被设置为 true，且事务传播模式被设置为 SUPPORTS。但这是如何做到的呢？由于传播模式被设置为 SUPPORTS，所以不会启动任何事务，因此该方法有效地利用了一个本地（数据库）事务。只读标志只在事务启动时应用。在本例中，因为没有启动任何事务，所以只读标志被忽略。 例三：将只读标志与 REQUIRED 传播模式结合使用 1234@Transactional(readOnly = true, propagation=Propagation.REQUIRED)public long insertTrade(TradeData trade) throws Exception &#123; em.persist(trade);&#125; 执行到例三的 insertTrade() 方法时，结果是：抛出一个只读连接异常。 表示正在试图对一个只读连接执行更新。因为启动了一个事务（REQUIRED），而连接被设置为只读。毫无疑问，在试图执行 SQL 语句时，会得到一个异常，告诉该连接是一个只读连接。 关于只读标志很奇怪的一点是：要使用它，必须启动一个事务。如果只是读取数据，需要事务吗？答案是根本不需要。启动一个事务来执行只读操作会增加处理线程的开销，并会导致数据库发生共享读取锁定（具体取决于使用的数据库类型和设置的隔离级别）。 例四：使用只读标志 1234@Transactional(readOnly = true)public TradeData getTrade(long tradeId) throws Exception &#123; return em.find(tradeId);&#125; 执行到例四的 getTrade() 方法时，结果是：启动一个事务，获取交易订单，然后提交事务。 @Transactional 注释的**默认传播模式是 REQUIRED**。这意味着事务会在不必要的情况下启动。根据使用的数据库，这会引起不必要的共享锁，可能会使数据库中出现死锁的情况。此外，启动和停止事务将消耗不必要的处理时间和资源。总的来说，在使用基于ORM的框架时，只读标志基本上毫无用处，在大多数情况下会被忽略。但如果坚持使用它，记得将传播模式设置为 SUPPORTS（如下例五所示），这样就不会启动事务： 12345// 例五@Transactional(readOnly = true, propagation=Propagation.SUPPORTS)public TradeData getTrade(long tradeId) throws Exception &#123; return em.find(tradeId);&#125; REQUIRES_NEW 事务属性陷阱REQUIRES_NEW 事务属性总是会在启动方法时启动一个新的事务，使用 REQUIRES_NEW 事务属性都会得到不好的结果并导致数据损坏和不一致。 例六： 使用 REQUIRES_NEW 事务属性 12345@Transactional(propagation=Propagation.REQUIRES_NEW)public long insertTrade(TradeData trade) throws Exception &#123;...&#125; @Transactional(propagation=Propagation.REQUIRES_NEW)public void updateAcct(TradeData trade) throws Exception &#123;...&#125; 例六中的两个方法都是公共方法，意味着它们可以单独调用。当使用 REQUIRES_NEW 属性的几个方法通过服务间通信或编排在同一逻辑工作单元内调用时，该属性就会出现问题。假设在例六中，可以独立于一些用例中的任何其他方法来调用 updateAcct() 方法，但也有在 insertTrade() 方法中调用 updateAcct() 方法的情况。现在如果调用 updateAcct() 方法后抛出异常，交易订单就会回滚，但帐户更新将会提交给数据库，如下例七所示： 例七：使用 REQUIRES_NEW 事务属性的多次更新 12345678@Transactional(propagation=Propagation.REQUIRES_NEW)public long insertTrade(TradeData trade) throws Exception &#123; em.persist(trade); updateAcct(trade); // 这里出现异常! insertTrade回滚但是updateAcct不会回滚! // exception occurs here! Trade rolled back but account update is not! ...&#125; 发生这种情况的原因是 updateAcct() 方法中启动了一个新事务，所以在 updateAcct() 方法结束后，事务将被提交。使用 REQUIRES_NEW 事务属性时，如果存在现有事务上下文，当前的事务会被挂起并启动一个新事务。方法结束后，新的事务被提交，原来的事务继续执行。 由于这种行为，只有在被调用方法中的数据库操作需要保存到数据库中，而不管覆盖事务的结果如何时，才应该使用 REQUIRES_NEW 事务属性。比如，假设尝试的所有股票交易都必须被记录在一个审计数据库中。出于验证错误、资金不足或其他原因，不管交易是否失败，这条信息都需要被持久化。如果没有对审计方法使用 REQUIRES_NEW 属性，审计记录就会连同尝试执行的交易一起回滚。使用 REQUIRES_NEW 属性可以确保不管初始事务的结果如何，审计数据都会被保存。这里要注意的一点是，要始终使用 MANDATORY 或 REQUIRED 属性，而不是 REQUIRES_NEW，除非有足够的理由来使用它，类似审计示例中的那些理由。 Spring事务REQUIRES_NEW不起作用原因是A方法（REQUIRES）调用B方法（REQUIRES_NEW）在同一类中，如果两个方法写在同一个Service类中，Spring并不会重新创建新事务，如果是两不同的Service，就会创建新事务了。 解决方案1：需要将两个方法分别写在不同的类中。 解决方案2：方法写在同一个类里，但调用B方法的时候，将service自己注入自己，用这个注入对象来调用B方法。 事务回滚陷阱例八：没有回滚支持 1234567891011@Transactional(propagation=Propagation.REQUIRED)public TradeData placeTrade(TradeData trade) throws Exception &#123; try &#123; insertTrade(trade); updateAcct(trade); return trade; &#125; catch (Exception up) &#123; //log the error throw up; &#125;&#125; 假设帐户中没有足够的资金来购买需要的股票，或者还没有准备购买或出售股票，并抛出了一个受检异常，那么交易订单会保存在数据库中吗？还是整个逻辑工作单元将执行回滚？答案出乎意料：根据受检异常（不管是在 Spring Framework 中还是在 EJB 中），事务会提交它还未提交的所有工作。使用例八，这意味着，如果在执行 updateAcct() 方法期间抛出受控异常，就会保存交易订单，但不会更新帐户来反映交易情况。 这可能是在使用事务时出现的主要数据完整性和一致性问题了。运行时异常（即非受检异常）自动强制执行整个逻辑工作单元的回滚，但受检异常不会。 例九：添加事务回滚支持 — Spring 1234567891011@Transactional(propagation=Propagation.REQUIRED, rollbackFor=Exception.class)public TradeData placeTrade(TradeData trade) throws Exception &#123; try &#123; insertTrade(trade); updateAcct(trade); return trade; &#125; catch (Exception up) &#123; //log the error throw up; &#125;&#125; @Transactional 注释中使用了 rollbackFor 参数。这个参数接受一个单一异常类或一组异常类，也可以使用 rollbackForClassName 参数将异常的名称指定为 Java String 类型。还可以使用此属性的相反形式（noRollbackFor）指定除某些异常以外的所有异常应该强制回滚。通常大多数开发人员指定 Exception.class 作为值，表示该方法中的所有异常应该强制回滚。 下面两种方式同样会回滚 1234567891011121314151617181920212223// 方式一，手动回滚@Transactional(propagation=Propagation.REQUIRED)public TradeData placeTrade1(TradeData trade) throws Exception &#123; try &#123; insertTrade(trade); updateAcct(trade); return trade; &#125; catch (Exception up) &#123; TransactionAspectSupport.currentTransactionStatus().setRollbackOnly(); &#125;&#125;// 方式二，抛出RuntimeException@Transactional(propagation=Propagation.REQUIRED)public TradeData placeTrade2(TradeData trade) throws Exception &#123; try &#123; insertTrade(trade); updateAcct(trade); return trade; &#125; catch (Exception up) &#123; throw new RuntimeException(); &#125;&#125; 参考了解事务陷阱","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"JAVA并发之锁","slug":"JAVA并发之锁","date":"2018-05-06T07:45:39.000Z","updated":"2021-05-09T10:46:58.899Z","comments":true,"path":"JAVA并发之锁/","link":"","permalink":"https://mx-go.github.io/JAVA%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%94%81/","excerpt":"引言锁作为并发共享数据，保证一致性的工具，数据库中有悲观锁、乐观锁等实现。在JAVA平台同样有多种实现(如 synchronized和Lock)。这些已经写好提供的锁为开发提供了便利，让我们有了更多的选择。","text":"引言锁作为并发共享数据，保证一致性的工具，数据库中有悲观锁、乐观锁等实现。在JAVA平台同样有多种实现(如 synchronized和Lock)。这些已经写好提供的锁为开发提供了便利，让我们有了更多的选择。 JAVA中锁分类乐观/悲观锁乐观锁：乐观锁则认为对于同一个数据的并发操作，是不会发生修改的。在更新数据的时候，会采用尝试更新，不断重新的方式更新数据，乐观的认为不加锁的并发操作是没有事情的。适合读操作多的场景。 乐观锁在JAVA中的使用，是无锁编程，Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS(CompareAndSwap)实现的。 CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 CAS操作中包含三个操作数 —— *内存值(V)、旧的的预期原值(A)和拟写入的新值(B)*。如果内存值V的值与预期原值A相匹配，那么处理器会自动将该位置值更新为新值B*，否则处理器不做任何操作。无论哪种情况，它都会在CAS指令之前返回该位置的值。(在CAS的一些特殊情况下将仅返回CAS是否成功，而不提取当前值)。CAS有效地说明了“我认为位置V应该包含值A；如果包含该值，则将B*放到这个位置；否则，不要更改该值，只告诉我这个位置现在的值即可“。 CAS缺点：ABA问题。 悲观锁：悲观锁认为对于同一个数据的并发操作，一定是会发生修改的，哪怕没有修改，也会认为修改。因此对于同一个数据的并发操作，悲观锁采取加锁的形式。悲观的认为，不加锁的并发操作一定会出问题。适合写操作多的场景。Java里面的同步语义synchronized关键字的实现是悲观锁。 可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。JAVA中的synchronized与ReentrantLock都是可重入锁。可重入锁的一个好处是可一定程度避免死锁。 对于Java ReentrantLock而言, 他的名字就可以看出是一个可重入锁，其名字是ReentrantLock重新进入锁。 对于synchronized而言，也是一个可重入锁。 12345678synchronized void methodA() throws Exception&#123; Thread.sleep(1000); methodB();&#125;synchronized void methodB() throws Exception&#123; Thread.sleep(1000);&#125; 上面的代码就是一个可重入锁的一个特点，如果不是可重入锁的话，methodB可能不会被当前线程执行，可能造成死锁。 独占/共享锁独占锁：是指该锁一次只能被一个线程所持有。共享锁：是指该锁可被多个线程所持有。 对于Java ReentrantLock而言，其是独占锁(互斥锁)。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁(读写锁)，其写锁是独占锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。 独占锁与共享锁也是通过AQS(AbstractQueuedSynchronizer[队列同步器])来实现的，通过实现不同的方法，来实现独占或者共享。 对于synchronized而言，是独占锁。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap(JDK7与JDK8中HashMap的实现)的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock(Segment继承了ReentrantLock)。当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在哪一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在同一个分段中，就实现了真正的并行插入。但是，在统计size的时候，就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。 synchronized锁synchronized是Java的一个关键字，它能够将代码块(方法)锁起来，它是在软件层面依赖JVM实现同步。 它使用起来是非常简单的，只要在代码块(方法)添加关键字synchronized，即可以实现同步的功能。 123public synchronized void test() &#123; // doSomething&#125; synchronized是一种互斥锁。 一次只能允许一个线程进入被锁住的代码块 synchronized是一种内置锁/监视器锁。 Java中每个对象都有一个**内置锁(监视器,也可以理解成锁标记)，而synchronized就是使用对象的内置锁(监视器)**来将代码块(方法)锁定的。 用处 synchronized保证了线程的原子性。(被保护的代码块是一次被执行的，没有任何线程会同时访问)。 synchronized保证了可见性。(当执行完synchronized之后，修改后的变量对其他的线程是可见的)。 Java中的synchronized，通过使用内置锁，来实现对变量的同步操作，进而实现了对变量操作的原子性和其他线程对变量的可见性，从而确保了并发情况下的线程安全。 原理下面是synchronized修饰方法和代码块的代码实例： 12345678910111213public class Main &#123; //修饰方法 public synchronized void test1()&#123; &#125; public void test2()&#123; // 修饰代码块 synchronized (this)&#123; // dosomething &#125; &#125;&#125; 反编译结果如下图： 同步代码块：monitorenter和monitorexit指令实现的。 同步方法（在这看不出来需要看JVM底层实现）：方法修饰符上的ACC_SYNCHRONIZED实现。 synchronized底层是是通过monitor对象，对象有自己的对象头，存储了很多信息，其中一个信息标示是被哪个线程持有。 synchronized的使用synchronized一般用来修饰三种东西： 修饰普通方法 修饰代码块 修饰静态方法 修饰普通方法用的锁是SyncTest对象(内置锁) 1234567public class SyncTest &#123; // 修饰普通方法，此时用的锁是SyncTest对象(内置锁) public synchronized void test() &#123; // doSomething &#125;&#125; 修饰代码块用的锁是**SyncTest对象(内置锁) ** —&gt; this 123456789public class SyncTest &#123; public void test() &#123; // 修饰代码块，此时用的锁是SyncTest对象(内置锁)---&gt;this synchronized (this)&#123; // doSomething &#125; &#125;&#125; 修饰静态方法用的锁是类锁，锁的是SyncTest类。 123456789101112public class SyncTest &#123; // 1.修饰代码块，此时用的锁是SyncTest类锁 public static synchronized void test() &#123; // doSomething &#125; // 2.修饰类的class synchronized(SyncTest.class) &#123; // doSomething &#125;&#125; 类锁与对象锁synchronized修饰静态方法获取的是类锁(类的字节码文件对象)，synchronized修饰普通方法或代码块获取的是对象锁。 一个锁的是类对象，一个锁的是实例对象。若类对象被lock，则类对象的所有同步方法全被lock；若实例对象被lock，则该实例对象的所有同步方法全被lock。 synchronized static是某个类的范围，防止多个线程中多个实例同时访问这个类中的synchronized static方法。它可以对类的所有对象实例起作用。 synchronized是某实例的范围，synchronized防止多个线程中同一个实例同时访问这个类的synchronized 方法。 它们互不冲突，也就是说：获取了类锁的线程和获取了对象锁的线程是不冲突的。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class SynchoronizedDemo &#123; // synchronized修饰非静态方法 public synchronized void function() throws InterruptedException &#123; for (int i = 0; i &lt; 3; i++) &#123; Thread.sleep(1000); System.out.println(&quot;function running...&quot;); &#125; &#125; // synchronized修饰静态方法 public static synchronized void staticFunction() throws InterruptedException &#123; for (int i = 0; i &lt; 3; i++) &#123; Thread.sleep(1000); System.out.println(&quot;Static function running...&quot;); &#125; &#125; public static void main(String[] args) &#123; final SynchoronizedDemo demo = new SynchoronizedDemo(); // 创建线程执行静态方法 Thread t1 = new Thread(() -&gt; &#123; try &#123; staticFunction(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); // 创建线程执行实例方法 Thread t2 = new Thread(() -&gt; &#123; try &#123; demo.function(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); // 启动 t1.start(); t2.start(); &#125;&#125; 结果证明：类锁和对象锁是不会冲突的！ 重入锁123456789101112131415public class Widget &#123; // 加锁 public synchronized void doSomething() &#123; ... &#125;&#125;public class LoggingWidget extends Widget &#123; // 加锁 public synchronized void doSomething() &#123; System.out.println(toString() + &quot;: calling doSomething&quot;); super.doSomething(); &#125;&#125; 当线程A进入到LoggingWidget的doSomething()方法时，此时拿到了LoggingWidget实例对象的锁。 随后在方法上又调用了父类Widget的doSomething()方法，它又是被synchronized修饰。 那现在我们LoggingWidget实例对象的锁还没有释放，进入父类Widget的doSomething()方法还需要一把锁吗？ 不需要的！ 因为锁的持有者是“线程”，而不是“调用”。线程A已经是有了LoggingWidget实例对象的锁了，当再需要的时候可以继续“开锁”进去的！ 这就是内置锁的可重入性。 释放锁的时机 当方法(代码块)执行完毕后会自动释放锁，不需要做任何的操作。 当一个线程执行的代码出现异常时，其所持有的锁会自动释放。 不会由于异常导致出现死锁现象。 Lock显式锁简单介绍Lock显式锁是JDK1.5之后才有的，之前都是使用synchronized锁来使线程安全的。 Lock显式锁是一个接口 Lock方式来获取锁支持中断、超时不获取、是非阻塞的。 提高了语义化，哪里加锁，哪里解锁都得写出来。 Lock显式锁可以给我们带来很好的灵活性，但同时必须手动释放锁。 支持Condition条件对象。 允许多个读线程同时访问共享资源。 常用方式Lock接口，它提供了比synchronized更加广泛的锁定操作。Lock接口有3个实现它的类：ReentrantLock、ReetrantReadWriteLock.ReadLock和ReetrantReadWriteLock.WriteLock，即重入锁、读锁和写锁。 lock必须被显式地创建、锁定和释放，为了可以使用更多的功能，一般用ReentrantLock为其实例化。为了保证锁最终一定会被释放(可能会有异常发生)，要把互斥区放在try语句块内，并在finally语句块中释放锁，尤其当有return语句时，return语句必须放在try字句中，以确保unlock()不会过早发生，从而将数据暴露给第二个任务。因此，采用lock加锁和释放锁的一般形式如下： 123456789101112// 默认使用非公平锁，如果要使用公平锁，需要传入参数true Lock lock = new ReentrantLock();........ lock.lock(); try &#123; // 更新对象的状态 // 捕获异常，必要时恢复到原来的不变约束 // 如果有return语句，放在这里 &#125;finally &#123; // 锁必须在finally块中释放 lock.unlock();&#125; 实现策略Lock基于冲突检测的乐观并发策略，如果没有其他线程争用共享数据，那操作就成功了，如果共享数据被争用，产生了冲突，那就再进行其他的补偿措施(最常见的补偿措施就是不断地重试，直到试成功为止)，这种乐观并发策略的许多实现都不需要把线程挂起，因此这种同步被称为非阻塞同步。ReetrantLock采用的便是这种并发策略。 在乐观的并发策略中，需要操作和冲突检测这两个步骤具备原子性，它靠硬件指令来保证，这里用的是CAS操作(Compare and Swap)。JDK1.5之后，Java程序才可以使用CAS操作。进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState，这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而compareAndSet()就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起。 Java 5中引入了注入AutomicInteger、AutomicLong、AutomicReference等特殊的原子性变量类，它们提供的如：compareAndSet()、incrementAndSet()和getAndIncrement()等方法都使用了CAS操作。因此，它们都是由硬件指令来保证的原子方法。 ReetrankLock与synchronized比较性能比较在JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞的是实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。 到了JDK1.6，对synchronize加入了很多优化措施，有自适应自旋、锁消除、锁粗化、轻量级锁、偏向锁等等。 在JDK1.8以后，对synchronized性能进行了优化，使其和ReentrantLock的性能相差不多。所以还是提倡在synchronized能实现需求的情况下，优先考虑使用synchronized来进行同步。 实现策略synchronized采用的是互斥同步，因而这种同步又称为阻塞同步，它属于一种悲观的并发策略，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁，synchronized是托管给JVM执行的。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。 Lock基于乐观的并发策略，是Java写的控制锁的代码，基于CAS硬件指令保证。 用途基本语法上，ReentrantLock与synchronized很相似，它们都具备一样的线程重入特性，只是代码写法上有点区别而已，一个表现为API层面的互斥锁(lock和unlock方法配合try/finally语句块来完成)，一个表现为原生语法层面的互斥锁(synchronized)。ReentrantLock相对synchronized而言还是增加了一些高级功能，主要有以下三项： 等待可中断当持有锁的线程长期不释放锁时，正在等待的线程可以选择放弃等待，改为处理其他事情，它对处理执行时间非常长的同步块很有帮助。而在等待由synchronized产生的互斥锁时，会一直阻塞，是不能被中断的。 1234567891011ReentrantLock lock = new ReentrantLock(); ........... lock.lockInterruptibly();//获取响应中断锁 try &#123; // 更新对象的状态 // 捕获异常，必要时恢复到原来的不变约束 // 如果有return语句，放在这里 &#125;finally&#123; // 锁必须在finally块中释放 lock.unlock(); &#125; 可实现公平锁多个线程在等待同一个锁时，必须按照申请锁的时间顺序排队等待，而非公平锁则不保证这点，在锁释放时，任何一个等待锁的线程都有机会获得锁。synchronized中的锁时非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过构造方法ReentrantLock(ture)来要求使用公平锁，公平锁会来带一些性能的消耗。 锁绑定多个条件ReentrantLock对象可以同时绑定多个Condition对象(条件变量或条件队列)，而在synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含条件，但如果要和多于一个的条件关联的时候，就不得不额外地添加一个锁，而ReentrantLock则无需这么做，只需要多次调用newCondition()方法即可。还可以通过绑定Condition对象来判断当前线程通知的是哪些线程(即与Condition对象绑定在一起的其他线程)。 读写锁synchronized获取的互斥锁不仅互斥读写操作、写写操作，还互斥读读操作，而读读操作是不会带来数据竞争的，因此对对读读操作也互斥的话，会降低性能。Java5中提供了读写锁，它将读锁和写锁分离，使得读读操作不互斥，获取读锁和写锁的一般形式如下： 123ReadWriteLock rwl = new ReentrantReadWriteLock(); rwl.writeLock().lock() //获取写锁 rwl.readLock().lock() //获取读锁 用读锁来锁定读操作，用写锁来锁定写操作，这样写操作和写操作之间会互斥，读操作和写操作之间会互斥，但读操作和读操作就不会互斥。 最后介绍了synchronized内置锁和Lock显式锁，总得来说： synchronized好用，简单，性能不差 没有使用到Lock显式锁的特性就不要使用Lock锁了。 参考Java锁机制了解一下","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"HTTPS协议","slug":"HTTPS协议","date":"2018-05-05T02:06:57.000Z","updated":"2021-05-09T10:48:29.715Z","comments":true,"path":"HTTPS协议/","link":"","permalink":"https://mx-go.github.io/HTTPS%E5%8D%8F%E8%AE%AE/","excerpt":"引言HTTP和HTTPS协议是互联网上应用最为广泛的网络协议，现在为了安全，很多网站从HTTP的阵营转向HTTPS。近两年，Google、Baidu、Facebook 等这样的互联网巨头，不谋而合地开始大力推行 HTTPS， 国内外的大型互联网公司很多也都已经启用了全站 HTTPS，这也是未来互联网发展的趋势。","text":"引言HTTP和HTTPS协议是互联网上应用最为广泛的网络协议，现在为了安全，很多网站从HTTP的阵营转向HTTPS。近两年，Google、Baidu、Facebook 等这样的互联网巨头，不谋而合地开始大力推行 HTTPS， 国内外的大型互联网公司很多也都已经启用了全站 HTTPS，这也是未来互联网发展的趋势。 TCP协议TCP协议的三次握手与四次挥手先来一张网络模型图（应表会传网数物），可以看到TCP、UDP协议处于传输层。 建立TCP需要三次握手才能建立，而断开连接连接则需要四次挥手。整个过程如下图： 三次握手建立连接 1、Client端发送连接请求报文。 2、Server端接受连接后回复ACK报文，并为这次连接分配资源。 3、Client端接收到ACK报文后也向Server段发送报文，并分配资源 这就是TCP的三次握手建立连接阶段。 四次挥手断开连接 中断连接端可以是Client端，也可以是Server端。 1、假设Client端发起中断请求，也就是发送FIN报文。 2、Server端接到FIN报文后，告诉Client端，“你的请求我收到了，但是我还没准备好，请继续你等我的消息”。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。 3、当Server端确定数据已发送完成，则向Client端发送FIN报文。告诉Client端，”好了，我这边数据发完了，准备好关闭连接了”。 4、Client端收到FIN报文后，就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。Server端收到ACK后，就知道可以断开连接了。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那Client端也可以关闭连接了。 这就是TCP四次挥手断开连接。 问题一、为什么连接的时候是三次握手，关闭的时候却是四次握手？ 答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，”你发的FIN报文我收到了”。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。 二、为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间Maximum Segment Lifetime)才能返回到CLOSE状态？ 答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。 HTTPS协议HTTPS（Hypertext Transfer Protocol over Secure Socket Layer，基于SSL的HTTP协议）使用了HTTP协议，但HTTPS使用不同于HTTP协议的默认端口及一个加密、身份验证层（HTTP与TCP之间）。HTTPS是一个安全通信通道，用于在客户计算机和服务器之间交换信息。它使用安全套接字层(SSL)进行信息交换，简单来说它是HTTP的安全版。 内容加密：建立一个信息安全通道，来保证数据传输的安全； 身份认证：确认网站的真实性； 数据完整性：防止内容被第三方冒充或者篡改； 加密算法对称加密有流式、分组两种。加密和解密都是使用的同一个密钥。 例如：DES、AES-GCM、ChaCha20-Poly1305等。 非对称加密加密使用的密钥和解密使用的密钥是不相同的，分别称为：公钥、私钥，公钥的算法是公开的，私钥是保密的。非对称加密算法性能较低，但是安全性超强，由于其加密特性，非对称加密算法能加密的数据长度也是有限的。 例如：RSA、DSA、ECDSA、 DH、ECDHE。 哈希算法将任意长度的信息转换为较短的固定长度的值，通常其长度要比信息小得多，且算法不可逆。 例如：MD5、SHA-1、SHA-2、SHA-256 等 数字签名签名就是在信息的后面再加上一段内容（信息经过hash后的值），可以证明信息没有被修改过。hash值一般都会加密后（也就是签名）再和信息一起发送，以保证这个hash值不被修改。 请求过程HTTPS其实是有两部分组成：HTTP + SSL/TLS，也就是在HTTP上又加了一层处理加密信息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密后的数据。 客户端发起HTTPS请求用户在浏览器里输入一个https网址，连接到server的443端口。 服务端配置采用HTTPS协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面。这套证书其实就是一对公钥和私钥。如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。 传送证书这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。 客户端解析证书这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值。然后用证书对该随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。 传送加密信息这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。 服务端解密信息服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密。所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。 传输加密后的信息这部分信息是服务段用私钥加密后的信息，可以在客户端被还原。 客户端解密信息客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。 总结HTTPS请求连接的全过程可简化理解为：客户端拿到服务端非对称加密的公钥验证其身份后，将对称加密的私钥通过非对称加密的公钥加密后传输给服务端，服务端通过非对称加密的私钥解密后得到对称加密的私钥，其后客户端和服务端通过对称加密的私钥对数据进行加密传输。 相比 HTTP 协议，HTTPS 协议增加了很多握手、加密解密等流程，虽然过程很复杂，但其可以保证数据传输的安全。然而，加密和解密过程需要耗费系统大量的开销，严重降低机器的性能，相关测试数据表明使用HTTPS协议传输数据的工作效率只有使用HTTP协议传输的十分之一。所谓鱼与熊掌不可兼得，适当的选择HTTP和HTTPS协议非常重要。","categories":[{"name":"方法论","slug":"方法论","permalink":"https://mx-go.github.io/categories/%E6%96%B9%E6%B3%95%E8%AE%BA/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Spring下MySQL读写分离","slug":"Spring下MySQL读写分离","date":"2018-05-02T07:46:51.000Z","updated":"2021-05-05T03:30:23.275Z","comments":true,"path":"Spring下MySQL读写分离/","link":"","permalink":"https://mx-go.github.io/Spring%E4%B8%8BMySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/","excerpt":"引言之前的文章已经说明MySQL主从/主主同步环境的搭建，接下来就是要实现在业务代码里面实现读写分离。在当前流行的SSM的框架开发的web项目下，数据库模式为主从同步的环境下编写业务代码。","text":"引言之前的文章已经说明MySQL主从/主主同步环境的搭建，接下来就是要实现在业务代码里面实现读写分离。在当前流行的SSM的框架开发的web项目下，数据库模式为主从同步的环境下编写业务代码。 编写jdbc.propreties在这里指定了两个数据库，主从数据库都在本地，只是端口不一致。 1234567891011121314#数据库连接池的配置jdbc.pool.init=1jdbc.pool.minIdle=3jdbc.pool.maxActive=20#mysql驱动jdbc.driver=com.mysql.jdbc.Driver#主数据库地址jdbc.master.url=jdbc:mysql://127.0.0.1:3306/test?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true#从数据库地址jdbc.slave.url=jdbc:mysql://127.0.0.1:3308/test?useUnicode=true&amp;characterEncoding=utf-8&amp;autoReconnect=true#数据库账号、密码jdbc.username=mysqluserjdbc.password=mysqlpassword 注意： 在此之前，项目中一般会使用一个数据库用户远程操作数据库（避免直接使用root用户），因此需要在主从数据库里面都创建一个用户mysqluser，赋予其增删改查的权限： 1GRANT select,insert,update,delete ON *.* TO &#x27;mysqluser&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;mysqlpassword&#x27; WITH GRANT OPTION; 配置数据源在spring-dao.xml中配置数据源，部分配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192 &lt;!-- 1.配置数据库相关参数properties的属性：$&#123;url&#125; --&gt; &lt;context:property-placeholder ignore-unresolvable=&quot;true&quot; location=&quot;classpath:jdbc.properties&quot; /&gt;&lt;!-- 数据源配置, 使用 Druid 数据库连接池 --&gt; &lt;bean id=&quot;dataSourceMaster&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;!-- 数据源驱动类可不写，Druid默认会自动根据URL识别DriverClass --&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driver&#125;&quot; /&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.master.url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;!-- 配置初始化大小、最小、最大连接池 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;jdbc.pool.init&#125;&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;jdbc.pool.minIdle&#125;&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;$&#123;jdbc.pool.maxActive&#125;&quot; /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;300000&quot; /&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;$&#123;jdbc.testSql&#125;&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;false&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot; /&gt; &lt;!-- 打开removeAbandoned功能 --&gt; &lt;property name=&quot;removeAbandoned&quot; value=&quot;true&quot; /&gt; &lt;!-- 1800秒，也就是30分钟 --&gt; &lt;property name=&quot;removeAbandonedTimeout&quot; value=&quot;1800&quot; /&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; &lt;property name=&quot;connectionProperties&quot; value=&quot;druid.stat.slowSqlMillis=5000&quot; /&gt; &lt;/bean&gt; &lt;!-- 数据源配置, 使用 Druid 数据库连接池 --&gt; &lt;bean id=&quot;dataSourceSlave&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; init-method=&quot;init&quot; destroy-method=&quot;close&quot;&gt; &lt;!-- 数据源驱动类可不写，Druid默认会自动根据URL识别DriverClass --&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;jdbc.driver&#125;&quot; /&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;jdbc.slave.url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;jdbc.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot; /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name=&quot;initialSize&quot; value=&quot;$&#123;jdbc.pool.init&#125;&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;$&#123;jdbc.pool.minIdle&#125;&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;$&#123;jdbc.pool.maxActive&#125;&quot; /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name=&quot;maxWait&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;60000&quot; /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;300000&quot; /&gt; &lt;property name=&quot;validationQuery&quot; value=&quot;$&#123;jdbc.testSql&#125;&quot; /&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;false&quot; /&gt; &lt;property name=&quot;testOnReturn&quot; value=&quot;false&quot; /&gt; &lt;!-- 打开removeAbandoned功能 --&gt; &lt;property name=&quot;removeAbandoned&quot; value=&quot;true&quot; /&gt; &lt;!-- 1800秒，也就是30分钟 --&gt; &lt;property name=&quot;removeAbandonedTimeout&quot; value=&quot;1800&quot; /&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name=&quot;filters&quot; value=&quot;stat&quot; /&gt; &lt;property name=&quot;connectionProperties&quot; value=&quot;druid.stat.slowSqlMillis=5000&quot; /&gt; &lt;/bean&gt; &lt;!--配置动态数据源，这里的targetDataSource就是路由数据源所对应的名称--&gt; &lt;bean id=&quot;dataSourceSelector&quot; class=&quot;com.rainbowhorse.common.dynamicDataSource.DataSourceSelector&quot;&gt; &lt;property name=&quot;targetDataSources&quot;&gt; &lt;map&gt; &lt;entry value-ref=&quot;dataSourceMaster&quot; key=&quot;master&quot;&gt;&lt;/entry&gt; &lt;entry value-ref=&quot;dataSourceSlave&quot; key=&quot;slave&quot;&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--配置数据源懒加载--&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.LazyConnectionDataSourceProxy&quot;&gt; &lt;property name=&quot;targetDataSource&quot;&gt; &lt;ref bean=&quot;dataSourceSelector&quot;&gt;&lt;/ref&gt; &lt;/property&gt; &lt;/bean&gt; 说明：首先读取配置文件jdbc.properties，然后配置了两个具体的数据源dataSourceMaster、dataSourceSlave。里面配置了数据库连接的具体属性，然后配置了动态数据源，他将决定使用哪个具体的数据源，这里面的关键就是DataSourceSelector，接下来会实现这个bean。下一步设置了数据源的懒加载，保证在数据源加载的时候其他依赖的bean已经加载好了。接着就是常规的配置了，mybatis全局配置文件如下。 mybatis全局配置文件1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;!-- 全局参数 --&gt; &lt;settings&gt; &lt;!-- 使全局的映射器启用或禁用缓存。 --&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 全局启用或禁用延迟加载。当禁用时，所有关联对象都会即时加载。 --&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 当启用时，有延迟加载属性的对象在被调用时将会完全加载任意属性。否则，每种属性将会按需要加载。 --&gt; &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;true&quot;/&gt; &lt;!-- 是否允许单条sql 返回多个数据集 (取决于驱动的兼容性) default:true --&gt; &lt;setting name=&quot;multipleResultSetsEnabled&quot; value=&quot;true&quot;/&gt; &lt;!-- 是否可以使用列的别名 (取决于驱动的兼容性) default:true --&gt; &lt;setting name=&quot;useColumnLabel&quot; value=&quot;true&quot;/&gt; &lt;!-- 允许JDBC 生成主键。需要驱动器支持。如果设为了true，这个设置将强制使用被生成的主键，有一些驱动器不兼容不过仍然可以执行。 default:false --&gt; &lt;setting name=&quot;useGeneratedKeys&quot; value=&quot;false&quot;/&gt; &lt;!-- 指定 MyBatis 如何自动映射 数据基表的列 NONE：不隐射 PARTIAL:部分 FULL:全部 --&gt; &lt;setting name=&quot;autoMappingBehavior&quot; value=&quot;PARTIAL&quot;/&gt; &lt;!-- 这是默认的执行类型 （SIMPLE: 简单； REUSE: 执行器可能重复使用prepared statements语句；BATCH: 执行器可以重复执行语句和批量更新） --&gt; &lt;setting name=&quot;defaultExecutorType&quot; value=&quot;SIMPLE&quot;/&gt; &lt;!-- 使用驼峰命名法转换字段。 --&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt; &lt;!-- 设置本地缓存范围 session:就会有数据的共享 statement:语句范围 (这样就不会有数据的共享 ) defalut:session --&gt; &lt;setting name=&quot;localCacheScope&quot; value=&quot;SESSION&quot;/&gt; &lt;!-- 设置但JDBC类型为空时,某些驱动程序 要指定值,default:OTHER，插入空值时不需要指定类型 --&gt; &lt;setting name=&quot;jdbcTypeForNull&quot; value=&quot;NULL&quot;/&gt; &lt;/settings&gt; &lt;!-- 插件配置 --&gt; &lt;plugins&gt; &lt;plugin interceptor=&quot;com.raninbowhorse.common.dynamicDataSource.DateSourceSelectInterceptor&quot; /&gt; &lt;/plugins&gt; &lt;/configuration&gt; 这里面的关键就是DateSourceSelectInterceptor这个拦截器，它会拦截所有的数据库操作，然后分析sql语句判断是“读”操作还是“写”操作，接下来就来实现上述的DataSourceSelector和DateSourceSelectInterceptor。 编写DataSourceSelectorDataSourceSelector就是在spring-dao.xml配置的，用于动态配置数据源。代码如下： 123456789101112/** * 继承了AbstractRoutingDataSource，动态选择数据源 * ClassName: DataSourceSelector * @Description: TODO * @author rainbowhorse */public class DataSourceSelector extends AbstractRoutingDataSource &#123; @Override protected Object determineCurrentLookupKey() &#123; return DynamicDataSourceHolder.getDataSourceType(); &#125;&#125; 只要继承AbstractRoutingDataSource并且重写determineCurrentLookupKey()方法就可以动态配置数据源。 编写DynamicDataSourceHolder123456789101112131415161718192021222324252627282930313233343536373839404142/** * 配置数据源 * ClassName: DynamicDataSourceHolder * @Description: TODO * @author rainbowhorse */public class DynamicDataSourceHolder &#123; /** 用来存取key，ThreadLocal保证了线程安全 */ private static ThreadLocal&lt;String&gt; CONTEXTHOLDER = new ThreadLocal&lt;String&gt;(); /** 主库 */ public static final String DB_MASTER = &quot;master&quot;; /** 从库 */ public static final String DB_SLAVE = &quot;slave&quot;; /** * 获取线程的数据源 * @return */ public static String getDataSourceType() &#123; String db = CONTEXTHOLDER.get(); if (db == null) &#123; // 如果db为空则默认使用主库（因为主库支持读和写） db = DB_MASTER; &#125; return db; &#125; /** * 设置线程的数据源 * @param s */ public static void setDataSourceType(String s) &#123; CONTEXTHOLDER.set(s); &#125; /** * 清理连接类型 */ public static void clearDataSource() &#123; CONTEXTHOLDER.remove(); &#125;&#125; 这个类决定返回的数据源是master还是slave，这个类的初始化需要借助DateSourceSelectInterceptor，拦截所有的数据库操作请求，通过分析SQL语句来判断是读还是写操作，读操作就给DynamicDataSourceHolder设置slave源，写操作就给其设置master源。 编写DateSourceSelectInterceptor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * 拦截数据库操作，根据sql判断是读还是写，选择不同的数据源 * ClassName: DateSourceSelectInterceptor * @Description: TODO * @author rainbowhorse */@Intercepts(&#123; @Signature(type = Executor.class, method = &quot;update&quot;, args = &#123; MappedStatement.class, Object.class &#125;), @Signature(type = Executor.class, method = &quot;query&quot;, args = &#123; MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class &#125;) &#125;)public class DateSourceSelectInterceptor implements Interceptor &#123; /** 正则匹配 insert、delete、update操作 */ private static final String REGEX = &quot;.*insert\\\\\\\\u0020.*|.*delete\\\\\\\\u0020.*|.*update\\\\\\\\u0020.*&quot;; @Override public Object intercept(Invocation invocation) throws Throwable &#123; // 判断当前操作是否有事务 boolean synchonizationActive = TransactionSynchronizationManager.isSynchronizationActive(); // 当前事务的readOnly状态 boolean readOnly = TransactionSynchronizationManager.isCurrentTransactionReadOnly(); // 获取执行参数 Object[] objects = invocation.getArgs(); MappedStatement ms = (MappedStatement) objects[0]; // 默认设置使用主库 String lookupKey = DynamicDataSourceHolder.DB_MASTER; // 有事务且为readOnly=true状态 if (readOnly &amp;&amp; synchonizationActive) &#123; // 读方法 if (ms.getSqlCommandType().equals(SqlCommandType.SELECT)) &#123; // selectKey为自增主键（SELECT LAST_INSERT_ID()）方法,使用主库 if (ms.getId().contains(SelectKeyGenerator.SELECT_KEY_SUFFIX)) &#123; lookupKey = DynamicDataSourceHolder.DB_MASTER; &#125; else &#123; BoundSql boundSql = ms.getSqlSource().getBoundSql(objects[1]); String sql = boundSql.getSql().toLowerCase(Locale.CHINA).replace(&quot;[\\\\t\\\\n\\\\r]&quot;, &quot; &quot;); // 如果是insert、delete、update操作 使用主库 if (sql.matches(REGEX)) &#123; lookupKey = DynamicDataSourceHolder.DB_MASTER; &#125; else &#123; // 使用从库 lookupKey = DynamicDataSourceHolder.DB_SLAVE; &#125; &#125; &#125; &#125; else &#123; // 一般使用事务的都是写操作，直接使用主库 lookupKey = DynamicDataSourceHolder.DB_MASTER; &#125; System.out.println(&quot;-----------------&quot; + readOnly + &quot;--------------------&quot;); // 设置数据源 DynamicDataSourceHolder.setDataSourceType(lookupKey); return invocation.proceed(); &#125; @Override public Object plugin(Object target) &#123; if (target instanceof Executor) &#123; // 如果是Executor（执行增删改查操作），则拦截下来 return Plugin.wrap(target, this); &#125; else &#123; return target; &#125; &#125; @Override public void setProperties(Properties properties) &#123; &#125;&#125; 通过这个拦截器，所有的insert、delete、update操作设置使用master源，select会使用slave源。 最后所有代码都已编写完毕，接下来就是测试了，通过打印的日志可判断是否正确。 配置多个slave用于负载均衡时，只需要在spring-dao.xml中添加slave1、slave2、slave3……然后修改dataSourceSelector这个bean，在map标签中添加slave1、slave2、slave3……即可，具体的负载均衡策略在DynamicDataSourceHolder、DateSourceSelectInterceptor中实现即可。 12345678910&lt;bean id=&quot;dataSourceSelector&quot; class=&quot;com.rainbowhorse.common.dynamicDataSource.DataSourceSelector&quot;&gt; &lt;property name=&quot;targetDataSources&quot;&gt; &lt;map&gt; &lt;entry value-ref=&quot;master&quot; key=&quot;master&quot;&gt;&lt;/entry&gt; &lt;entry value-ref=&quot;slave1&quot; key=&quot;slave1&quot;&gt;&lt;/entry&gt; &lt;entry value-ref=&quot;slave2&quot; key=&quot;slave2&quot;&gt;&lt;/entry&gt; &lt;entry value-ref=&quot;slave3&quot; key=&quot;slave3&quot;&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt; 梳理一下整个流程： 1、项目启动后，在依赖的bean加载完成后，数据源通过LazyConnectionDataSourceProxy开始加载，会引用dataSourceSelector加载数据源。 2、DataSourceSelector会选择一个数据源，代码里设置了默认数据源为master，在初始化的时候就默认使用master源。 3、在数据库操作执行时，DateSourceSelectInterceptor拦截器拦截了请求，通过分析SQL决定使用哪个数据源。“读操作”使用slave源，“写操作”使用master源。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"MySQL执行计划","slug":"MySQL执行计划","date":"2018-04-27T01:24:06.000Z","updated":"2021-05-09T10:49:27.967Z","comments":true,"path":"MySQL执行计划/","link":"","permalink":"https://mx-go.github.io/MySQL%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/","excerpt":"","text":"引言MySQL执行计划，简单的来说，是SQL在数据库中执行时的表现情况，通常用于SQL性能分析，优化等场景。在MySQL使用 explain 关键字来查看SQL的执行计划。 适用场景适用于 select、update、insert、replace、delete语句，在需要分析的语句前加EXPLAIN，即可。 EXPLAIN可得到的信息 SQL如何使用索引 关联查询的执行顺序 查询扫描的数据行数 读懂执行计划例如以下关联查询： 1EXPLAIN SELECT * FROM tb_item JOIN tb_item_desc ON tb_item.id=tb_item_desc.item_id WHERE id=&#x27;679533&#x27;; 根据上图可得到执行计划的列信息，下面分析一下每列所表示的信息。 ## ID ID列中的数据为一组数字，表示执行Select语句的顺序。 ID值相同时，执行顺序由上至下。 ID值越大优先级越高，越先被执行。 SELECT_TYPE表示查询中每个Select子句的类型（简单 OR 复杂）。 SIMPLE：不包含子查询或是UNION操作的查询。 PRIMARY：查询中如果包含任何子查询，那么最外层的查询则被标记为PRIMARY。 SUBQUERY：SELECT 列表中的子查询。 DEPENDENT SUBQUERY：被别的查询所依赖的子查询。 UNION：union操作的第二个或是之后的查询的值为union。 DEPENDENT UNION：当union作为子查询时，第二或者是第二个后的查询的值。 UNION RESULT：union产生的结果集。 DERIVED：出现在from子句中的子查询。 TABLE输出数据行所在的表的名称或别名。 **&lt;unionM,N&gt;*：由ID为M,N查询union*产生的结果集。 **&lt;derivedN&gt;/&lt;subqueryN&gt;**：由ID为N的查询产生的结果。 PARTITIONS 对于分区表，显示查询的分区ID。 对于非分区表，显示为NULL。 TYPE（类型性能是依次降低）该属性表示访问类型,有很多种访问类型。 system：这是const连接类型的一个特例，当查询的表只有一行时使用。 const：表中有且只有一个匹配的行时使用，如对主键或是唯一索引的查询，这是效率最高的联接方式。 eq_ref：唯一索引或者是主键索引查找，对于每个索引键，表中只有一条记录与之匹配 ref：非唯一索引查找，返回匹配某个单独值的所有行。 ref_or_null：类似于ref类型的查询，但是附加了对NULL值列的查询。 index_merge：该联接类型表示使用了索引合并优化方法。 range：索引范围扫描，常见于between、&gt;、&lt;、这样的查询条件。 index：full index scan 全索引扫描，同ALL的区别是，遍历的是索引树。 all：full table scan 全表扫描，这是效率最差的联接方式。 POSSIBLE_KEYS指出MySQL能使用那些索引来优化查询，查询列所涉及到的列上的索引都会被列出，但不一定会被使用。 KEY显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL。 TIPS：查询中若使用了覆盖索引，则该索引仅出现在key列表中。 KEY_LEN 表示索引字段的最大可能长度。 此值的长度有字段定义计算而来，并非数据的实际长度。 REF表示表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。 ROWS表示MySQL通过索引统计的信息，估算出的所需读取的行数。是一个不十分准确的值。 FILTERED表示返回结果的行数占需读取行数的百分比，越大越好，也并不十分准确。 EXTRA1、Using index 该值表示相应的Select操作中使用了***覆盖索引(Covering Index)***。 TIPS：覆盖索引（Covering Index） MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件包含所有满足查询需要的数据的索引称为 覆盖索引（Covering Index） 注意：如果要使用覆盖索引，一定要注意Select列表中只取出需要的列，不可Select *，因为如果将所有字段一起做索引会导致索引文件过大，查询性能下降。 2、Using where 表示MySQL服务器在存储引擎受到记录后进行“后过滤”（Post-filter），如果查询未能使用索引，Using where的作用只是提醒我们MySQL将用where子句来过滤结果集。 3、Using temporary 表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询。 4、Using filesort MySQL中无法利用索引完成的排序操作称为“文件排序”。 5、distinct 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。 6、not exists 使用not exists来优化查询。 7、select tables optimized away 直接通过索引来获得数据，不用访问表。 执行计划的局限性 EXPLAIN无法展示关于触发器、存储过程的信息或用户自定义函数对查询的影响情况。 EXPLAIN不考虑各种Cache。 EXPLAIN不能显示MySQL在执行查询时所作的优化工作。 部分统计信息是估算的，并非精确值。 早期版本的MySQL只支持对Select语句进行分析。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"MySQL主从/主主复制","slug":"MySQL主从复制","date":"2018-04-17T05:43:00.000Z","updated":"2021-05-09T10:50:45.177Z","comments":true,"path":"MySQL主从复制/","link":"","permalink":"https://mx-go.github.io/MySQL%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","excerpt":"","text":"引言MySQL作为世界上最广泛的数据库之一，免费是原因之一，其本身功能的强大也是获得众多用的青睐的重要原因。在实际的生产环境中，单机版MySQL数据库就不能满足实际的需求了，此时数据库集群就很好的解决了这个问题了。采用MySQL分布式集群，能够搭建一个高并发、负载均衡的集群服务器。在此之前必须要保证每台MySQL服务器里的数据同步。数据同步可以通过MySQL内部配置就可以轻松完成，主要有主从复制和主主复制。 在本案例下使用同一台机器安装两个数据库，只是端口不一致，一个为3306，一个为3308。 复制原理 Master将数据改变记录到二进制日志(binary log)中，也就是配置文件log-bin指定的文件，这些记录叫做二进制日志事件(binary log events) 。 Slave通过I/O线程读取Master中的binary log events并写入到它的中继日志(relay log) 。 Slave重做中继日志中的事件，把中继日志中的事件信息一条一条的在本地执行一次，完成数据在本地的存储，从而实现将改变反映到它自己的数据(数据重放)。 复制类型 1、基于语句的复制(statement) 在Master上执行的SQL语句，在Slave上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高。 根据上图可得到执行计划的列信息，下面分析一下每列所表示的信息。 把改变的内容复制到Slave，而不是把命令在Slave上执行一遍。从MySQL5.0开始支持。 3、混合类型的复制(mixed) 默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。 要求 文件${mysql}/data/auto.cnf里server-uuid不能重复。 主从服务器操作系统版本和位数一致。 Master和Slave数据库的版本要一致。 Master和Slave数据库中的数据要一致。 Master开启二进制日志，Master和Slave的server_id在局域网内必须唯一。 主从复制主从复制能保证主SQL（Master）和从SQL（Slave）的数据是一致性的，向Master插入数据后，Slave会自动从Master把修改的数据同步过来（有一定的延迟），通过这种方式来保证数据的一致性，主从复制**基于日志(binlog)**。 主从复制可解决： 高可用 因为数据都是相同的，所以当Master挂掉后，可以指定一台Slave充当Master继续保证服务运行，因为数据是一致性的（如果当插入Master就挂掉，可能不一致，因为同步也需要时间）。 负载均衡 因为读写分离也算是负载均衡的一种，一般都是有多台Slave的，所以可以将读操作指定到Slave服务器上（需要代码控制），然后再用负载均衡来选择那台Slave来提供服务，同时也可以吧一些大量计算的查询指定到某台Slave，这样就不会影响Master的写入以及其他查询。 数据备份 一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全。 业务模块化 可以一个业务模块读取一个Slave，再针对不同的业务场景进行数据库的索引创建和根据业务选择MySQL存储引擎。 配置Master配置my.cnfLinux下MySQL配置文件为my.cnf，windows下为my.ini。在Master添加以下配置： 12345678910111213141516[mysqld]## 设置server_id，一般设置为IP,注意要唯一server_id=1## 复制过滤：也就是指定哪个数据库不用同步（mysql库一般不同步）binlog-ignore-db=mysql## 开启二进制日志功能，可以随便取，最好有含义（关键就是这里了）log-bin=mysql-bin## 为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存binlog_cache_size=1M## 主从复制的格式（mixed,statement,row，默认格式是statement）binlog_format=mixed## 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。expire_logs_days=7## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致slave_skip_errors=1062 配置完成后重启MySQL。 创建数据同步用户1234-- -- 用户名：slave，密码：slaveCREATE USER &#x27;slave&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;slave&#x27;;-- 授予用户REPLICATION SLAVE权限和REPLICATION CLIENT权限GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#x27;slave&#x27;@&#x27;%&#x27;; 配置SlaveLinux下MySQL配置文件为my.cnf，windows下为my.ini。在Slave添加以下配置： 12345678910111213141516171819202122[mysqld]## 设置server_id，一般设置为IP,注意要唯一server_id ## 复制过滤：也就是指定哪个数据库不用同步（mysql库一般不同步）binlog-ignore-db=mysql## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用log-bin=mysql-slave1-bin## 为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存binlog_cache_size=1M## 主从复制的格式（mixed,statement,row，默认格式是statement）binlog_format=mixed## 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。expire_logs_days=7## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致slave_skip_errors=1062## relay_log配置中继日志relay_log=mysql-relay-bin ## log_slave_updates表示slave将复制事件写进自己的二进制日志log_slave_updates=1## 防止改变数据(除了特殊的线程)read_only=1 如果Slave为其它Slave的Master时，必须设置bin_log。配置完成后重启MySQL。 连接Master和Slave查询Master状态在master中执行 1SHOW MASTER STATUS; 记录下返回结果的File列和Position列的值。 在Slave中设置Master信息在slave中执行 12345678CHANGE MASTER TO MASTER_HOST=&#x27;127.0.0.1&#x27;, MASTER_USER=&#x27;slave&#x27;, MASTER_PASSWORD=&#x27;slave&#x27;, MASTER_PORT=3306, MASTER_LOG_FILE=&#x27;mysql-bin.000014&#x27;, MASTER_LOG_POS=1122, MASTER_CONNECT_RETRY=30;-- master_host=&#x27;127.0.0.1&#x27; ## Master的IP地址-- master_user=&#x27;slave&#x27; ## 用于同步数据的用户（在Master中授权的用户）-- master_password=&#x27;slave&#x27; ## 同步数据用户的密码-- master_port=3306 ## Master数据库服务的端口-- master_log_file=&#x27;mysql-bin.000014&#x27; ##指定Slave从哪个日志文件开始读复制数据（Master上执行命令的结果的File字段）-- master_log_pos=1122 ## 从哪个POSITION号开始读（Master上执行命令的结果的Position字段）-- masterconnectretry=30 ##当重新建立主从连接时，如果连接建立失败，间隔多久后重试。单位为秒，默认设置为60秒，同步延迟调优参数。 查看主从同步状态1SHOW SLAVE STATUS; 可看到Slave_IO_State为空， Slave_IO_Running和Slave_SQL_Running是No，表明Slave还没有开始复制过程。相反Slave_IO_Running和Slave_SQL_Running是Yes表明已经开始工作了。 开启/关闭主从在slave中执行 1234-- 停止主从STOP SLAVE;-- 开启主从START SLAVE; 查询查看主从同步状态，会发现Slave_IO_Running和Slave_SQL_Running是Yes了，表明开启成功。 主主复制主主复制即在两台MySQL主机内都可以变更数据，而且另外一台主机也会做出相应的变更。其实现就是将两个主从复制有机合并起来就好了。只不过在配置的时候我们需要注意一些问题，例如，主键重复，server-id不能重复等等。 配置Master接上一案例，在上一案例中的Slave中执行 1234-- 用户名：slave1，密码：slave1GRANT REPLICATION SLAVE ON *.* TO &#x27;slave1&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;slave1&#x27;;FLUSH PRIVILEGES;SHOW MASTER STATUS; 同样记录下返回结果的File列和Position列的值。 配置Slave在上一案例中的Master中执行 1CHANGE MASTER TO MASTER_HOST=&#x27;127.0.0.1&#x27;, MASTER_USER=&#x27;slave1&#x27;, MASTER_PASSWORD=&#x27;slave1&#x27;, MASTER_PORT=3308, MASTER_LOG_FILE=&#x27;mysql-bin.000017&#x27;, MASTER_LOG_POS=1860, MASTER_CONNECT_RETRY=30; 分别开启 START SLAVE; 当且仅当两个数据库Slave_IO_Running和Slave_SQL_Running都为 YES才表明状态正常。 注意 主主复制只能保证主键不重复，却不能保证主键有序。 当配置完成Slave_IO_Running、Slave_SQL_Running不全为YES时，show slave status\\G信息中有错误提示，可根据错误提示进行更正。 Slave_IO_Running、Slave_SQL_Running不全为YES时，大多数问题都是数据不统一导致。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"Redis数据过期策略","slug":"Redis数据过期策略","date":"2018-04-09T08:18:12.000Z","updated":"2021-05-09T10:52:09.205Z","comments":true,"path":"Redis数据过期策略/","link":"","permalink":"https://mx-go.github.io/Redis%E6%95%B0%E6%8D%AE%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5/","excerpt":"","text":"引言Redis作为一个高性能的内存NoSQL数据库，其容量受到最大内存限制的限制。为了防止一次性清理大量过期Key导致Redis服务受影响，Redis只在空闲时清理过期Key。 Redis过期时间设置过期时间redis有四种命令可以用于设置键的生存时间和过期时间： 1234EXPIRE &lt;KEY&gt; &lt;TTL&gt; : 将键的生存时间设为 ttl 秒PEXPIRE &lt;KEY&gt; &lt;TTL&gt; : 将键的生存时间设为 ttl 毫秒EXPIREAT &lt;KEY&gt; &lt;timestamp&gt; : 将键的过期时间设为 timestamp 所指定的秒数时间戳PEXPIREAT &lt;KEY&gt; &lt;timestamp&gt;: 将键的过期时间设为 timestamp 所指定的毫秒数时间戳. 返回值 一个整数值1或0，如下： 如果成功地为该键设置了超时时间，返回 1 如果键不存在或无法设置超时时间，返回 0 保存过期时间redis中key的过期时间和生存时间保存方式：在数据库结构redisDb中的expires字典中保存了数据库中所有键的过期时间，称expire这个字典为过期字典。（1）过期字典是一个指针，指向键空间的某个键对象。（2）过期字典的值是一个longlong类型的整数，这个整数保存了键所指向的数据库键的过期时间–一个毫秒级的 UNIX 时间戳。 下图是一个带过期字典的数据库例子： 从以上结构中可以看到expire字典(过期字典)和dict字典（数据库键空间，保存着数据库中所有键值对）是并列的，由此可见expire字典的重要性。 移除过期时间PERSIST命令可以移除一个键的过期时间： 12345678910127.0.0.1:6379&gt; set message &quot;hello&quot;OK127.0.0.1:6379&gt; expire message 60(integer) 1127.0.0.1:6379&gt; ttl message(integer) 54127.0.0.1:6379&gt; persist message(integer) 1127.0.0.1:6379&gt; ttl message(integer) -1 persist命令就是expire命令的反命令，这个函数在过期字典中查找给定的键,并从过期字典中移除。比如在数据库当前状态(如上图所示)，当给book这个key移除过期时间： 12redis&gt; persist book(integer) 1 数据库将更新成如下状态： 可以从图中看到,当PERSIST book命令执行之后,过期字典中的 book 键消失了。 计算并返回剩余生存时间ttl命令以秒为单位返回指定键的剩余生存时间。pttl以毫秒返回。两个命令都是通过计算当前时间和过期时间的差值得到剩余生存期的。 1234567891011127.0.0.1:6379&gt; set name rainbowhorseOK127.0.0.1:6379&gt; expire name 60(integer) 1127.0.0.1:6379&gt; ttl name(integer) 57127.0.0.1:6379&gt; ttl name(integer) 27127.0.0.1:6379&gt; pttl name(integer) 23839127.0.0.1:6379&gt; 过期键的删除策略如果一个键是过期的，它的怎么从内存中消失的，是什么时候被删除的？ redis有三种不同的删除策略： 定时删除。每隔一段时间，对expires字典进行检查，删除里面的过期键。 立即删除。在设置键的过期时间时，创建一个回调事件，当过期时间达到时，由时间处理器自动执行键的删除操作。 惰性删除。键过期了就过期了，不管。每次从dict字典中按key取值时，先检查此key是否已经过期，如果过期了就删除它，并返回nil，如果没过期，就返回键值。 由此可见，第二种为被动删除，第一种和第三种为主动删除，且第一种实时性更高。下面对这三种删除策略进行具体分析。 定时删除 含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除 优点：保证内存被尽快释放 缺点： 若过期key很多，删除这些key会占用很多的CPU时间，在CPU时间紧张的情况下，CPU不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些key 定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重 没人用 定期删除 含义：每隔一段时间执行一次删除(在redis.conf配置文件设置hz，1s刷新的频率)过期key操作 优点： 通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用–处理”定时删除”的缺点 定期删除过期key–处理”惰性删除”的缺点 缺点 在内存友好方面，不如”定时删除” 在CPU时间友好方面，不如”惰性删除” 难点 合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了） 定期删除可以通过： 第一、配置redis.conf 的hz选项，默认为10 （即1秒执行10次，100ms一次，值越大说明刷新频率越快，最Redis性能损耗也越大） 第二、配置redis.conf的maxmemory最大值，当已用内存超过maxmemory限定时，就会触发主动清理策略 惰性删除 含义：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null。 优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了） 缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存） 定时删除和定期删除为主动删除：Redis会定期主动淘汰一批已过去的key。 惰性删除为被动删除：用到的时候才会去检验key是不是已过期，过期就删除。 redis使用的策略redis使用的过期键值删除策略是：惰性删除加上定期删除，两者配合使用。 最佳实践 不要放垃圾数据，及时清理无用数据。实验性的数据和下线的业务数据及时删除。 key尽量都设置过期时间。对具有时效性的key设置过期时间，通过redis自身的过期key清理策略来降低过期key对于内存的占用，同时也能够减少业务的麻烦，不需要定期手动清理了。 单Key不要过大。给用户排查问题时遇到过单个string的value有43M的，也有一个list 100多万个大成员占了1G多内存的。这种key在get的时候网络传输延迟会比较大，需要分配的输出缓冲区也比较大，在定期清理的时候也容易造成比较高的延迟. 最好能通过业务拆分，数据压缩等方式避免这种过大的key的产生。 不同业务如果公用一个业务的话，最好使用不同的逻辑db分开。从上面的分析可以看出，Redis的过期Key清理策略和强制淘汰策略都会遍历各个db。将key分布在不同的db有助于过期Key的及时清理。另外不同业务使用不同db也有助于问题排查和无用数据的及时下线。 参考redis的过期时间和过期删除机制","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://mx-go.github.io/tags/redis/"}]},{"title":"Spring之动态代理","slug":"Spring之动态代理","date":"2018-04-02T01:55:03.000Z","updated":"2021-05-09T10:52:55.713Z","comments":true,"path":"Spring之动态代理/","link":"","permalink":"https://mx-go.github.io/Spring%E4%B9%8B%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"引言Spring主要有两大思想，一个是AOP，一个是IOC。对于Spring的核心AOP来说，动态代理机制是其核心，想要明白AOP原理，一定要了解动态代理机制。","text":"引言Spring主要有两大思想，一个是AOP，一个是IOC。对于Spring的核心AOP来说，动态代理机制是其核心，想要明白AOP原理，一定要了解动态代理机制。 代理模式 给某个对象提供一个代理对象，并由代理对象控制对于原对象的访问，即操作者不直接操控原对象，而是通过代理对象简介地操控原对象。 实现代理模式分为静态代理和动态代理： 静态代理：代理类是在编译时就实现好。也就是说 Java 编译完成后代理类是一个实际的 class 文件。 动态代理：动态代理类的字节码是在程序运行时由Java反射机制动态生成。也就是说 Java 编译完之后并没有实际的 class 文件，而是在运行时动态生成的类字节码，并加载到JVM中。 Spring静态代理 由程序员创建或工具生成代理类的源码，再编译代理类。所谓静态也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。 静态代理之前已经说过 Spring-AOP两种配置方式 Spring动态代理JDK动态代理(对有实现接口的对象做代理) 实现方式说明JDK动态代理中 需要了解的两个重要的类或接口 [InvocationHandler 和 Proxy] InvocationHandler接口 1234567public interface InvocationHandler &#123; // 参数说明： // Object proxy：指被代理的对象 // Method method：所要调用被代理对象的某个方法的Method对象 // Object[] args：被代理对象某个方法调用时所需要的参数 public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; &#125; 可以将InvocationHandler接口的子类想象成一个代理的最终操作类。 说明：每一个动态代理对象都必须要实现InvocationHandler这个接口，并且每个代理类（Proxy）的实例都关联到了一个handle，当我们通过代理对象调用一个方法的时候，这个方法的调用就会被转发为InvocationHandler这个接口的invoke方法来进行调用。同时在invoke的方法里，可以对被代理对象的方法调用做增强处理(如添加事务、日志、权限认证等操作)。 Proxy类 Proxy类是专门完成代理的操作类，可以通过此类为一个或多个接口动态地生成实现类，该类常用的调用方法为newProxyInstance newProxyInstance方法参数说明如下： ClassLoader loader：类加载器，定义了由哪个ClassLoader对象来对生成的代理对象进行加载 Class&lt;?&gt;[] interfaces：得到被代理类全部的接口，如果我提供了一组接口给它，那么这个代理对象就宣称实现了该接口，这样我就能调用这组接口中的方法了 InvocationHandler h：得到InvocationHandler接口的子类实例 实现实例一、首先定义了一个Subject类型的接口：Subject.java 12345678public interface Subject &#123; // 学习 void study(); // 说话 String say(String words);&#125; 二、接着定义一个接口的实现类，这个类就是我们示例中的被代理对象：RealSubject.java 1234567891011121314151617/** * 被代理类 * ClassName: RealSubject * @author rainbowhorse */public class RealSubject implements Subject &#123; @Override public void study() &#123; System.out.println(&quot;I am study now.&quot;); &#125; @Override public String say(String words) &#123; return &quot;I say &quot; + words; &#125;&#125; 三、定义一个动态代理类（必须要实现 InvocationHandler 接口）：DynamicProxy.java 123456789101112131415161718192021222324252627282930313233import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * JDK动态代理类 * ClassName: DynamicProxy * @author rainbowhorse */public class DynamicProxy implements InvocationHandler &#123; // 这个就是要代理的真实对象 private Object subject; // 构造方法，给要代理的真实对象赋初值 public DynamicProxy(Object subject) &#123; this.subject = subject; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 在代理真实对象前可以添加一些自己的操作 System.out.println(&quot;before method&quot;); System.out.println(&quot;Method:&quot; + method); // 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用 Object invoke = method.invoke(subject, args); // 在代理真实对象后也可以添加一些自己的操作 System.out.println(&quot;after method&quot;); return invoke; &#125;&#125; 四、代理测试类：Client.java 1234567891011121314151617181920212223242526272829import java.lang.reflect.InvocationHandler;import java.lang.reflect.Proxy;public class Client &#123; public static void main(String[] args) &#123; // 要代理的真实对象 Subject realSubject = new RealSubject(); // 要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法的 InvocationHandler handler = new DynamicProxy(realSubject); /* * 通过Proxy的newProxyInstance方法来动态创建我们的代理对象 * 参数一：这里使用handler这个类的ClassLoader对象来加载代理对象 * 参数二：这里为代理对象提供的接口是真实对象所实行的接口，表示我要代理的是该真实对象，这样就能调用这组接口中的方法了 * 参数三：这里将这个代理对象关联到了上方的 InvocationHandler 这个对象上 */ Subject subject = (Subject) Proxy.newProxyInstance(handler.getClass().getClassLoader(), realSubject.getClass().getInterfaces(), handler); System.out.println(subject.getClass().getName()); subject.study(); System.out.println(); String string = subject.say(&quot;Hello World.&quot;); System.out.println(string); &#125;&#125; 运行-&gt;控制台输出结果如下 CGLib动态代理[对没有实现接口的普通类做代理]说明概述 CGLib（Code Generation Library）是一个优秀的动态代理框架，它的底层使用ASM（JAVA字节码处理框架）在内存中动态的生成被代理类的子类。使用CGLib即使被代理类没有实现任何接口也可以实现动态代理功能。但是不能对final修饰的类进行代理。 原理 通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用。JDK动态代理与CGLib动态代理均是实现Spring AOP的基础。 实现实例一、定义一个没有实现接口的代理委托类：CGLibRealSubject.java 123456789101112131415/** * 没有实现接口的代理委托类 * ClassName: CGLibRealSubject * @author rainbowhorse */public class CGLibRealSubject &#123; public void study() &#123; System.out.println(&quot;I am study now.&quot;); &#125; public String say(String words) &#123; return &quot;I say &quot; + words; &#125;&#125; 二、定义一个CGLib动态代理类: CGLibDynamicProxy.java 123456789101112131415161718192021222324252627282930313233343536373839404142import java.lang.reflect.Method;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;public class CGLibDynamicProxy implements MethodInterceptor &#123; private Object target; /** * 创建代理对象 * * @param target * 被代理的对象 * @return */ public Object getProxyInstance(Object target) &#123; this.target = target; // 声明增强类实例 Enhancer enhancer = new Enhancer(); // 设置被代理类字节码，CGLIB根据字节码生成被代理类的子类 enhancer.setSuperclass(this.target.getClass()); // 设置要代理的拦截器，回调函数，即一个方法拦截 new MethodInterceptor() enhancer.setCallback(this); // 创建代理对象 实例 return enhancer.create(); &#125; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; // 在代理真实对象操作前 我们可以添加一些自己的操作 System.out.println(&quot;before method&quot;); Object object = proxy.invokeSuper(obj, args); // 在代理真实对象操作后 我们也可以添加一些自己的操作 System.out.println(&quot;after method&quot;); return object; &#125;&#125; 三、创建测试客户端类：CGLibClient.java 1234567891011121314151617/** * CGLib动态代理测试类 * ClassName: CGLibClient * @author rainbowhorse */public class CGLibClient &#123; public static void main(String[] args) &#123; CGLibDynamicProxy cglib = new CGLibDynamicProxy(); CGLibRealSubject realSubject = (CGLibRealSubject) cglib.getProxyInstance(new CGLibRealSubject()); realSubject.study(); System.out.println(); System.out.println(realSubject.say(&quot;Hello World.&quot;)); &#125;&#125; 运行-&gt;控制台输出结果如下 总结Spirng的AOP的动态代理实现机制有两种，分别是: 1）JDK动态代理 具体实现原理： 通过实现InvocationHandlet接口创建自己的调用处理器 通过为Proxy类指定ClassLoader对象和一组interface来创建动态代理 通过反射机制获取动态代理类的构造函数，其唯一参数类型就是调用处理器接口类型 通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数参入 JDK动态代理是面向接口的代理模式，如果被代理目标没有接口那么Spring也无能为力 Spring通过java的反射机制生产被代理接口的新的匿名实现类，重写了其中AOP的增强方法。 2）CGLib动态代理 CGLib是一个强大、高性能的Code生产类库，可以实现运行期动态扩展java类，Spring在运行期间通过CGlib继承要被动态代理的类，重写父类的方法，实现AOP面向切面编程。 对比 JDK动态代理是面向接口，在创建代理实现类时比CGLib要快，创建代理速度快。 CGLib动态代理是通过字节码底层继承要代理类来实现（如果被代理类被final关键字所修饰，那么会失败），在创建代理这一块没有JDK动态代理快，但是运行速度比JDK动态代理要快。 注意 如果要被代理的对象不是个实现类，那么Spring会强制使用CGLib来实现动态代理。 Spring中配置动态代理方式通过配置Spring的中**aop:config**标签来显示的指定使用动态代理机制 proxy-target-class=true表示使用CGLib代理，如果为false就是默认使用JDK动态代理。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"Apache-Commons-Email发送邮件","slug":"Apache-Commons-Email发送邮件","date":"2018-03-28T10:18:13.000Z","updated":"2021-05-09T10:54:05.136Z","comments":true,"path":"Apache-Commons-Email发送邮件/","link":"","permalink":"https://mx-go.github.io/Apache-Commons-Email%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/","excerpt":"","text":"引言使用Apache-Commons-Email发送邮件 环境准备Maven的pom.xml 文件中引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-email&lt;/artifactId&gt; &lt;version&gt;1.5&lt;/version&gt;&lt;/dependency&gt; 一个简单的纯文本邮件HTTP模式下第一个例子是创建一个简单的email。 123456789101112131415161718192021222324252627282930313233343536373839import org.apache.commons.mail.EmailException;import org.apache.commons.mail.SimpleEmail;/*** 类名: TestSimpleEmail.java &lt;br/&gt;* 详细描述: 一个简单的纯文本邮件 &lt;br/&gt;* 发布版本： V1.0 &lt;br/&gt; */public class TestSimpleEmail &#123; public static void main(String[] args) &#123; SimpleEmail email = new SimpleEmail(); //设置发送主机的服务器地址(如果不设置，默认是&quot;mail.host&quot;) email.setHostName (&quot;smtp.163.com&quot;); // 开启debug模式 email.setDebug(true); //设置端口号 email.setSmtpPort(25);//默认也是25 //如果要求身份验证，设置用户名、密码，分别为发件人在邮件服务器上注册的用户名和密码 email.setAuthentication ( &quot;from@163.com&quot;, &quot;password&quot; ); try &#123; //设置收件人邮箱以及名称 email.addTo (&quot;to@qq.com&quot;, &quot;收件人名称&quot;); //发件人邮箱以及名称 //email.setFrom (&quot;from@163.com&quot;, &quot;发件人名称&quot;); //发件人邮箱以及名称，邮件编码格式 email.setFrom(&quot;from@163.com&quot;, &quot;发件人名称&quot;, &quot;UTF-8&quot;); //设置邮件的主题 email.setSubject (&quot;这是邮件主题内容&quot;); //邮件正文消息 email.setMsg (&quot;这是邮件内容！&quot;); // 发送 email.send (); System.out.println (&quot;Send email successful!&quot;); &#125; catch (EmailException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 如果遇到乱码情况可以通过以下方案解决： 1234//设置主题的字符集为UTF-8email.setCharset(&quot;UTF-8&quot;);//设置内容的字符集为UTF-8,先buildMimeMessage才能设置内容文本email.getMimeMessage().setText(&quot;测试邮件内容&quot;,&quot;UTF-8&quot;); 开启了HTTPS需要添加ssl端口，以及开启SSLOnConnect。 1234567891011121314151617181920212223242526272829303132333435363738import org.apache.commons.mail.EmailException;import org.apache.commons.mail.SimpleEmail;/*** 类名: TestSimpleSSLEmail.java &lt;br/&gt;* 详细描述: 一个简单的纯文本邮件 --开启了https的情况下 &lt;br/&gt;* 发布版本： V1.0 &lt;br/&gt; */public class TestSimpleSSLEmail &#123; public static void main(String[] args) &#123; SimpleEmail email = new SimpleEmail (); // smtp host email.setHostName (&quot;smtp.qq.com&quot;); //端口号 email.setSslSmtpPort(&quot;465&quot;); // 登陆邮件服务器的用户名和密码 email.setAuthentication (&quot;from@qq.com&quot;, &quot;password&quot;);//注意qq邮箱需要授权，在设置那里生成一个随机码，然后填写到密码框。 // 接收人 email.setSSLOnConnect(true); try &#123; //设置收件人邮箱以及名称 email.addTo (&quot;to@qq.com&quot;, &quot;to&quot;); // 发送人 //email.setFrom (&quot;from@163.com&quot;, &quot;from&quot;); email.setFrom(&quot;from@qq.com&quot;, &quot;from&quot;, &quot;UTF-8&quot;); //设置邮件的主题 email.setSubject (&quot;这是邮件主题内容&quot;); //邮件正文消息 email.setMsg (&quot;这是邮件内容！--一个简单的纯文本邮件 --开启了https的情况下 &quot;); // 发送 email.send (); System.out.println (&quot;Send email successful!&quot;); &#125; catch (EmailException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 特别要注意的是qq邮箱进行了加密，所以需要到qq账户设置里面拿到开启stmp发信客户端的密码。 取到一串字符串，然后填写到密码处。不然会报以下的错误。而不是填写QQ账号密码到密码认证处。详细也可以参照QQ客户端说明文档。 发送带附件的邮件发送带附件的邮件得用MultiPartEmail 类来给邮件添加附件。除过覆盖attach()方法来给邮件添加附件外，这个类就和SimpleEmail类差不多。对于内联或是加入附件的个数是没有限制的。但附件必须是MIME编码。最简单的添加附件的方式是用 EmailAttachment类。 本地附件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import org.apache.commons.mail.EmailAttachment;import org.apache.commons.mail.EmailException;import org.apache.commons.mail.MultiPartEmail;/*** 类名: TestEmailAttachment.java &lt;br/&gt;* 详细描述:发送带附件的邮件--读取本地路径的文件 &lt;br/&gt;* 发布版本： V1.0 &lt;br/&gt; */public class TestEmailAttachment &#123; public static void main(String[] args) &#123; // 创建一个Email附件 EmailAttachment attachment = new EmailAttachment(); // 本地资源需要存在 attachment.setPath(&quot;E:\\\\qrcode.jpg&quot;); attachment.setDisposition(EmailAttachment.ATTACHMENT); attachment.setDescription(&quot;图片&quot;); // 自定义文件名，并且格式要一致，不然附近收到的话，有可能读不出来。 attachment.setName(&quot;qrcode.jpg&quot;); // Create the email message MultiPartEmail email = new MultiPartEmail(); // smtp host email.setHostName (&quot;smtp.163.com&quot;); //设置端口号 email.setSmtpPort(25);//默认也是25 // 登陆邮件服务器的用户名和密码 email.setAuthentication (&quot;from@163.com&quot;,&quot;password&quot;); try &#123; //设置收件人邮箱以及名称 email.addTo (&quot;to@qq.com&quot;, &quot;收件人名称&quot;); //发件人邮箱以及名称 //email.setFrom (&quot;from@163.com&quot;, &quot;发件人名称&quot;); //发件人邮箱以及名称，邮件编码格式 email.setFrom(&quot;from@163.com&quot;, &quot;发件人名称&quot;, &quot;UTF-8&quot;); //设置邮件的主题 email.setSubject (&quot;这是邮件主题内容&quot;); //邮件正文消息 email.setMsg (&quot;这是邮件内容！&quot;); // add the attachment email.attach(attachment); // send the email email.send(); System.out.println (&quot;Send email successful!&quot;); &#125; catch (EmailException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 远程附件如果没有本地文件，可以用 EmailAttachment 添加任何可用的URL。当邮件发送后，文件会自动加载并加入到邮件内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.net.MalformedURLException;import java.net.URL; import org.apache.commons.mail.EmailAttachment;import org.apache.commons.mail.EmailException;import org.apache.commons.mail.MultiPartEmail;/*** 类名: TestEmailAttachment.java &lt;br/&gt;* 详细描述:发送带附件的邮件--读取本地路径的文件 &lt;br/&gt;* 发布版本： V1.0 &lt;br/&gt; */public class TestEmailAttachment2 &#123; public static void main(String[] args) throws MalformedURLException &#123; // 创建一个Email附件 EmailAttachment attachment = new EmailAttachment(); attachment.setURL(new URL(&quot;http://www.apache.org/images/asf_logo_wide.gif&quot;)); attachment.setDisposition(EmailAttachment.ATTACHMENT); attachment.setDescription(&quot;Apache logo&quot;); // 自定义文件名，并且格式要一致，不然附近收到的话，有可能读不出来 attachment.setName(&quot;asf_logo_wide.gif&quot;); // Create the email message MultiPartEmail email = new MultiPartEmail(); // smtp host email.setHostName (&quot;smtp.163.com&quot;); //设置端口号(默认25) email.setSmtpPort(25); // 登陆邮件服务器的用户名和密码 email.setAuthentication (&quot;from@163.com&quot;,&quot;password&quot;); try &#123; // 设置收件人邮箱以及名称 email.addTo (&quot;to@qq.com&quot;, &quot;收件人名称&quot;); // 发件人邮箱以及名称 // email.setFrom (&quot;from@163.com&quot;, &quot;发件人名称&quot;); // 发件人邮箱以及名称，邮件编码格式 email.setFrom(&quot;from@163.com&quot;, &quot;发件人名称&quot;, &quot;UTF-8&quot;); // 设置邮件的主题 email.setSubject (&quot;这是邮件主题内容&quot;); // 邮件正文消息 email.setMsg (&quot;这是邮件内容！&quot;); // 添加附件 email.attach(attachment); // 发送邮件 email.send(); System.out.println (&quot;Send email successful!&quot;); &#125; catch (EmailException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 发送带HTML格式的邮件12345678910111213141516171819202122232425262728293031323334353637383940414243444546import java.net.MalformedURLException;import java.net.URL; import org.apache.commons.mail.EmailException;import org.apache.commons.mail.HtmlEmail;/*** 类名: TestHtmlEmail.java &lt;br/&gt;* 详细描述: 发送带HTML格式的邮件&lt;br/&gt;* 发布版本： V1.0 &lt;br/&gt; */public class TestHtmlEmail &#123; public static void main(String[] args) &#123; // 创建HTML邮件 HtmlEmail email = new HtmlEmail(); // 设置发送主机的服务器地址 email.setHostName (&quot;smtp.163.com&quot;); // 设置端口号(默认25) email.setSmtpPort(25); // 如果要求身份验证，设置用户名、密码，分别为发件人在邮件服务器上注册的用户名和密码 email.setAuthentication (&quot;from@163.com&quot;, &quot;password&quot; ); try &#123; URL url = new URL(&quot;http://www.apache.org/images/asf_logo_wide.gif&quot;); String cid = email.embed(url, &quot;Apache logo&quot;); //设置收件人邮箱以及名称 email.addTo (&quot;to@qq.com&quot;, &quot;收件人名称&quot;); //发件人邮箱以及名称 //email.setFrom (&quot;from@163.com&quot;, &quot;发件人名称&quot;); //发件人邮箱以及名称，邮件编码格式 email.setFrom(&quot;from@163.com&quot;, &quot;发件人名称&quot;, &quot;UTF-8&quot;); //设置邮件的主题 email.setSubject (&quot;这是邮件主题内容-发送带HTML格式的邮件&quot;); // HTML信息 email.setHtmlMsg(&quot;&lt;html&gt;The apache logo - &lt;img src=\\&quot;cid:&quot; + cid + &quot;\\&quot;&gt;&lt;/html&gt;&quot;); // set the alternative message email.setTextMsg(&quot;Your email client does not support HTML messages&quot;); // 发送邮件 email.send(); System.out.println (&quot;Send email successful!&quot;); &#125; catch (EmailException | MalformedURLException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 注意： embed()方法返回一个字符串。该字符串是一个随机生成的标识符，必须在图像标记中引用图像的图像。 没有调用setmsg()这个例子。因为如果HTML内容里有内联图片的话，这个方法是不能用的。这样我们可以用setHtmlMsg和setTextMsg方法。 发送带嵌入图片的HTML文本前面说的是创建带嵌入图片的HTML邮件，但是用HTML邮件模板来处理图片是很麻烦的。ImageHtmlEmail类能解决这个问题，它能很方便的将所有外部图片转化为内联图片。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.net.MalformedURLException;import java.net.URL;import org.apache.commons.mail.EmailException;import org.apache.commons.mail.ImageHtmlEmail;import org.apache.commons.mail.resolver.DataSourceUrlResolver; /*** 类名: TestHtmlEmail.java &lt;br/&gt;* 详细描述: 发送带HTML格式的邮件--嵌入图片的HTML文本 &lt;br/&gt;* 发布版本： V1.0 &lt;br/&gt; */public class TestHtmlEmail2 &#123; public static void main(String[] args) &#123; // create the email message ImageHtmlEmail email = new ImageHtmlEmail(); // 设置发送主机的服务器地址 email.setHostName (&quot;smtp.163.com&quot;); // 设置端口号(默认25) email.setSmtpPort(25); // 如果要求身份验证，设置用户名、密码，分别为发件人在邮件服务器上注册的用户名和密码 email.setAuthentication ( &quot;from@163.com&quot;, &quot;password&quot; ); // load your HTML email template String htmlEmailTemplate = &quot;嵌入图片的HTML文本:&lt;img src=\\&quot;http://www.apache.org/images/feather.gif\\&quot;&gt; ....&quot;; try &#123; URL url = new URL(&quot;http://www.apache.org&quot;); email.setDataSourceResolver(new DataSourceUrlResolver(url)); // 设置收件人邮箱以及名称 email.addTo(&quot;to@sina.com&quot;, &quot;收件人名称&quot;); // 发件人邮箱以及名称 // 发件人邮箱以及名称，邮件编码格式 email.setFrom(&quot;from@qq.com&quot;, &quot;发件人名称&quot;, &quot;UTF-8&quot;); // 设置邮件的主题 email.setSubject(&quot;这是邮件主题内容&quot;); // set the html message email.setHtmlMsg(htmlEmailTemplate); email.setCharset(&quot;UTF-8&quot;); // set the alternative message email.setTextMsg(&quot;Your email client does not support HTML messages&quot;); // 发送邮件 email.send(); System.out.println(&quot;Send email successful!&quot;); &#125; catch (MalformedURLException | EmailException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 调试JavaMail API支持调试选项，通过调用setDebug(true)来开启调试。调试信息会通过System.out打印出来。 commons-email的安全设置的特性。可以用EmailLiveTest和EmailConfiguration类在真正的SMTP服务器上测试commons-email。 认证如果要对SMTP服务器进行认证，可以在发邮件前调用setAuthentication(userName,password)方法测试。这将会在JavaMail API发送邮件时创建DefaultAuthenticator实例，要支持此方法得让你的服务器支持RFC255协议。 可以用javax.mail.Authenticator的子类来完成更加复杂的认证，如弹出个对话框等。当想收集并处理用户信息时，必须覆盖getPasswordAuthentication()方法。用Email.setAuthenticator方法可以创建新的Authenticator类。 参考文章http://commons.apache.org/proper/commons-email/userguide.html Apache Commons Email 发送邮件的用法介绍以及实战练习","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Mybatis之缓存","slug":"Mybatis之缓存","date":"2018-03-20T02:43:53.000Z","updated":"2021-05-09T10:54:58.072Z","comments":true,"path":"Mybatis之缓存/","link":"","permalink":"https://mx-go.github.io/Mybatis%E4%B9%8B%E7%BC%93%E5%AD%98/","excerpt":"","text":"引言Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存1024条SQL。二级缓存是指可以跨SqlSession的缓存。 Mybatis缓存缓存的意义：将用户经常查询的数据放在缓存（内存）中，用户去查询数据就不用从磁盘上(关系型数据库数据文件)查询，从缓存中查询，从而提高查询效率，解决了高并发系统的性能问题。 Mybatis提供一级缓存和二级缓存 mybatis一级缓存是一个SqlSession级别，sqlsession只能访问自己的一级缓存的数据。 二级缓存是跨sqlSession，是mapper级别的缓存，对于mapper级别的缓存不同的sqlsession是可以共享的。 Mybatis一级缓存Mybatis的一级缓存原理： 第一次发出一个查询sql，sql查询结果写入sqlsession的一级缓存中，缓存使用的数据结构是一个map&lt;key,value&gt; key：hashcode + sql + sql输入参数 + 输出参数（sql的唯一标识） value：用户信息 同一个sqlsession再次发出相同的sql，就从缓存中取，不走数据库。如果两次中间出现commit操作（修改、添加、删除），本sqlsession中的一级缓存区域全部清空，下次再去缓存中查询不到所以要从数据库查询，从数据库查询到再写入缓存。 Mybatis一级缓存值得注意的地方： Mybatis默认就是支持一级缓存的，并不需要我们配置。 mybatis和spring整合后进行mapper代理开发，不支持一级缓存，mybatis和Spring整合，Spring按照mapper的模板去生成mapper代理对象，模板中在最后统一关闭sqlsession。 在未开启事物的情况之下，每次查询，spring都会关闭旧的sqlSession而创建新的sqlSession，因此此时的一级缓存是没有启作用的。 在开启事物的情况之下，Spring使用ThreadLocal获取当前资源绑定同一个sqlSession，因此此时一级缓存是有效的。 Mybatis二级缓存二级缓存原理： 二级缓存的范围是mapper级别（mapper同一个命名空间），mapper以命名空间为单位创建缓存数据结构，结构是map&lt;key、value&gt;。 二级缓存配置Mybatis二级缓存需要手动开启，需要在Mybatis的配置文件中配置二级缓存 12345&lt;!-- 全局配置参数 --&gt;&lt;settings&gt; &lt;!-- 开启二级缓存 --&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt;&lt;/settings&gt; 上面已经说了，二级缓存的范围是mapper级别的，因此Mapper如果要使用二级缓存，还需要在对应的映射文件中配置。 123&lt;mapper namespace=&quot;com.rainbowhorse.test.dao.TestDataDao&quot;&gt;&lt;!-- 在mapper中开启二级缓存 --&gt;&lt;cache/&gt; 查询结果映射的pojo序列化 mybatis二级缓存需要将查询结果映射的pojo实现 java.io.serializable接口，如果不实现则抛出异常： 1org.apache.ibatis.cache.CacheException: Error serializing object. Cause: java.io.NotSerializableException: com.rainbowhorse.test.po.User 二级缓存可以将内存的数据写到磁盘，存在对象的序列化和反序列化，所以要实现java.io.serializable接口。 如果结果映射的pojo中还包括了pojo，都要实现java.io.serializable接口。 禁用二级缓存对于变化频率较高的sql，需要禁用二级缓存： 在statement中设置useCache=false可以禁用当前select语句的二级缓存，即每次查询都会发出sql去查询，默认情况是true，即该sql使用二级缓存。 1&lt;select id=&quot;findOrderListResultMap&quot; resultMap=&quot;ordersUserMap&quot; useCache=&quot;false&quot;&gt; 刷新缓存我们的缓存都是在查询语句中配置，而使用增删改的时候，缓存默认就会被清空【刷新了】。缓存其实就是为我们的查询服务的，对于增删改而言，如果我们的缓存保存了增删改后的数据，那么再次读取时就会读到脏数据了！ 我们在特定的情况下，还可以单独配置刷新缓存【但不建议使用】flushCache，默认是的true。 123&lt;update id=&quot;updateUser&quot; parameterType=&quot;cn.itcast.mybatis.po.User&quot; flushCache=&quot;false&quot;&gt; update user set username=#&#123;username&#125;,birthday=#&#123;birthday&#125;,sex=#&#123;sex&#125;,address=#&#123;address&#125; where id=#&#123;id&#125; &lt;/update&gt; 缓存参数mybatis的cache参数只适用于mybatis维护缓存。 flushInterval（刷新间隔）可以被设置为任意的正整数，而且它们代表一个合理的毫秒形式的时间段。默认情况是不设置，也就是没有刷新间隔，缓存仅仅调用语句时刷新。size（引用数目）可以被设置为任意正整数，要记住你缓存的对象数目和你运行环境的可用内存资源数目。默认值是1024。readOnly（只读）属性可以被设置为true或false。只读的缓存会给所有调用者返回缓存对象的相同实例。因此这些对象不能被修改。这提供了很重要的性能优势。可读写的缓存会返回缓存对象的拷贝（通过序列化）。这会慢一些，但是安全，因此默认是false。 如下例子：&lt;cache eviction=&quot;FIFO&quot; flushInterval=&quot;60000&quot; size=&quot;512&quot; readOnly=&quot;true&quot;/&gt;这个更高级的配置创建了一个 FIFO 缓存,并每隔 60 秒刷新,存数结果对象或列表的 512 个引用,而且返回的对象被认为是只读的,因此在不同线程中的调用者之间修改它们会导致冲突。可用的收回策略有, 默认的是 LRU: LRU – 最近最少使用的:移除最长时间不被使用的对象。 FIFO – 先进先出:按对象进入缓存的顺序来移除它们。 SOFT – 软引用:移除基于垃圾回收器状态和软引用规则的对象。 WEAK – 弱引用:更积极地移除基于垃圾收集器状态和弱引用规则的对象。 Mybatis和Ehcache整合Ehcache是专门用于管理缓存的，Mybatis的缓存交由ehcache管理会更加得当。在mybatis中提供一个cache接口，只要实现cache接口就可以把缓存数据灵活的管理起来。 整合jar包 mybatis-ehcache-1.0.2.jar ehcache-core-2.6.5.jar Ehcache对cache接口的实现类： ehcache.xml配置信息这个xml配置文件是配置全局的缓存管理方案 12345678910111213141516&lt;ehcache xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:noNamespaceSchemaLocation=&quot;../config/ehcache.xsd&quot;&gt; &lt;!--diskStore：缓存数据持久化的目录 地址 --&gt; &lt;diskStore path=&quot;F:\\develop\\ehcache&quot; /&gt; &lt;defaultCache maxElementsInMemory=&quot;1000&quot; maxElementsOnDisk=&quot;10000000&quot; eternal=&quot;false&quot; overflowToDisk=&quot;false&quot; diskPersistent=&quot;true&quot; timeToIdleSeconds=&quot;120&quot; timeToLiveSeconds=&quot;120&quot; diskExpiryThreadIntervalSeconds=&quot;120&quot; memoryStoreEvictionPolicy=&quot;LRU&quot;&gt; &lt;/defaultCache&gt;&lt;/ehcache&gt; 如果我们Mapper想单独拥有一些特性，需要在mapper.xml中单独配置 12345678910&lt;!-- 单位：毫秒 --&gt;&lt;cache type=&quot;org.mybatis.caches.ehcache.EhcacheCache&quot;&gt; &lt;property name=&quot;timeToIdleSeconds&quot; value=&quot;12000&quot;/&gt; &lt;property name=&quot;timeToLiveSeconds&quot; value=&quot;3600&quot;/&gt; &lt;!-- 同ehcache参数maxElementsInMemory --&gt; &lt;property name=&quot;maxEntriesLocalHeap&quot; value=&quot;1000&quot;/&gt; &lt;!-- 同ehcache参数maxElementsOnDisk --&gt; &lt;property name=&quot;maxEntriesLocalDisk&quot; value=&quot;10000000&quot;/&gt; &lt;property name=&quot;memoryStoreEvictionPolicy&quot; value=&quot;LRU&quot;/&gt;&lt;/cache&gt; 应用场景与局限性应用场景 对查询频率高，变化频率低的数据建议使用二级缓存。 对于访问多的查询请求且用户对查询结果实时性要求不高，此时可采用mybatis二级缓存技术降低数据库访问量，提高访问速度。 业务场景比如： 耗时较高的统计分析sql 电话账单查询sql等。 实现方法如下：通过设置刷新间隔时间，由mybatis每隔一段时间自动清空缓存，根据数据变化频率设置缓存刷新间隔flushInterval，比如设置为30分钟、60分钟、24小时等，根据需求而定。 局限性mybatis二级缓存对细粒度的数据级别的缓存实现不好，比如如下需求：对商品信息进行缓存，由于商品信息查询访问量大，但是要求用户每次都能查询最新的商品信息，此时如果使用mybatis的二级缓存就无法实现当一个商品变化时只刷新该商品的缓存信息而不刷新其它商品的信息，因为mybaits的二级缓存区域以mapper为单位划分，当一个商品信息变化会将所有商品信息的缓存数据全部清空。解决此类问题需要在业务层根据需求对数据有针对性缓存。 总结 Mybatis的一级缓存是SqlSession级别的。只能访问自己的sqlSession内的缓存。如果Mybatis与Spring整合了，Spring会自动关闭sqlSession的。所以一级缓存会失效。 一级缓存的原理是map集合，Mybatis默认就支持一级缓存。 二级缓存是Mapper级别的。只要在Mapper namespace下都可以使用二级缓存。需要自己手动去配置二级缓存。 Mybatis的缓存我们可以使用Ehcache框架来进行管理，Ehcache实现Cache接口就代表使用Ehcache来环境Mybatis缓存。 参考Mybatis【逆向工程，缓存，代理】知识要点","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"https://mx-go.github.io/tags/mybatis/"}]},{"title":"线程池之ThreadPoolExecutor","slug":"线程池之ThreadPoolExecutor","date":"2018-03-17T06:09:10.000Z","updated":"2021-05-09T10:56:01.793Z","comments":true,"path":"线程池之ThreadPoolExecutor/","link":"","permalink":"https://mx-go.github.io/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B9%8BThreadPoolExecutor/","excerpt":"","text":"引言JAVA对于多线程的封装非常丰富，提供了多种适用于不同场景的多并发实现。但如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。这里就引入了线程池来管理线程，其中最基础、最核心的线程池要属ThreadPoolExecutor类了。 Java中的ThreadPoolExecutor类java.uitl.concurrent.ThreadPoolExecutor类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下ThreadPoolExecutor类的具体实现源码。 在ThreadPoolExecutor类中提供了四个构造方法： 123456789101112131415161718192021public class ThreadPoolExecutor extends AbstractExecutorService &#123; ..... public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler); public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler); ...&#125;//corePoolSize： 线程池维护线程的最少数量 //maximumPoolSize：线程池维护线程的最大数量 //keepAliveTime： 线程池维护线程所允许的空闲时间 //unit： 线程池维护线程所允许的空闲时间的单位 //workQueue： 线程池所使用的缓冲队列 //handler： 线程池对拒绝任务的处理策略 从上面的代码可以得知，ThreadPoolExecutor继承了AbstractExecutorService类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。 corePoolSize：核心池的大小。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； maximumPoolSize：线程池最大线程数，它表示在线程池中最多能创建多少个线程； keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； unit：参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性： 1234567TimeUnit.DAYS; //天TimeUnit.HOURS; //小时TimeUnit.MINUTES; //分钟TimeUnit.SECONDS; //秒TimeUnit.MILLISECONDS; //毫秒TimeUnit.MICROSECONDS; //微妙TimeUnit.NANOSECONDS; //纳秒 workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择： 123ArrayBlockingQueue;LinkedBlockingQueue;SynchronousQueue; ArrayBlockingQueue和PriorityBlockingQueue使用较少，一般使用LinkedBlockingQueue和Synchronous。线程池的排队策略与BlockingQueue有关。 threadFactory：线程工厂，主要用来创建线程； handler：表示当拒绝处理任务时的策略，有以下四种取值： 1234ThreadPoolExecutor.AbortPolicy: 缺省。丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃任务队列中最旧任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 由图中我们可得知ThreadPoolExecutor继承了AbstractExecutorService，AbstractExecutorService是一个抽象类，它实现了ExecutorService接口，而ExecutorService又是继承了Executor接口。 线程池实现原理线程池状态在ThreadPoolExecutor中定义了几个static final变量表示线程池的各个状态： 1234567891011121314151617181920private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; * RUNNING -&gt; SHUTDOWN * On invocation of shutdown(), perhaps implicitly in finalize() * (RUNNING or SHUTDOWN) -&gt; STOP * On invocation of shutdownNow() * SHUTDOWN -&gt; TIDYING * When both queue and pool are empty * STOP -&gt; TIDYING * When pool is empty * TIDYING -&gt; TERMINATED * When the terminated() hook method has completed **/private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 下面的几个static final变量表示runState可能的几个取值。 RUNNING：允许接收新任务并且处理队列中的任务。 SHUTDOWN：不再接收新的任务，仅消化完队列中的任务。 STOP：不仅不再接收新的任务，连队列中的任务都不再消化处理了，并且尝试中断正在执行任务的线程。 TIDYING：所有任务被终止了，工作线程数workCount也被设为0，线程的状态也被设为TIDYING，并开始调用钩子函数terminated()。 TERMINATED：钩子函数terminated()执行完毕。 任务的执行123456789101112131415161718private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小/runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集private volatile long keepAliveTime; //线程存活时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数private volatile int poolSize; //线程池中当前的线程数private volatile RejectedExecutionHandler handler; //任务拒绝策略private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数private long completedTaskCount; //用来记录已经执行完毕的任务个数 每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。 如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务； 如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务； 如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理； 如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。 任务缓存及排队策略在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。workQueue的类型为BlockingQueue&lt;Runnable&gt;，通常可以取下面三种类型： 1）ArrayBlockingQueue：有界队列，有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 2）LinkedBlockingQueue：无界队列，将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 3）SynchronousQueue：工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 任务拒绝策略当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： 1234ThreadPoolExecutor.AbortPolicy: 丢弃任务并抛出RejectedExecutionException异常。ThreadPoolExecutor.DiscardPolicy： 也是丢弃任务，但是不抛出异常。ThreadPoolExecutor.DiscardOldestPolicy： 丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）ThreadPoolExecutor.CallerRunsPolicy： 由调用线程处理该任务 线程池的关闭ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。 shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。 线程池容量的动态调整ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()： setMaximumPoolSize：设置线程池最大能创建的线程数目大小。 使用Executors创建线程池Executors提供的工厂方法，可以创建以下四种类型线程池： newFixedThreadPool：该方法将用于创建一个固定大小的线程池（此时corePoolSize = maxPoolSize），每提交一个任务就创建一个线程池，直到线程池达到最大数量，线程池的规模在此后不会发生任何变化； newCachedThreadPool：该方法创建了一个可缓存的线程池，（此时corePoolSize = 0，maxPoolSize = Integer.MAX_VALUE），空闲线程超过60秒就会被自动回收，该线程池存在的风险是，如果服务器应用达到请求高峰期时，会不断创建新的线程，直到内存耗尽； newSingleThreadExecutor：该方法创建了一个单线程的线程池，该线程池按照任务在队列中的顺序串行执行（如：FIFO、LIFO、优先级）； newScheduledThreadPool：该方法创建了一个固定长度的线程池，可以以延迟或者定时的方式执行任务； 实例12345678910111213141516171819202122232425262728293031323334public class Test &#123; public static void main(String[] args) &#123; ThreadFactory factory = new ThreadFactoryBuilder().setNameFormat(&quot;test&quot;).build(); ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 5, 200, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(5),factory,new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 1; i &lt;= 10; i++) &#123; MyTask myTask = new MyTask(i); executor.execute(myTask); System.out.println(&quot;线程池中线程数目：&quot; + executor.getPoolSize() + &quot;，队列中等待执行的任务数目：&quot; + executor.getQueue().size() + &quot;，已执行玩别的任务数目：&quot; + executor.getCompletedTaskCount()); &#125; executor.shutdown(); &#125;&#125;class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println(&quot;正在执行task &quot; + taskNum); try &#123; Thread.currentThread().sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;task &quot; + taskNum + &quot;执行完毕&quot;); &#125;&#125; 执行结果： 合理配置线程池大小一般需要根据任务的类型来配置线程池大小： 如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1 如果是IO密集型任务，参考值可以设置为2*NCPU 这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 参考Java并发编程：线程池的使用","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Spring+webSocket","slug":"Spring-webSocket","date":"2018-03-16T06:00:11.000Z","updated":"2021-05-09T10:56:42.498Z","comments":true,"path":"Spring-webSocket/","link":"","permalink":"https://mx-go.github.io/Spring-webSocket/","excerpt":"引言websocket 是 HTML5新增加特性之一，目的是浏览器与服务端建立全双工的通信方式，解决 HTTP请求-响应带来过多的资源消耗，同时对特殊场景应用提供了全新的实现方式，比如聊天、股票交易、游戏等对对实时性要求较高的行业领域。","text":"引言websocket 是 HTML5新增加特性之一，目的是浏览器与服务端建立全双工的通信方式，解决 HTTP请求-响应带来过多的资源消耗，同时对特殊场景应用提供了全新的实现方式，比如聊天、股票交易、游戏等对对实时性要求较高的行业领域。 STOMPSTOMP(Simple Text-Orientated Messaging Protocol) 面向消息的简单文本协议。 WebSocket是一个消息架构，不强制使用任何特定的消息协议，它依赖于应用层解释消息的含义； 与处在应用层的HTTP不同，WebSocket处在TCP上非常薄的一层，会将字节流转换为文本/二进制消息，因此，对于实际应用来说，WebSocket的通信形式层级过低，因此，可以在 WebSocket 之上使用 STOMP协议，来为浏览器 和 server间的 通信增加适当的消息语义。 如何理解 STOMP 与 WebSocket 的关系： HTTP协议解决了 web 浏览器发起请求以及 web 服务器响应请求的细节，假设 HTTP 协议 并不存在，只能使用 TCP 套接字来 编写 web 应用，你可能认为这是一件疯狂的事情； 直接使用 WebSocket（SockJS） 就很类似于 使用 TCP 套接字来编写 web 应用，因为没有高层协议，就需要我们定义应用间所发送消息的语义，还需要确保连接的两端都能遵循这些语义； 同 HTTP 在 TCP 套接字上添加请求-响应模型层一样，STOMP 在 WebSocket 之上提供了一个基于帧的线路格式层，用来定义消息语义； Spring+websocket添加依赖需要添加spring-websocket和spring-messaging依赖，注意和spring-core的版本保持一致。 1234567891011&lt;!-- spring-websocket --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-websocket&lt;/artifactId&gt; &lt;version&gt;4.1.9.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-messaging&lt;/artifactId&gt; &lt;version&gt;4.1.9.RELEASE&lt;/version&gt;&lt;/dependency&gt; 服务端代码服务端的初始化，只需要两个类：WebsocketConfig（stomp节点配置）和WebSocketController。 12345678910111213141516171819202122232425262728import org.springframework.context.annotation.Configuration;import org.springframework.messaging.simp.config.MessageBrokerRegistry;import org.springframework.web.socket.config.annotation.AbstractWebSocketMessageBrokerConfigurer;import org.springframework.web.socket.config.annotation.EnableWebSocketMessageBroker;import org.springframework.web.socket.config.annotation.StompEndpointRegistry;/** * 通过EnableWebSocketMessageBroker 开启使用STOMP协议来传输基于代理(message broker)的消息,此时浏览器支持使用@MessageMapping 就像支持@RequestMapping一样。 */@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig extends AbstractWebSocketMessageBrokerConfigurer &#123; @Override public void registerStompEndpoints(StompEndpointRegistry registry) &#123; //endPoint 注册协议节点,并映射指定的URl //注册一个名字为&quot;endpointChat&quot; 的endpoint,并指定 SockJS协议，客户端就可以通过这个端点来进行连接；withSockJS作用是添加SockJS支持。 registry.addEndpoint(&quot;/endpointChat&quot;).withSockJS(); &#125; @Override public void configureMessageBroker(MessageBrokerRegistry registry) &#123; //配置消息代理(message broker)，定义了两个客户端订阅地址的前缀信息，也就是客户端接收服务端发送消息的前缀信息 //点对点式增加一个/queue 消息代理 registry.enableSimpleBroker(&quot;/queue&quot;, &quot;/topic&quot;); //定义了服务端接收地址的前缀，也即客户端给服务端发消息的地址前缀 //registry.setApplicationDestinationPrefixes(“/user”); &#125;&#125; 对以上代码分析： EnableWebSocketMessageBroker 注解表明： 这个配置类不仅配置了 WebSocket，还配置了基于代理的 STOMP 消息； 它复写了 registerStompEndpoints() 方法：添加一个服务端点，来接收客户端的连接。将 “/endpointChat” 路径注册为 STOMP 端点。这个路径与之前发送和接收消息的目的路径有所不同， 这是一个端点，客户端在订阅或发布消息到目的地址前，要连接该端点，即用户发送请求 ：URL=’/127.0.0.1:8080/endpointChat’ 与 STOMP server 进行连接，之后再转发到订阅URL； 它复写了 configureMessageBroker() 方法：配置了一个 简单的消息代理，通俗一点讲就是设置消息连接请求的各种规范信息。 12345678910111213141516171819202122232425262728293031import org.springframework.messaging.handler.annotation.MessageMapping;import org.springframework.messaging.simp.SimpMessagingTemplate;import org.springframework.stereotype.Controller;import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import org.springframework.beans.factory.annotation.Autowired;import com.thinkgem.jeesite.modules.sys.utils.UserUtils;@Controller@RequestMapping(&quot;/websocket&quot;)public class WebsocketController &#123; @Autowired private SimpMessagingTemplate template; @MessageMapping(&quot;/sendMsg&quot;) public void roomMessage() &#123; // 多线程配置推送消息 ThreadPoolExecutor executor = new ThreadPoolExecutor(1, 1, 0, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()); executor.execute(new Runnable() &#123; @Override public void run() &#123; template.convertAndSendToUser(userId, &quot;/queue/notifications&quot;,&quot;新消息：这是websocked测试消息&quot;);// 一对一发送，发送特定的客户端 //template.convertAndSend(&quot;/topic/getResponse&quot;,&quot;新消息：这是websocked测试消息&quot;);//广播消息 &#125; &#125;); executor.shutdown(); &#125;&#125; template.convertAndSendToUser(user, dest, message) 这个方法官方给出的解释是 Convert the given Object to serialized form, possibly using a MessageConverter, wrap it as a message and send it to the given destination. 意思就是“将给定的对象进行序列化，使用 ‘MessageConverter’ 进行包装转化成一条消息，发送到指定的目标”，通俗点讲就是我们使用这个方法进行消息的转发发送。 客户端实现首先引用 sockjs.js 和 stomp.js 12345678910111213141516171819202122232425262728&lt;script src=&quot;/js/common/sockjs.min.js&quot;&gt;&lt;script src=&quot;/js/common/stomp.min.js&quot;&gt;&lt;script type=&quot;text/javascript&quot;&gt; $(function() &#123; connect(); &#125;); function connect() &#123; // TOMP客户端要想接收来自服务器推送的消息，必须先订阅相应的URL，即发送一个SUBSCRIBE帧，然后才能不断接收来自服务器的推送消息； var sock = new SockJS(&quot;http://localhost:8080/endpointChat&quot;); var stomp = Stomp.over(sock); stomp.connect(&#x27;guest&#x27;, &#x27;guest&#x27;, function(frame) &#123; /**订阅了/user/queue/notifications 发送的消息,这里与在控制器convertAndSendToUser 定义的地址保持一致 * 这里多用了一个/user,并且这个user 是必须的,使用user才会发送消息到指定的用户。 * */ stomp.subscribe(&quot;/user/queue/notifications&quot;, handleNotification); stomp.subscribe(&#x27;/topic/getResponse&#x27;, function(response) &#123; //订阅/topic/getResponse 目标发送的消息。这个是在控制器的@SendTo中定义的。 console.info(response.body); &#125;); //向服务端发送消息 stomp.send(&quot;URL&quot;, &#123;&#125;, JSON.stringify(message)); //订阅服务器发送来的消息 function handleNotification(message) &#123; console.info(message.body); &#125; &#125;&lt;/script&gt; 利用 stomp的connect(login, passcode, connectCallback, errorCallback, vhost) 方法建立连接，值得注意的是不同版本的 stomp.js 的 connect() 函数的参数会有所不同； 利用 stomp的subscribe(destination, callback, headers) 方法可以订阅服务器发送来的消息，destination 表示服务器发送消息地址；通过 event 的 body 获取消息内容； 利用 stompClient 的send(destination, headers, body) 方法可以向服务端发送消息，第一个参数为发送消息地址，最后一个参数是发送消息的 json 串； 测试在客户端请求*/websocket/sendMsg*后会有如下效果： 参考： Spring Framework Reference Documentation websocket+spring spring websocket + stomp 实现广播通信和一对一通信","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"谈谈敏捷开发","slug":"谈谈敏捷开发","date":"2018-03-15T01:34:03.000Z","updated":"2021-05-09T11:03:46.186Z","comments":true,"path":"谈谈敏捷开发/","link":"","permalink":"https://mx-go.github.io/%E8%B0%88%E8%B0%88%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/","excerpt":"引言敏捷开发是一种从上个世纪九十年代开始逐渐引起广泛关注的一些新型软件开发方法，是一种应对快速变化的需求的一种软件开发能力。常言道：“天下武功，唯快不破”，此言用于形容“敏捷”的威力相当合适。敏捷意思为快，但敏捷思想不仅仅求快，它更多强调“多快好省”，产出得多，产出得快，产出得好，同时节省各种成本，既经济又实用。它们更强调程序员团队与业务专家之间的紧密协作、面对面的沟通（认为比书面的文档更有效）、频繁交付新的软件版本、紧凑而自我组织型的团队、能够很好地适应需求变化的代码编写和团队组织方法，也更注重软件开发过程中人的作用。","text":"引言敏捷开发是一种从上个世纪九十年代开始逐渐引起广泛关注的一些新型软件开发方法，是一种应对快速变化的需求的一种软件开发能力。常言道：“天下武功，唯快不破”，此言用于形容“敏捷”的威力相当合适。敏捷意思为快，但敏捷思想不仅仅求快，它更多强调“多快好省”，产出得多，产出得快，产出得好，同时节省各种成本，既经济又实用。它们更强调程序员团队与业务专家之间的紧密协作、面对面的沟通（认为比书面的文档更有效）、频繁交付新的软件版本、紧凑而自我组织型的团队、能够很好地适应需求变化的代码编写和团队组织方法，也更注重软件开发过程中人的作用。 敏捷开发宣言和原则敏捷宣言的价值观 个体和互动 高于 流程和工具 工作的软件 高于 详尽的文档 客户合作 高于 合同谈判 响应变化 高于 遵循计划 也就是说，尽管右项有其价值，我们更重视左项的价值。 敏捷宣言的原则 我们最重要的目标，是通过持续不断地及早交付有价值的软件使客户满意。 欣然面对需求变化，即使在开发后期也一样。为了客户的竞争优势，敏捷过程掌控变化。 经常地交付可工作的软件，相隔几星期或一两个月，倾向于采取较短的周期。 业务人员和开发人员必须相互合作，项目中的每一天都不例外。 激发个体的斗志，以他们为核心搭建项目。提供所需的环境和支援，辅以信任，从而达成目标。 不论团队内外，传递信息效果最好效率也最高的方式是面对面的交谈。 可工作的软件是进度的首要度量标准。 敏捷过程倡导可持续开发。责任人、开发人员和用户要能够共同维持其步调稳定延续。 坚持不懈地追求技术卓越和良好设计，敏捷能力由此增强。 以简洁为本，它是极力减少不必要工作量的艺术。 最好的架构、需求和设计出自自组织团队。 团队定期地反思如何能提高成效，并依此调整自身的举止表现。 敏捷宣言中这些价值观和原则，所谓入门容易精通难，在旁人或者入门者看来也许略显空洞，所言无物；然而，敏捷精髓的实践者们一直坚信着这些理念，觉得它们字字珠玑，所言极是。不管我们是走敏捷的哪个流派，都不妨在实践敏捷的过程中，回过头来看看这些价值观和原则，想必会常看常新，大有裨益。 Scrum核心 团队密切协作敏捷开发中，最核心的就是人。 不是说每个人坐在自己的格子间里，各自独立开发，定期向领导汇报工作就完事了，敏捷开发需要做到几个关键点： 定期会面。通过定期高效会议让开发人员保持紧张有序的工作状态。 及时告知项目进展。鼓励遇到问题一定要及时告知，让所有利益相关者都能够及时了解项目的最新进展。 知识共享。把知识分享出来，可以提升整个团队的开发能力，是对团队的一种投资。 代码共享。把代码集中在版本管理工具之中，团队任何人都有访问权限。 代码审查。针对代码的每个改动，都需要相关人员做代码审查。 不断反馈和调整敏捷开发与传统瀑布式开发一个最大的不同就是，并非一次定终身。 软件开发不是线性过程，它存在很多的不确定性，有一定的动态波动，所以需要不断的反馈、调整，快速响应变化。 需求调整。在产品落地前，你是不可能制定出完美需求方案的，客户也并不一定能够清晰的知道他想要的软件产品到底是什么样子。所以，要做好需求不断变化的心理准备，也要有快速响应需求变化的能力。 功能调整。收集客户反馈、用户反响，来不断调整和优化软件功能。 代码重构。在开发的过程中，需要不断的重构代码，保持代码清晰、内聚、整洁。 保持软件可用传统软件开发的方式是，等代码编写完毕，所有功能都完成之后，再集中测试和上线，在这之前，软件都是用户不可用的。 在信息快速发展的今天，这显然太落伍了，可能等你软件开发个一年半载，外面都变天了。 敏捷开发，另一大特色，就是保持软件一直可用，在最小可用版本基础之上，不断做功能迭代，不断发布新的版本。 通俗点讲就是，先做一个简化版本出来，让用户一直有软件可用，而后再逐步添加更多的功能，「小步快跑」式的做开发，而非一步到位。 这样做的好处，也是为了能够不断收集用户反馈与需求，及时调整开发方向。 短迭代 增量发布这一条是上一条的延伸。 所谓「迭代」就是，重复下一个开发周期，此刻你可以想象一下 while loop。 用迭代的方法在前一版本之上逐步开发新的功能，发布新的版本，即：增量发布。 迭代周期不宜过长，一年半年显然就太久了，尽量要缩短迭代周期，保持开发过程稳步前进。 但短迭代并不意味着太过频繁，每天或者每周迭代一次的话，很可能会过犹不及，半个月到一个月应该是一个不错的时间节点。当然这只是参考建议，具体的迭代周期还应根据真实情况量力而行。 提早集成 不断集成「集成」的含义就是，把软件的各个模块，新旧代码统一整合在一起，能够正确编译、运行，并且能够通过一系列的单元测试。 敏捷开发要求开发人员，不要临到软件发布或者交付的当天才开始集成，也不要很久才集成一次，尽可能的做到提早继承、频繁集成。理论上讲，每添加进一些新的代码，最好都要做一次集成。 通过提早集成、不断集成，能够尽早发现代码中的问题，保持软件的状态一直是可用的。 自动化集成、测试与部署敏捷的另一个关键点是，通过技术手段把集成、测试与部署这些非常耗时的操作自动化。 至于为什么要自动化，如果你是一个人开发一个几千行的程序，那确实没必要自动化，确切的说，也没必要应用什么敏捷开发。 针对开发大型软件的团队而言，编译、测试过程有可能都非常的耗时，编译有时会花上半天的时间，测试可能会持续好几天。而且是多人协作共同开发，如果纯手动的话，你想象一下如果两个人想前后脚提交代码，岂不是要等上好几天的时间，等前面那个人集成结束之后，后面那个人才可以开始集成？ 把集成、测试与部署自动化的好处就是，把这些耗时的纯体力劳动扔给机器去做，它做完了，只要返回你一个最终结果就好了，而且两个人同时 Check In 时也不会受到影响。 这副图涵盖了自动化集成、测试以及部署的流程。 开发者 Check In 之后的所有工作将都交给机器去做，它们都有专门的工具 ，包括集成工具、测试工具，当然这些工具可以使用第三方的，也可以自己开发。 一般情况下，这一系列的工作都跟版本管理工具绑定在一起，你只要 Check In 就会触发集成、测试，甚至还有部署。而你，只要专心的等待结果就好。 总结在流程上，敏捷最大的特色是迭代式开发。敏捷开发可以用一句话概括：拥抱变化，轻量文档，团队合作，多个短的冲刺周期 参考文章： https://www.zybuluo.com/yishuailuo/note/672154?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://mx-go.github.io/categories/%E6%9D%82%E8%B0%88/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://mx-go.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Sping定时任务","slug":"Sping定时任务","date":"2018-03-07T09:09:22.000Z","updated":"2021-05-05T03:29:41.580Z","comments":true,"path":"Sping定时任务/","link":"","permalink":"https://mx-go.github.io/Sping%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/","excerpt":"引言在企业开发中，经常会遇到时间任务调度的需求，比如每天凌晨生成前天报表、数据汇总等动态配置是否开启定时的任务。在Java领域中，定时任务的开源工具也非常多，小到一个Timer类，大到Quartz框架。在Spring中最常见的定时任务方式属Spring schedule注解的方式和利用Quartz动态管理定时任务。总体来说，个人比较喜欢的还是Quartz，功能强大而且使用方便。","text":"引言在企业开发中，经常会遇到时间任务调度的需求，比如每天凌晨生成前天报表、数据汇总等动态配置是否开启定时的任务。在Java领域中，定时任务的开源工具也非常多，小到一个Timer类，大到Quartz框架。在Spring中最常见的定时任务方式属Spring schedule注解的方式和利用Quartz动态管理定时任务。总体来说，个人比较喜欢的还是Quartz，功能强大而且使用方便。 Spring-@scheduled对于较简单的任务可以使用Spring内置的定时任务方法@scheduled注解进行配置达到自己的需求。 spring配置文件配置spring项目的基础文件spring.xml 123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot; http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.1.xsd&quot;&gt; &lt;!-- 开启定时任务 spring的定时任务默认是单线程，多个任务执行起来时间会有问题，所以这里配置了线程池--&gt; &lt;task:executor id=&quot;executor&quot; pool-size=&quot;5&quot; /&gt; &lt;task:scheduler id=&quot;scheduler&quot; pool-size=&quot;10&quot; /&gt; &lt;task:annotation-driven executor=&quot;executor&quot; scheduler=&quot;scheduler&quot; /&gt; &lt;/beans&gt; Task任务类定义了一个任务类ATask，里面有两个定时任务aTask和bTask。编写java业务代码，需要在类声明上边添加**@Component注解，并在需要定时任务执行的方法声明上添加@Scheduled**注解以及cron表达式和相关的参数。 12345678910111213141516// 定时器的任务方法不能有返回值@Componentpublic class ATask &#123; @Scheduled(cron = &quot;0/10 * * * * ? &quot;) // 每10秒执行一次 public void aTask() &#123; DateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); System.out.println(sdf.format(DateTime.now().toDate()) + &quot;*********A任务每10秒执行一次进入测试&quot;); &#125; @Scheduled(cron = &quot;0/5 * * * * ? &quot;) // 每5秒执行一次 public void bTask() &#123; DateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); System.out.println(sdf.format(DateTime.now().toDate()) + &quot;*********B任务每5秒执行一次进入测试&quot;); &#125;&#125; 运行结果启动项目会发现定时任务已经开启。 Spring-Quartz@scheduled固然可以实现定时任务，但是仔细想想并不灵活，任务随着应用的启动而执行，并不能动态的进行管理，很是不方便，然而Quartz很好的解决了这一问题。 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt; 任务管理类QuartzManager123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151public class QuartzManager &#123; private static SchedulerFactory schedulerFactory = new StdSchedulerFactory(); /** * @Description: 添加一个定时任务 * * @param jobName * 任务名 * @param jobGroupName * 任务组名 * @param triggerName * 触发器名 * @param triggerGroupName * 触发器组名 * @param jobClass * 任务 * @param cron * 时间设置，参考quartz说明文档 */ @SuppressWarnings(&#123; &quot;unchecked&quot;, &quot;rawtypes&quot; &#125;) public static void addJob(String jobName, String jobGroupName, String triggerName, String triggerGroupName, Class jobClass, String cron) &#123; try &#123; Scheduler sched = schedulerFactory.getScheduler(); // 任务名，任务组，任务执行类 JobDetail jobDetail = JobBuilder.newJob(jobClass).withIdentity(jobName, jobGroupName).build(); // 触发器 TriggerBuilder&lt;Trigger&gt; triggerBuilder = TriggerBuilder.newTrigger(); // 触发器名,触发器组 triggerBuilder.withIdentity(triggerName, triggerGroupName); triggerBuilder.startNow(); // 触发器时间设定 triggerBuilder.withSchedule(CronScheduleBuilder.cronSchedule(cron)); // 创建Trigger对象 CronTrigger trigger = (CronTrigger) triggerBuilder.build(); // 调度容器设置JobDetail和Trigger sched.scheduleJob(jobDetail, trigger); // 启动 if (!sched.isShutdown()) &#123; sched.start(); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /** * @Description: 修改一个任务的触发时间 * * @param jobName * @param jobGroupName * @param triggerName * 触发器名 * @param triggerGroupName * 触发器组名 * @param cron * 时间设置，参考quartz说明文档 */ public static void modifyJobTime(String jobName, String jobGroupName, String triggerName, String triggerGroupName, String cron) &#123; try &#123; Scheduler sched = schedulerFactory.getScheduler(); TriggerKey triggerKey = TriggerKey.triggerKey(triggerName, triggerGroupName); CronTrigger trigger = (CronTrigger) sched.getTrigger(triggerKey); if (trigger == null) &#123; return; &#125; String oldTime = trigger.getCronExpression(); if (!oldTime.equalsIgnoreCase(cron)) &#123; /** 方式一 ：调用 rescheduleJob 开始 */ // 触发器 TriggerBuilder&lt;Trigger&gt; triggerBuilder = TriggerBuilder.newTrigger(); // 触发器名,触发器组 triggerBuilder.withIdentity(triggerName, triggerGroupName); triggerBuilder.startNow(); // 触发器时间设定 triggerBuilder.withSchedule(CronScheduleBuilder.cronSchedule(cron)); // 创建Trigger对象 trigger = (CronTrigger) triggerBuilder.build(); // 方式一 ：修改一个任务的触发时间 sched.rescheduleJob(triggerKey, trigger); /** 方式一 ：调用 rescheduleJob 结束 */ /** 方式二：先删除，然后在创建一个新的Job */ // JobDetail jobDetail = // sched.getJobDetail(JobKey.jobKey(jobName, jobGroupName)); // Class&lt;? extends Job&gt; jobClass = jobDetail.getJobClass(); // removeJob(jobName, jobGroupName, triggerName, // triggerGroupName); // addJob(jobName, jobGroupName, triggerName, triggerGroupName, // jobClass, cron); /** 方式二 ：先删除，然后在创建一个新的Job */ &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /** * @Description: 移除一个任务 * * @param jobName * @param jobGroupName * @param triggerName * @param triggerGroupName */ public static void removeJob(String jobName, String jobGroupName, String triggerName, String triggerGroupName) &#123; try &#123; Scheduler sched = schedulerFactory.getScheduler(); TriggerKey triggerKey = TriggerKey.triggerKey(triggerName, triggerGroupName); sched.pauseTrigger(triggerKey);// 停止触发器 sched.unscheduleJob(triggerKey);// 移除触发器 sched.deleteJob(JobKey.jobKey(jobName, jobGroupName));// 删除任务 &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /** * @Description:启动所有定时任务 */ public static void startJobs() &#123; try &#123; Scheduler sched = schedulerFactory.getScheduler(); sched.start(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; /** * @Description:关闭所有定时任务 */ public static void shutdownJobs() &#123; try &#123; Scheduler sched = schedulerFactory.getScheduler(); if (!sched.isShutdown()) &#123; sched.shutdown(); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 任务执行业务这里做一个简单的演示，只实现Job接口打印当前时间。 1234567public class MyJob implements Job&#123; public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException &#123; DateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); System.out.println(sdf.format(DateTime.now().toDate())); &#125;&#125; 测试动态定时任务新建QuartzTest.Java 测试类 123456789101112131415161718192021222324public class QuartzTest &#123; public static String JOB_NAME = &quot;动态任务调度&quot;; public static String TRIGGER_NAME = &quot;动态任务触发器&quot;; public static String JOB_GROUP_NAME = &quot;XLXXCC_JOB_GROUP&quot;; public static String TRIGGER_GROUP_NAME = &quot;XLXXCC_JOB_GROUP&quot;; public static void main(String[] args) &#123; try &#123; System.out.println(&quot;【系统启动】开始(每1秒输出一次)...&quot;); QuartzManager.addJob(JOB_NAME, JOB_GROUP_NAME, TRIGGER_NAME, TRIGGER_GROUP_NAME, MyJob.class,&quot;0/1 * * * * ?&quot;); Thread.sleep(5000); System.out.println(&quot;【修改时间】开始(每5秒输出一次)...&quot;); QuartzManager.modifyJobTime(JOB_NAME, JOB_GROUP_NAME, TRIGGER_NAME, TRIGGER_GROUP_NAME, &quot;0/5 * * * * ?&quot;); Thread.sleep(15000); System.out.println(&quot;【移除定时】开始...&quot;); QuartzManager.removeJob(JOB_NAME, JOB_GROUP_NAME, TRIGGER_NAME, TRIGGER_GROUP_NAME); System.out.println(&quot;【移除定时】成功&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出如下： 总结通过以上测试可以明显的看出两者的优劣，Quartz足够灵活强大，但Spring scheduled 在简单任务下也是一个不错的选择。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"大话数据库连接池","slug":"大话数据库连接池","date":"2018-02-06T09:50:49.000Z","updated":"2021-05-11T00:17:29.841Z","comments":true,"path":"大话数据库连接池/","link":"","permalink":"https://mx-go.github.io/%E5%A4%A7%E8%AF%9D%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0/","excerpt":"","text":"引言数据库连接池在Java数据库相关中间件产品群中，应该算是最底层最基础的一类产品，作为企业应用开发必不可少的组件，无数开发者们贡献了一个又一个的优秀产品，它们有的随着时代发展，功成身退，有的还在不断迭代，老而弥坚，更有新生代产品，或性能无敌、或功能全面。接下来就聊一聊 “那些年，我们用过的数据库连接池。” 第一、二代连接池区分一个数据库连接池是属于第一代产品还是代二代产品有一个最重要的特征就是看它在架构和设计时采用的线程模型，因为这直接影响的是并发环境下存取数据库连接的性能。 一般来讲采用单线程同步的架构设计都属于第一代连接池，二采用多线程异步架构的则属于第二代。比较有代表性的就是Apache Commons DBCP，在1.x版本中，一直延续着单线程设计模式，到2.x才采用多线程模型。 用版本发布时间来辨别区分两代产品，则一个偷懒的好方法。以下是这些常见数据库连接池最新版本的发布时间： 数据库连接池 最新版本 发布时间 C3P0 c3p0-0.9.5.2 on 9 Dec 2015 DBCP 2.2.0 27 December 2017 Druid 0.11.0 Dec 4 2017 HikariCP 2.7.6 2018-01-14 从表中可以看出，C3P0已经很久没有更新了。DBCP更新速度很慢，基本处于不活跃状态，而Druid和HikariCP处于活跃状态的更新中，这就是我们说的二代产品了。 二代产品对一代产品的超越是颠覆性的，除了一些“历史原因”，你很难再找到第二条理由说服自己不选择二代产品，但任何成功都不是偶然的，二代产品的成功很大程度上得益于前代产品们打下的基础，站在巨人的肩膀上，新一代的连接池的设计师们将这一项“工具化”的产品，推向了极致。其中，最具代表性的两款产品是： HikariCP Druid 彻底死掉的C3P0C3P0是我使用的第一款数据库连接池，在很长一段时间内，它一直是Java领域内数据库连接池的代名词，当年盛极一时的Hibernate都将其作为内置的数据库连接池，可以业内对它的稳定性还是认可的。C3P0功能简单易用，稳定性好这是它的优点，但是性能上的缺点却让它彻底被打入冷宫。C3P0的性能很差，差到即便是同时代的产品相比它也是垫底的，更不用和Druid、HikariCP等相比了。正常来讲，有问题很正常，改就是了，但c3p0最致命的问题就是架构设计过于复杂，让重构变成了一项不可能完成的任务。随着国内互联网大潮的涌起，性能有硬伤的c3p0彻底的退出了历史舞台。 咸鱼翻身的DBCPDBCP（DataBase Connection Pool）属于Apache顶级项目Commons中的核心子项目（最早在Jakarta Commons里就有）,在Apache的生态圈中的影响里十分广泛，比如最为大家所熟知的Tomcat就在内部集成了DBCP，实现JPA规范的OpenJPA，也是默认集成DBCP的。但DBCP并不是独立实现连接池功能的，它内部依赖于Commons中的另一个子项目Pool，连接池最核心的“池”，就是由Pool组件提供的，因此，DBCP的性能实际上就是Pool的性能，DBCP和Pool的依赖关系如下表： Apache Commons DBCP Apache Commons Pool v1.2.2 v1.3 v1.3 v1.5.4 v1.4 v1.5.4 v2.0.x v2.2 v2.1.x v2.4.2 v2.2.x v2.5.0 可以看到，因为核心功能依赖于Pool，所以DBCP本身只能做小版本的更新，真正大版本的更迭则完全依托于pool。有很长一段时间，pool都还是停留在1.x版本，这直接导致DBCP也更新乏力。很多依赖DBCP的应用在遇到性能瓶颈之后，别无选择，只能将其替换掉，DBCP忠实的拥趸tomcat就在其tomcat 7.0版本中，自己重新设计开发出了一套连接池（Tomcat JDBC Pool）。好在，在2013年事情终于迎来转机，13年9月Commons-Pool 2.0版本发布，14年2月份，DBCP也终于迎来了自己的2.0版本，基于新的线程模型全新设计的“池”让DBCP重焕青春，虽然和新一代的连接池相比仍有一定差距，但差距并不大，DBCP2.x版本已经稳稳达到了和新一代产品同级别的性能指标（见下图）。 DBCP终于靠Pool咸鱼翻身，打了一个漂亮的翻身仗，但长时间的等待已经完全消磨了用户的耐心，与新一代的产品项目相比，DBCP没有任何优势，试问，谁会在有选择的前提下，去选择那个并不优秀的呢？也许，现在还选择DBCP2的唯一理由，就是情怀吧。 性能无敌的HikariCPHikariCP号称“性能杀手”（It’s Faster），它的表现究竟如何呢，先来看下官网提供的数据： 不光性能强劲，稳定性也不差： 那它是怎么做到如此强劲的呢？官网给出的说明如下： 字节码精简：优化代码，直到编译后的字节码最少，这样，CPU缓存可以加载更多的程序代码； 优化代理和拦截器：减少代码，例如HikariCP的Statement proxy只有100行代码； 自定义数组类型（FastStatementList）代替ArrayList：避免每次get()调用都要进行range check，避免调用remove()时的从头到尾的扫描； 自定义集合类型（ConcurrentBag）：提高并发读写的效率； 其他缺陷的优化，比如对于耗时超过一个CPU时间片的方法调用的研究（但没说具体怎么优化）。 可以看到，上述这几点优化，和现在能找到的资料来看，HakariCP在性能上的优势应该是得到共识的，再加上它自身小巧的身形，在当前的“云时代、微服务”的背景下，HakariCP一定会得到更多人的青睐。 功能全面的Druid近几年，阿里在开源项目上动作频频，除了有像fastJson、dubbo这类项目，更有像AliSQL这类的大型软件，今天说的Druid，就是阿里众多优秀开源项目中的一个。它除了提供性能卓越的连接池功能外，还集成了SQL监控，黑名单拦截等功能，用它自己的话说，Druid是“为监控而生”。借助于阿里这个平台的号召力，产品一经发布就赢得了大批用户的拥趸，从用户使用的反馈来看，Druid也确实没让用户失望。 相较于其他产品，Druid另一个比较大的优势，就是中文文档比较全面（毕竟是国人的项目么），在github的wiki页面，列举了日常使用中可能遇到的问题，对一个新用户来讲，上面提供的内容已经足够指导它完成产品的配置和使用了。 下图为Druid自己提供的性能测试数据： 现在项目开发中，我还是比较倾向于使用Durid，它不仅仅是一个数据库连接池，它还包含一个ProxyDriver，一系列内置的JDBC组件库，一个SQL Parser。 Druid 相对于其他数据库连接池的优点 强大的监控特性，通过Druid提供的监控功能，可以清楚知道连接池和SQL的工作情况。 a. 监控SQL的执行时间、ResultSet持有时间、返回行数、更新行数、错误次数、错误堆栈信息； b. SQL执行的耗时区间分布。什么是耗时区间分布呢？比如说，某个SQL执行了1000次，其中01毫秒区间50次，110毫秒800次，10100毫秒100次，1001000毫秒30次，1~10秒15次，10秒以上5次。通过耗时区间分布，能够非常清楚知道SQL的执行耗时情况； c. 监控连接池的物理连接创建和销毁次数、逻辑连接的申请和关闭次数、非空等待次数、PSCache命中率等。 方便扩展。Druid提供了Filter-Chain模式的扩展API，可以自己编写Filter拦截JDBC中的任何方法，可以在上面做任何事情，比如说性能监控、SQL审计、用户名密码加密、日志等等。 Druid集合了开源和商业数据库连接池的优秀特性，并结合阿里巴巴大规模苛刻生产环境的使用经验进行优化。 总结时至今日，虽然每个应用（需要RDBMS的）都离不开连接池，但在实际使用的时候，连接池已经可以做到“隐形”了。也就是说在通常情况下，连接池完成项目初始化配置之后，就再不需要再做任何改动了。不论你是选择Druid或是HikariCP，甚至是DBCP，它们都足够稳定且高效！之前讨论了很多关于连接池的性能的问题，但这些性能上的差异，是相较于其他连接池而言的，对整个系统应用来说，第二代连接池在使用过程中体会到的差别是微乎其微的，基本上不存在因为连接池的自身的配饰和使用导致系统性能下降的情况，除非是在单点应用的数据库负载足够高的时候（压力测试的时候），但即便是如此，通用的优化的方式也是单点改集群，而不是在单点的连接池上死扣。 参考 数据库连接池性能比对 大话数据库连接池 c3p0,Druid,Tomcat Jdbc Pool,dbcp2,proxool数据源性能比较","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"sql","slug":"sql","permalink":"https://mx-go.github.io/tags/sql/"}]},{"title":"Nginx配置文件详解","slug":"Nginx配置文件详解","date":"2018-01-24T06:12:52.000Z","updated":"2021-05-10T15:07:38.821Z","comments":true,"path":"Nginx配置文件详解/","link":"","permalink":"https://mx-go.github.io/Nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"引言之前介绍了Linux下安装Nginx，Nginx 专为性能优化而开发，性能是其最重要的考量,实现上非常注重效率 。它支持内核 Poll 模型，能经受高负载的考验,有报告表明能支持高达 50,000 个并发连接数。 Nginx特点Nginx 具有很高的稳定性。其它 HTTP 服务器，当遇到访问的峰值，或者有人恶意发起慢速连接时，也很可能会导致服务器物理内存耗尽频繁交换，失去响应，只能重启服务器。例如当前 apache 一旦上到 200 个以上进程，web响应速度就明显非常缓慢了。而 Nginx 采取了分阶段资源分配技术，使得它的 CPU 与内存占用率非常低。Nginx 官方表示保持 10,000 个没有活动的连接，它只占 2.5M 内存，所以类似 DOS 这样的攻击对 Nginx 来说基本上是毫无用处的。就稳定性而言，Nginx 比 lighthttpd 更胜一筹。 Nginx 支持热部署。启动特别容易，并且几乎可以做到 7*24 不间断运行，即使运行数个月也不需要重新启动。还能够在不间断服务的情况下，对软件版本进行进行升级。 Nginx的用处说了这么多Nginx的优点，Nginx在开发中最常用作反向代理服务器，但是Nginx的用处可不止这一点。 Nginx配置虚拟主机虚拟主机是一种特殊的软硬件技术，它可以将网络上的每一台计算机分成多个虚拟主机，每个虚拟主机可以独立对外提供www服务，这样就可以实现一台主机对外提供多个web服务，每个虚拟主机之间是独立的，互不影响的。 1、 基于ip的虚拟主机 2、基于端口的虚拟主机 3、基于域名的虚拟主机 Nginx反向代理通常的代理服务器，只用于代理内部网络对Internet的连接请求，客户机必须指定代理服务器,并将本来要直接发送到Web服务器上的http请求发送到代理服务器中由代理服务器向Internet上的web服务器发起请求，最终达到客户机上网的目的。 ​ 而反向代理（Reverse Proxy）方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。 Nginx配置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264#用户user nginx ;#工作进程，根据硬件调整，大于等于cpu核数worker_processes 8;#错误日志error_log logs/nginx_error.log crit;#pid放置的位置pid logs/nginx.pid;#指定进程可以打开的最大描述符worker_rlimit_nofile 204800;这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。events&#123; #使用epoll的I/O 模型 use epoll; 补充说明: 与apache相类，nginx针对不同的操作系统，有不同的事件模型 A）标准事件模型 Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll B）高效事件模型 Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 Epoll:使用于Linux内核2.6版本及以后的系统。 /dev/poll：使用于Solaris 7 11/99+, HP/UX 11.22+ (eventport), IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 Eventport：使用于Solaris 10. 为了防止出现内核崩溃的问题， 有必要安装安全补丁 #工作进程的最大连接数量，根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行 worker_connections 204800; 每个进程允许的最多连接数， 理论上每台nginx服务器的最大连接数为worker_processes*worker_connections #keepalive超时时间。 keepalive_timeout 60; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 open_file_cache_min_uses 1;&#125;#设定http服务器，利用它的反向代理功能提供负载均衡支持http&#123; #设定mime类型,类型由mime.type文件定义 include mime.types; default_type application/octet-stream; log_format main &#x27;$host $status [$time_local] $remote_addr [$time_local] $request_uri &#x27;&#x27;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &#x27;&#x27;$bytes_sent $request_time $sent_http_x_cache_hit&#x27;;log_format log404 &#x27;$status [$time_local] $remote_addr $host$request_uri $sent_http_location&#x27;;$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；$remote_user：用来记录客户端用户名称；$time_local： 用来记录访问时间与时区；$request： 用来记录请求的url与http协议；$status： 用来记录请求状态；成功是200，$body_bytes_s ent ：记录发送给客户端文件主体内容大小；$http_referer：用来记录从那个页面链接访问过来的；$http_user_agent：记录客户毒啊浏览器的相关信息；通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址； # 用了log_format指令设置了日志格式之后，需要用access_log指令指定日志文件的存放路径； # access_log /usr/local/nginx/logs/access_log main; access_log /dev/null; #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 128k; #客户请求头缓冲大小 n#ginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取如果设置过小HTTP头/Cookie过大 会报400 错误nginx 400 bad request求行如果超过buffer，就会报HTTP 414错误(URI Too Long)nginx接受最长的HTTP头部大小必须比其中一个buffer大，否则就会报400的 large_client_header_buffers 8 128k;HTTP错误(Bad Request)。#使用字段:http, server, location 这个指令指定缓存是否启用,如果启用,将记录文件以下信息: ·打开的文件描述符,大小信息和修改时间. ·存在的目录信息. ·在搜索文件过程中的错误信息 --没有这个文件,无法正确读取,参考open_file_cache_errors指令选项:·max -指定缓存的最大数目,如果缓存溢出,最长使用过的文件(LRU)将被移除#例: open_file_cache max=1000 inactive=20s; open_file_cache_valid 30s; open_file_cache_min_uses 2; open_file_cache_errors on; open_file_cache max 102400 #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误. open_file_cache_errors #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如 果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid #设定通过nginx上传文件的大小 client_max_body_size 300m; #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件， #对于普通应用，必须设为on。 #如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #后端服务器连接的超时时间_发起握手等候响应超时时间 proxy_connect_timeout 90; #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 180; #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 180; #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 256k; #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 8 256k; proxy_busy_buffers_size 256k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 proxy_temp_file_write_size 256k; #proxy_temp_path和proxy_cache_path指定的路径必须在同一分区 proxy_temp_path /data0/proxy_temp_dir; #设置内存缓存空间大小为200MB，1天没有被访问的内容自动清除，硬盘缓存空间大小为30GB。 proxy_cache_path /data0/proxy_cache_dir levels=1:2 keys_zone=cache_one:200m inactive=1d max_size=30g; client_header_timeout 5; client_body_timeout 5; send_timeout 5; #keepalive超时时间。 keepalive_timeout 120; #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。#无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 512k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; upstream img_relay &#123; server 127.0.0.1:8027; server 127.0.0.1:8028; server 127.0.0.1:8029; hash $request_uri; &#125; #如果请求为img_relay:80,则交给名称为img_relay的Nginx集群来处理 server&#123; listen 80; server_name img_relay;# limit_req zone=req_one burst=5 nodelay; location ~ .*.jsp$ &#123; proxy_ignore_client_abort on; proxy_pass http://img_relay; #http:// + upstream名称 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_connect_timeout 60; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_read_timeout 600; #连接成功后，后端服务器响应时间(代理接收超时) proxy_send_timeout 60; #后端服务器数据回传时间(代理发送超时) proxy_buffer_size 128k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 32 128k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_busy_buffers_size 128k; #高负荷下缓冲大小（proxy_buffers*2） &#125;&#125;nginx的upstream目前支持4种方式的分配1、轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 2、weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如：upstream bakend &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10;&#125;3、ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。例如：upstream bakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80;&#125;4、fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。upstream backend &#123; server server1; server server2; fair;&#125;5、url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32;&#125;tips:upstream bakend&#123;#定义负载均衡设备的Ip及设备状态 ip_hash; server 127.0.0.1:9090 down; server 127.0.0.1:8080 weight=2; server 127.0.0.1:6060; server 127.0.0.1:7070 backup;&#125;在需要使用负载均衡的server中增加proxy_pass http://bakend/;每个设备的状态设置为:1.down表示单前的server暂时不参与负载2.weight默认为1.weight越大，负载的权重就越大。3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误4.fail_timeout:max_fails次失败后，暂停的时间。5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。nginx支持同时设置多组的负载均衡，用来给不用的server来使用。client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debugclient_body_temp_path设置记录文件的目录 可以设置最多3层目录location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://mx-go.github.io/tags/nginx/"}]},{"title":"HttpClient后台跨域","slug":"HttpClient后台跨域","date":"2018-01-20T01:48:24.000Z","updated":"2021-05-05T03:23:27.472Z","comments":true,"path":"HttpClient后台跨域/","link":"","permalink":"https://mx-go.github.io/HttpClient%E5%90%8E%E5%8F%B0%E8%B7%A8%E5%9F%9F/","excerpt":"引言跨域可以说是一个经常遇到的问题，最近在联调一个身份证识别接口，该接口由python语言编写，Java语言调用，刚开始采用了CORS（Cross-Origin Resource Sharing）跨域，在IE8上一直出现兼容性问题，固定的思维容易出现错误，自己一直想着前端Ajax跨域而忽略了后台HttpClient的跨域，最后还是用HttpClient顺利解决问题，避免了浏览器跨域带来的兼容性问题。","text":"引言跨域可以说是一个经常遇到的问题，最近在联调一个身份证识别接口，该接口由python语言编写，Java语言调用，刚开始采用了CORS（Cross-Origin Resource Sharing）跨域，在IE8上一直出现兼容性问题，固定的思维容易出现错误，自己一直想着前端Ajax跨域而忽略了后台HttpClient的跨域，最后还是用HttpClient顺利解决问题，避免了浏览器跨域带来的兼容性问题。 HttpClient VS Jsonp之前的博客有说过Jsonp的跨域方式，jsonp的核心则是动态添加&lt;script&gt;标签来调用服务器提供的js脚本。相比于HttpClient，Jsonp有两个很大的缺点： 1、它只能发送get请求，如果发送post请求会造成无法解析获取不到数据的问题。 2、如果返回的数据没有经过配置相应的编码文件来处理，拿到的数据可能会是一堆乱码。 问题总是能解决，HttpClient则没那么多约束，HttpClient封装了http协议的jar包，基本的请求方法get、post、put、 delete都能实现，当然得在web.xml文件中配置相应的filter拦截器拦截请求后再设好编码，一般返回的参数都是Json字符串，而我们只需要导入Jackson或者fastJson或者别的jar包来解析这对象把他转换成你所需要的数据即可。 整合Spring添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.2&lt;/version&gt;&lt;/dependency&gt; 封装方法新建HttpClientUtil工具类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public class HttpClientUtil &#123; public static String doGet(String url, Map&lt;String, String&gt; param) &#123; // 创建Httpclient对象 CloseableHttpClient httpclient = HttpClients.createDefault(); String resultString = &quot;&quot;; CloseableHttpResponse response = null; try &#123; // 创建uri URIBuilder builder = new URIBuilder(url); if (param != null) &#123; for (String key : param.keySet()) &#123; builder.addParameter(key, param.get(key)); &#125; &#125; URI uri = builder.build(); // 创建http GET请求 HttpGet httpGet = new HttpGet(uri); // 执行请求 response = httpclient.execute(httpGet); // 判断返回状态是否为200 if (response.getStatusLine().getStatusCode() == 200) &#123; resultString = EntityUtils.toString(response.getEntity(), &quot;UTF-8&quot;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (response != null) &#123; response.close(); &#125; httpclient.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return resultString; &#125; public static String doGet(String url) &#123; return doGet(url, null); &#125; public static String doPost(String url, Map&lt;String, String&gt; param) &#123; // 创建Httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); CloseableHttpResponse response = null; String resultString = &quot;&quot;; try &#123; // 创建Http Post请求 HttpPost httpPost = new HttpPost(url); // 创建参数列表 if (param != null) &#123; List&lt;NameValuePair&gt; paramList = new ArrayList&lt;&gt;(); for (String key : param.keySet()) &#123; paramList.add(new BasicNameValuePair(key, param.get(key))); &#125; // 模拟表单 UrlEncodedFormEntity entity = new UrlEncodedFormEntity(paramList); httpPost.setEntity(entity); &#125; // 执行http请求 response = httpClient.execute(httpPost); resultString = EntityUtils.toString(response.getEntity(), &quot;utf-8&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; response.close(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; return resultString; &#125; public static String doPost(String url) &#123; return doPost(url, null); &#125; public static String doPostJson(String url, String json) &#123; // 创建Httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); CloseableHttpResponse response = null; String resultString = &quot;&quot;; try &#123; // 创建Http Post请求 HttpPost httpPost = new HttpPost(url); // 创建请求内容 StringEntity entity = new StringEntity(json, ContentType.APPLICATION_JSON); httpPost.setEntity(entity); // 执行http请求 response = httpClient.execute(httpPost); resultString = EntityUtils.toString(response.getEntity(), &quot;utf-8&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; response.close(); &#125; catch (IOException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; return resultString; &#125;&#125; 单元测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class HttpClientTest &#123; @Test public void doGet() throws Exception &#123; //创建一个httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建一个GET对象 HttpGet get = new HttpGet(&quot;http://www.sogou.com&quot;); //执行请求 CloseableHttpResponse response = httpClient.execute(get); //取响应的结果 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(statusCode); HttpEntity entity = response.getEntity(); String string = EntityUtils.toString(entity, &quot;utf-8&quot;); System.out.println(string); //关闭httpclient response.close(); httpClient.close(); &#125; @Test public void doGetWithParam() throws Exception&#123; //创建一个httpclient对象 CloseableHttpClient httpClient = HttpClients.createDefault(); //创建一个uri对象 URIBuilder uriBuilder = new URIBuilder(&quot;http://www.sogou.com/web&quot;); uriBuilder.addParameter(&quot;query&quot;, &quot;花千骨&quot;); HttpGet get = new HttpGet(uriBuilder.build()); //执行请求 CloseableHttpResponse response = httpClient.execute(get); //取响应的结果 int statusCode = response.getStatusLine().getStatusCode(); System.out.println(statusCode); HttpEntity entity = response.getEntity(); String string = EntityUtils.toString(entity, &quot;utf-8&quot;); System.out.println(string); //关闭httpclient response.close(); httpClient.close(); &#125; @Test public void doPost() throws Exception &#123; CloseableHttpClient httpClient = HttpClients.createDefault(); //创建一个post对象 HttpPost post = new HttpPost(&quot;http://localhost:8082/httpclient/post.action&quot;); //执行post请求 CloseableHttpResponse response = httpClient.execute(post); String string = EntityUtils.toString(response.getEntity()); System.out.println(string); response.close(); httpClient.close(); &#125; @Test public void doPostWithParam() throws Exception&#123; CloseableHttpClient httpClient = HttpClients.createDefault(); //创建一个post对象 HttpPost post = new HttpPost(&quot;http://localhost:8082/httpclient/post.action&quot;); //创建一个Entity。模拟一个表单 List&lt;NameValuePair&gt; kvList = new ArrayList&lt;&gt;(); kvList.add(new BasicNameValuePair(&quot;username&quot;, &quot;张三&quot;)); kvList.add(new BasicNameValuePair(&quot;password&quot;, &quot;123&quot;)); //包装成一个Entity对象 StringEntity entity = new UrlEncodedFormEntity(kvList, &quot;utf-8&quot;); //设置请求的内容 post.setEntity(entity); //执行post请求 CloseableHttpResponse response = httpClient.execute(post); String string = EntityUtils.toString(response.getEntity()); System.out.println(string); response.close(); httpClient.close(); &#125;&#125; 项目实例123456789101112131415161718192021222324252627/** * 订单处理Service * &lt;p&gt;Title: OrderServiceImpl&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * @version 1.0 */@Servicepublic class OrderServiceImpl implements OrderService &#123; @Value(&quot;$&#123;ORDER_BASE_URL&#125;&quot;) private String ORDER_BASE_URL; @Value(&quot;$&#123;ORDER_CREATE_URL&#125;&quot;) private String ORDER_CREATE_URL; @Override public String createOrder(Order order) &#123; //调用order的服务提交订单。 String json = HttpClientUtil.doPostJson(ORDER_BASE_URL + ORDER_CREATE_URL, JsonUtils.objectToJson(order)); //把json转换成taotaoResult TaotaoResult taotaoResult = TaotaoResult.format(json); if (taotaoResult.getStatus() == 200) &#123; Object orderId = taotaoResult.getData(); return orderId.toString(); &#125; return &quot;&quot;; &#125;&#125; 总结HttpClient与Jsonp能够轻易的解决跨域问题，从而得到自己想要的数据(来自不同IP，协议，端口)，唯一的不同点是，HttpClient是在后台Java代码中进行跨域访问，而Jsonp是在前台js中进行跨域访问。跨域还有一级跨域，二级跨域，更多内容值得研究。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"说说JSON和JSONP","slug":"说说JSON和JSONP","date":"2018-01-16T06:41:09.000Z","updated":"2021-05-05T03:19:50.144Z","comments":true,"path":"说说JSON和JSONP/","link":"","permalink":"https://mx-go.github.io/%E8%AF%B4%E8%AF%B4JSON%E5%92%8CJSONP/","excerpt":"前言说到AJAX就会不可避免的面临两个问题，第一个是AJAX以何种格式来交换数据？第二个是跨域的需求如何解决？这两个问题目前都有不同的解决方案，比如数据可以用自定义字符串或者用XML来描述，跨域可以通过服务器端代理来解决。 JSON和JSONP虽然只有一个字母的差别，但其实他们根本不是一回事：JSON是一种数据交换格式，而JSONP是一种依靠开发人员的聪明才智创造出的一种非官方跨域数据交互协议。我们拿最近比较火的谍战片来打个比方，JSON是地下党们用来书写和交换情报的“暗号”，而JSONP则是把用暗号书写的情报传递给自己同志时使用的接头方式。看到没？一个是描述信息的格式，一个是信息传递双方约定的方法。","text":"前言说到AJAX就会不可避免的面临两个问题，第一个是AJAX以何种格式来交换数据？第二个是跨域的需求如何解决？这两个问题目前都有不同的解决方案，比如数据可以用自定义字符串或者用XML来描述，跨域可以通过服务器端代理来解决。 JSON和JSONP虽然只有一个字母的差别，但其实他们根本不是一回事：JSON是一种数据交换格式，而JSONP是一种依靠开发人员的聪明才智创造出的一种非官方跨域数据交互协议。我们拿最近比较火的谍战片来打个比方，JSON是地下党们用来书写和交换情报的“暗号”，而JSONP则是把用暗号书写的情报传递给自己同志时使用的接头方式。看到没？一个是描述信息的格式，一个是信息传递双方约定的方法。 什么是JSON前面简单说了一下，JSON是一种基于文本的数据交换方式，或者叫做数据描述格式，你是否该选用他首先肯定要关注它所拥有的优点。 JSON的优点 基于纯文本，跨平台传递极其简单； JavaScript原生支持，后台语言几乎全部支持； 轻量级数据格式，占用字符数量极少，特别适合互联网传递； 可读性较强，虽然比不上XML那么一目了然，但在合理的依次缩进之后还是很容易识别的； 容易编写和解析，当然前提是你要知道数据结构； JSON的缺点当然也有，但在作者看来实在是无关紧要的东西，所以不再单独说明。 JSON的格式或者叫规则JSON能够以非常简单的方式来描述数据结构，XML能做的它都能做，因此在跨平台方面两者完全不分伯仲。 JSON只有两种数据类型描述符，大括号{}和方括号[]，其余英文冒号:是映射符，英文逗号,是分隔符，英文双引号””是定义符。 大括号{}用来描述一组“不同类型的无序键值对集合”（每个键值对可以理解为OOP的属性描述），方括号[]用来描述一组“相同类型的有序数据集合”（可对应OOP的数组）。 上述两种集合中若有多个子项，则通过英文逗号,进行分隔。 键值对以英文冒号:进行分隔，并且建议键名都加上英文双引号””，以便于不同语言的解析。 JSON内部常用数据类型无非就是字符串、数字、布尔、日期、null 这么几个，字符串必须用双引号引起来，其余的都不用，日期类型比较特殊，这里就不展开讲述了，只是建议如果客户端没有按日期排序功能需求的话，那么把日期时间直接作为字符串传递就好，可以省去很多麻烦。 JSON的实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// 描述一个人var person = &#123; &quot;Name&quot;: &quot;Bob&quot;, &quot;Age&quot;: 32, &quot;Company&quot;: &quot;IBM&quot;, &quot;Engineer&quot;: true&#125;// 获取这个人的信息var personAge = person.Age;// 描述几个人var members = [ &#123; &quot;Name&quot;: &quot;Bob&quot;, &quot;Age&quot;: 32, &quot;Company&quot;: &quot;IBM&quot;, &quot;Engineer&quot;: true &#125;, &#123; &quot;Name&quot;: &quot;John&quot;, &quot;Age&quot;: 20, &quot;Company&quot;: &quot;Oracle&quot;, &quot;Engineer&quot;: false &#125;, &#123; &quot;Name&quot;: &quot;Henry&quot;, &quot;Age&quot;: 45, &quot;Company&quot;: &quot;Microsoft&quot;, &quot;Engineer&quot;: false &#125;]// 读取其中John的公司名称var johnsCompany = members[1].Company;// 描述一次会议var conference = &#123; &quot;Conference&quot;: &quot;Future Marketing&quot;, &quot;Date&quot;: &quot;2012-6-1&quot;, &quot;Address&quot;: &quot;Beijing&quot;, &quot;Members&quot;: [ &#123; &quot;Name&quot;: &quot;Bob&quot;, &quot;Age&quot;: 32, &quot;Company&quot;: &quot;IBM&quot;, &quot;Engineer&quot;: true &#125;, &#123; &quot;Name&quot;: &quot;John&quot;, &quot;Age&quot;: 20, &quot;Company&quot;: &quot;Oracle&quot;, &quot;Engineer&quot;: false &#125;, &#123; &quot;Name&quot;: &quot;Henry&quot;, &quot;Age&quot;: 45, &quot;Company&quot;: &quot;Microsoft&quot;, &quot;Engineer&quot;: false &#125; ]&#125;// 读取参会者Henry是否工程师var henryIsAnEngineer = conference.Members[2].Engineer; 关于JSON，就说这么多，更多细节请在开发过程中查阅资料深入学习。 什么是JSONPJSONP的产生其实网上关于JSONP的讲解有很多，但却千篇一律，而且云里雾里，对于很多刚接触的人来讲理解起来有些困难，试着用自己的方式来阐释一下这个问题。 1、一个众所周知的问题，Ajax直接请求普通文件存在跨域无权限访问的问题，甭管你是静态页面、动态网页、web服务、WCF，只要是跨域请求，一律不准； 2、不过我们又发现，Web页面上调用js文件时则不受是否跨域的影响（不仅如此，我们还发现凡是拥有”src”这个属性的标签都拥有跨域的能力，比如&lt;script&gt;、&lt;img&gt;、&lt;iframe&gt;）； 3、于是可以判断，当前阶段如果想通过纯web端（ActiveX控件、服务端代理、属于未来的HTML5之Websocket等方式不算）跨域访问数据就只有一种可能，那就是在远程服务器上设法把数据装进js格式的文件里，供客户端调用和进一步处理； 4、恰巧我们已经知道有一种叫做JSON的纯字符数据格式可以简洁的描述复杂数据，更妙的是JSON还被js原生支持，所以在客户端几乎可以随心所欲的处理这种格式的数据； 5、这样子解决方案就呼之欲出了，web客户端通过与调用脚本一模一样的方式，来调用跨域服务器上动态生成的js格式文件（一般以JSON为后缀），显而易见，服务器之所以要动态生成JSON文件，目的就在于把客户端需要的数据装入进去。 6、客户端在对JSON文件调用成功之后，也就获得了自己所需的数据，剩下的就是按照自己需求进行处理和展现了，这种获取远程数据的方式看起来非常像AJAX，但其实并不一样。 7、为了便于客户端使用数据，逐渐形成了一种非正式传输协议，人们把它称作JSONP，该协议的一个要点就是允许用户传递一个callback参数给服务端，然后服务端返回数据时会将这个callback参数作为函数名来包裹住JSON数据，这样客户端就可以随意定制自己的函数来自动处理返回数据了。 JSONP的客户端具体实现不管jQuery也好，extjs也罢，又或者是其他支持jsonp的框架，他们幕后所做的工作都是一样的，下面我来循序渐进的说明一下jsonp在客户端的实现： 1、我们知道，哪怕跨域js文件中的代码（当然指符合web脚本安全策略的），web页面也是可以无条件执行的。 远程服务器remoteserver.com根目录下有个remote.js文件代码如下： 1alert(&#x27;我是远程文件&#x27;); 本地服务器localserver.com下有个jsonp.html页面代码如下： 123456789&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://remoteserver.com/remote.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 毫无疑问，页面将会弹出一个提示窗体，显示跨域调用成功。 2、现在我们在jsonp.html页面定义一个函数，然后在远程remote.js中传入数据进行调用。 jsonp.html页面代码如下： 1234567891011121314&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; var localHandler = function(data)&#123; alert(&#x27;我是本地函数，可以被跨域的remote.js文件调用，远程js带来的数据是：&#x27; + data.result); &#125;; &lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;http://remoteserver.com/remote.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; remote.js文件代码如下： 1localHandler(&#123;&quot;result&quot;:&quot;我是远程js带来的数据&quot;&#125;); 运行之后查看结果，页面成功弹出提示窗口，显示本地函数被跨域的远程js调用成功，并且还接收到了远程js带来的数据。很欣喜，跨域远程获取数据的目的基本实现了，但是又一个问题出现了，我怎么让远程js知道它应该调用的本地函数叫什么名字呢？毕竟是jsonp的服务者都要面对很多服务对象，而这些服务对象各自的本地函数都不相同啊？我们接着往下看。 3、聪明的开发者很容易想到，只要服务端提供的js脚本是动态生成的就行了呗，这样调用者可以传一个参数过去告诉服务端“我想要一段调用XXX函数的js代码，请你返回给我”，于是服务器就可以按照客户端的需求来生成js脚本并响应了。 看jsonp.html页面的代码： 123456789101112131415161718192021&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; // 得到航班信息查询结果后的回调函数 var flightHandler = function(data)&#123; alert(&#x27;你查询的航班结果是：票价 &#x27; + data.price + &#x27; 元，&#x27; + &#x27;余票 &#x27; + data.tickets + &#x27; 张。&#x27;); &#125;; // 提供jsonp服务的url地址（不管是什么类型的地址，最终生成的返回值都是一段javascript代码） var url = &quot;http://flightQuery.com/jsonp/flightResult.aspx?code=CA1998&amp;callback=flightHandler&quot;; // 创建script标签，设置其属性 var script = document.createElement(&#x27;script&#x27;); script.setAttribute(&#x27;src&#x27;, url); // 把script标签加入head，此时调用开始 document.getElementsByTagName(&#x27;head&#x27;)[0].appendChild(script); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 这次的代码变化比较大，不再直接把远程js文件写死，而是编码实现动态查询，而这也正是jsonp客户端实现的核心部分，本例中的重点也就在于如何完成jsonp调用的全过程。 我们看到调用的url中传递了一个code参数，告诉服务器我要查的是CA1998次航班的信息，而callback参数则告诉服务器，我的本地回调函数叫做flightHandler，所以请把查询结果传入这个函数中进行调用。 OK，服务器很聪明，这个叫做flightResult.aspx的页面生成了一段这样的代码提供给jsonp.html（服务端的实现这里就不演示了，与你选用的语言无关，说到底就是拼接字符串）： 12345flightHandler(&#123; &quot;code&quot;: &quot;CA1998&quot;, &quot;price&quot;: 1780, &quot;tickets&quot;: 5&#125;); 我们看到，传递给flightHandler函数的是一个json，它描述了航班的基本信息。运行一下页面，成功弹出提示窗口，jsonp的执行全过程顺利完成！ 4、到这里为止的话，相信你已经能够理解jsonp的客户端实现原理了吧？剩下的就是如何把代码封装一下，以便于与用户界面交互，从而实现多次和重复调用。 什么？你用的是jQuery，想知道jQuery如何实现jsonp调用？好吧，那我就好人做到底，再给你一段jQuery使用jsonp的代码（我们依然沿用上面那个航班信息查询的例子，假定返回jsonp结果不变）： 123456789101112131415161718192021222324252627&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot; &gt; &lt;head&gt; &lt;title&gt;Untitled Page&lt;/title&gt; &lt;script type=&quot;text/javascript&quot; src=jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; jQuery(document).ready(function()&#123; $.ajax(&#123; type: &quot;get&quot;, async: false, url: &quot;http://flightQuery.com/jsonp/flightResult.aspx?code=CA1998&quot;, dataType: &quot;jsonp&quot;, jsonp: &quot;callback&quot;,//传递给请求处理程序或页面的，用以获得jsonp回调函数名的参数名(一般默认为:callback) jsonpCallback:&quot;flightHandler&quot;,//自定义的jsonp回调函数名称，默认为jQuery自动生成的随机函数名，也可以写&quot;?&quot;，jQuery会自动为你处理数据 success: function(json)&#123; alert(&#x27;您查询到航班信息：票价： &#x27; + json.price + &#x27; 元，余票： &#x27; + json.tickets + &#x27; 张。&#x27;); &#125;, error: function()&#123; alert(&#x27;fail&#x27;); &#125; &#125;); &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;/body&gt; &lt;/html&gt; 是不是有点奇怪？为什么我这次没有写flightHandler这个函数呢？而且竟然也运行成功了！哈哈，这就是jQuery的功劳了，jquery在处理jsonp类型的ajax时（还是忍不住吐槽，虽然jquery也把jsonp归入了ajax，但其实它们真的不是一回事儿），自动帮你生成回调函数并把数据取出来供success属性方法来调用，是不是很爽呀？ 总结1、ajax和jsonp这两种技术在调用方式上“看起来”很像，目的也一样，都是请求一个url，然后把服务器返回的数据进行处理，因此jquery和ext等框架都把jsonp作为ajax的一种形式进行了封装； 2、但ajax和jsonp其实本质上是不同的东西。ajax的核心是通过XmlHttpRequest获取非本页内容，而jsonp的核心则是动态添加&lt;script&gt;标签来调用服务器提供的js脚本。 3、所以说，其实ajax与jsonp的区别不在于是否跨域，ajax通过服务端代理一样可以实现跨域，jsonp本身也不排斥同域的数据的获取。 4、还有就是，jsonp是一种方式或者说非强制性协议，如同ajax一样，它也不一定非要用json格式来传递数据，如果你愿意，字符串都行，只不过这样不利于用jsonp提供公开服务。 总而言之，jsonp不是ajax的一个特例，哪怕jquery等巨头把jsonp封装进了ajax，也不能改变着一点！ 转自：说说JSON和JSONP，也许你会豁然开朗，含jQuery用例","categories":[{"name":"前端","slug":"前端","permalink":"https://mx-go.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Linux下安装Nginx","slug":"Linux下安装Nginx","date":"2018-01-11T07:16:49.000Z","updated":"2021-05-05T09:31:48.704Z","comments":true,"path":"Linux下安装Nginx/","link":"","permalink":"https://mx-go.github.io/Linux%E4%B8%8B%E5%AE%89%E8%A3%85Nginx/","excerpt":"记录下Linux下安装Nginx。","text":"记录下Linux下安装Nginx。 Nginx安装环境Nginx是C语言开发，建议在Linxu上运行，下面操作实在Centos6.5上的安装环境。 gcc 安装nginx需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc。 安装命令：yum install gcc-c++ PCRE PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。 安装命令：yum install -y pcre pcre-devel zlib zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。 安装命令：yum install -y zlib zlib-devel openssl OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。 安装命令：yum install -y openssl openssl-devel 编译安装将nginx-1.8.0.tar.gz拷贝至Linux服务器后解压。 12tar -zxvf nginx-1.8.0.tar.gzcd nginx-1.8.0 configure ./configure –help查询详细参数。参数设置如下： 注意：下边将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录 123456789101112./configure \\--prefix=/usr/local/nginx \\--pid-path=/var/run/nginx/nginx.pid \\--lock-path=/var/lock/nginx.lock \\--error-log-path=/var/log/nginx/error.log \\--http-log-path=/var/log/nginx/access.log \\--with-http_gzip_static_module \\--http-client-body-temp-path=/var/temp/nginx/client \\--http-proxy-temp-path=/var/temp/nginx/proxy \\--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\--http-scgi-temp-path=/var/temp/nginx/scgi 编译安装 12makemake install 启动Nginx1234cd /usr/local/nginx/sbin/./nginx// 查询nginx进程命令ps aux|grep nginx 注意：执行./nginx启动nginx，这里可以-c指定加载的nginx配置文件，如下： 1./nginx -c /usr/soft/nginx-1.8.0/conf/nginx.conf 如果不指定-c，nginx在启动时默认加载/usr/local/nginx/conf/nginx.conf文件，此文件的地址也可以在编译安装nginx时指定./configure的参数（–conf-path= 指向配置文件（nginx.conf）） 重启Nginx 先停止再启动（建议使用） 对nginx进行重启相当于先停止nginx再启动nginx，即先执行停止命令再执行启动命令。 12./nginx -s quit./nginx 重新加载配置文件 当nginx的配置文件nginx.conf修改后，要想让配置生效需要重启nginx，使用-s reload不用先停止nginx再启动nginx即可将配置信息在nginx中生效。 1./nginx -s reload 测试nginx安装成功，启动nginx，即可访问虚拟机上的nginx 到这说明nginx上安装成功。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"安装","slug":"Linux/安装","permalink":"https://mx-go.github.io/categories/Linux/%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"nginx","slug":"nginx","permalink":"https://mx-go.github.io/tags/nginx/"}]},{"title":"Linux下安装JDK与MySQL","slug":"Linux下安装JDK与MySQL","date":"2018-01-09T11:53:24.000Z","updated":"2021-05-05T09:31:43.415Z","comments":true,"path":"Linux下安装JDK与MySQL/","link":"","permalink":"https://mx-go.github.io/Linux%E4%B8%8B%E5%AE%89%E8%A3%85JDK%E4%B8%8EMySQL/","excerpt":"引言重温记录下Linux环境下JDK和MySQL的安装。","text":"引言重温记录下Linux环境下JDK和MySQL的安装。 JDK的安装下载解压下载JDK压缩包，下载目录：http://www.oracle.com/technetwork/java/javase/downloads/index.html 解压 1tar -xvzf jdk-8u152-linux-x64.tar.gz 配置环境变量以root用户使用以下命令进入配置环境变量的profile文件。 1vim /etc/profile 在文件末尾加入以下内容并保存（注意修改JDK路径）。 1234# set java environment export JAVA_HOME=/usr/soft/jdk1.8.0_152export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 在命令行使用以下命令使环境变量生效。 1source /etc/profile 切换JDK版本当Linux中安装多个JDK时切换进行版本切换。 查看选择所有JDK。 1alternatives --config java 给jdk1.8.0_152设置序列号，输入以下命令（注意修改JDK目录）。 1alternatives --install /usr/bin/java java /usr/soft/jdk1.8.0_152 4 输入以下命令，选择JDK对应的数字，切换JDK版本。 1alternatives --config java MySQL的安装与卸载yum安装从Oracle官方网站下载Linux系统对应的MySQL的yum源包。地址：https://dev.mysql.com/downloads/repo/yum/ 把yum源包上传到linux，依次执行以下命令进行安装。 12yum localinstall mysql-community-release-el6-5.noarch.rpmyum install mysql-server 安装完成后启动MySQL 1service mysqld start 给root用户设置密码 1/usr/bin/mysqladmin -u root password &#x27;root&#x27; 进入MySQL后进行远程连接授权 1GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;root&#x27; WITH GRANT OPTION; 卸载查看MySQL的安装路径 1whereis mysql 查看mysql的安装包 1rpm -qa|grep mysql 卸载 1yum remove mysql 若卸载不完全，则要逐个卸载 1234rpm -qa|grep mysqlyum remove mysql-community-release-el6-5.noarchyum remove mysql-community-common-5.6.38-2.el6.x86_64yum remove mysql-community-libs-5.6.38-2.el6.x86_64 删除mysql的数据库文件 1rm -rf /var/lib/mysql/ 安装包离线安装下载MySQL离线安装包：https://dev.mysql.com/downloads/mysql/ 123456mv mysql-5.6.38-linux-glibc2.12-x86_64.tar.gz /usr/local/cd /usr/local/// 解压MySQL安装包tar -zxvf mysql-5.6.38-linux-glibc2.12-x86_64.tar.gz// 重命名mv mysql-5.6.38-linux-glibc2.12-x86_64 mysql 检查MySQL组和用户是否存在，如无创建 12345cat /etc/group | grep mysqlcat /etc/passwd | grep mysql// 如果没有则创建。useradd -r参数表示mysql用户是系统用户，不可用于登录系统groupadd mysqluseradd -r -g mysql mysql 分配用户和组 123456cd mysql// 更改mysql目录所属的用户(用户为mysql)chown -R mysql ../mysql/// -R是递归的意思，就是把mysql目录下的全部文件和子目录都设置为mysql用户和mysql组。chgrp -R mysql ../mysql/// 上面的做法是为了把mysql降权，以限定只能访问属于mysql用户的文件。 安装及初始化数据库（创建系统数据库的表） 1./scripts/mysql_install_db --user=mysql --basedir=/usr/local/mysql/ --datadir=/usr/local/mysql/data/ 配置MySQL数据库 12345678// 复制配置文件cp -a ./support-files/my-default.cnf /etc/my.cnf// 更改配置文件信息vi /etc/my.cnf// 加入以下内容# These are commonly set, remove the # and set as required.basedir = /usr/local/mysqldatadir = /usr/local/mysql/data 修改MySQL密码 123456// 启动MySQL./support-files/mysql.server start// 修改密码./bin/mysqladmin -u root -h localhost.localdomain password &#x27;root&#x27;// 进入MySQL./bin/mysql -h127.0.0.1 -uroot -proot 增加远程登录权限 12grant all privileges on *.* to root@&#x27;%&#x27; identified by &#x27;root&#x27;;flush privileges; 将MySQL加入Service系统服务 123456// 先退出MySQLcp support-files/mysql.server /etc/init.d/mysqldchkconfig --add mysqldchkconfig mysqld onservice mysqld restartservice mysqld status 到这里MySQL就配置完成了，剩下的就是优化MySQL，配置/etc/my.cnf啦！","categories":[{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"安装","slug":"Linux/安装","permalink":"https://mx-go.github.io/categories/Linux/%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"Linux下Tomcat的安装与优化","slug":"Linux下Tomcat的安装与优化","date":"2018-01-05T11:04:11.000Z","updated":"2021-05-05T09:31:54.838Z","comments":true,"path":"Linux下Tomcat的安装与优化/","link":"","permalink":"https://mx-go.github.io/Linux%E4%B8%8BTomcat%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BC%98%E5%8C%96/","excerpt":"引言Linux系统已经搁置很久了，之前有在Ubuntu系统上开发过，但是Linux已经很久没有用了。现在公司把项目部署在Linux系统上，又要把Linux相关知识温习一下。这篇博客温习一下Linux下Tomcat的部署与优化，大部分的操作与在windows上相同。","text":"引言Linux系统已经搁置很久了，之前有在Ubuntu系统上开发过，但是Linux已经很久没有用了。现在公司把项目部署在Linux系统上，又要把Linux相关知识温习一下。这篇博客温习一下Linux下Tomcat的部署与优化，大部分的操作与在windows上相同。 Tomcat的安装首先下载Tomcat的压缩包（apache-tomcat-7.0.82.tar.gz），下载地址为：https://tomcat.apache.org/download-70.cgi 将压缩包放到Linux预定目录下，执行tar的解压缩命令 12cd /usr/soft/tar -zxvf apache-tomcat-7.0.82.tar.gz 进入到apache-tomcat-7.0.82.tar.gz的bin目录下执行**./startup.sh** 命令即可启动Tomcat。 Tomcat的优化默认情况下Tomcat的配置适合开发模式或者比较小的系统应用，当访问量稍微多的时候比如1000人同时在线做一些频繁的业务操作的时候，可能性能方面就会存在问题，所以有必要在生产环境下对Tomcat做一些优化。 之前几篇文章也提到了Tomcat相关参数的设置与优化，Windows操作系统与Linux操作系统大同小异。 APR模式Tomcat 常用运行模式有3种，分别为 BIO，NIO，APR。生产环境建议用APR，从操作系统级别来解决异步的IO问题，大幅度的提高性能。Linux下需要另安装配置APR。 下载APR模式需要下载apr-1.6.3.tar.gz和apr-util-1.6.1.tar.gz两个文件，下载地址为：http://apr.apache.org/download.cgi 安装将连个文件放到合适的位置然后进行安装操作。 apr的安装依次执行，将安装路径设为/usr/local/apr 12345tar -zxvf apr-1.6.3.tar.gzcd apr-1.6.3.tar.gz./configure --prefix=/usr/local/aprmakemake install apr-util的安装12345tar -zxvf apr-util-1.6.1.tar.gzcd apr-util-1.6.1.tar.gz./configure --with-apr=/usr/local/apr/bin/apr-1-configmakemake install 安装tomcat-nativetomcat-native.tar.gz是Tomcat自带的压缩包，该文件在tomcat的bin目录下。 系统要先安装好JDK，我的JDK的安装目录为：/usr/soft/jdk1.8.0_152 123456cd /usr/soft/apache-tomcat-7.0.82/bin/tar -zxvf tomcat-native.tar.gzcd tomcat-native-1.2.14-src/java/org/apache/tomcat/jni/./configure --with-apr=/usr/local/apr/bin/apr-1-config --with-java-home=/usr/soft/jdk1.8.0_152makemake install 配置 编辑tomcat目录下文件bin/catalina.sh加载apr，在任意地方加入下面一行 1CATALINA_OPTS=&quot;$CATALINA_OPTS -Djava.library.path=/usr/local/apr/lib&quot; 编辑bin/catalina.sh配置JVM运行参数，注意引号不要忘记。 1JAVA_OPTS=&quot;-server -Xmx4g -Xms4g -Xmn1g -XX:PermSize=512M -XX:MaxPermSize=521M -XX:+DisableExplicitGC -XX:SurvivorRatio=3 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/soft/apache-tomcat-7.0.82 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:CMSInitiatingOccupancyFraction=65 -XX:+UseCMSInitiatingOccupancyOnly -XX:SoftRefLRUPolicyMSPerMB=0 -XX:+UseCMSCompactAtFullCollection -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintHeapAtGC -Xloggc:/usr/soft/jdk1.8.0_152/log/gc.log -Djava.awt.headless=true&quot; 编辑conf/server.xml使用apr运行模式 12345&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;200&quot; acceptCount=&quot;900&quot; enableLookups=&quot;false&quot; compression=&quot;on&quot; compressionMinSize=&quot;1024&quot; compressableMimeType=&quot;text/html,text/xml,text/css,text/javascript&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;UTF-8&quot; maxHttpHeaderSize=&quot;8192&quot;/&gt; 启动Tomcat 启动tomcat，查看tomcat日志文件，若出现如下信息则表明安装配置成功。 123456一月 05, 2018 2:03:09 下午 org.apache.coyote.AbstractProtocol init信息: Initializing ProtocolHandler [&quot;http-apr-8080&quot;]一月 05, 2018 2:03:09 下午 org.apache.coyote.AbstractProtocol init信息:: Initializing ProtocolHandler [&quot;ajp-apr-8009&quot;]一月 05, 2018 2:03:09 下午 org.apache.catalina.startup.Catalina load信息:: Initialization processed in 1471 ms 结语性能的影响因素是多方面的，互相影响，首先是系统本身没问题，数据库的响应没问题，web容器顺畅，硬件顺畅，网络带宽足够，再使用一些小工具进行检测，只有在大量用户在实际的生产环境中使用系统，才能发现问题，找到问题的根源到底是哪一块引发的性能瓶颈，调整一下自然一切都变得顺畅。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"安装","slug":"Linux/安装","permalink":"https://mx-go.github.io/categories/Linux/%E5%AE%89%E8%A3%85/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"tomcat","slug":"tomcat","permalink":"https://mx-go.github.io/tags/tomcat/"}]},{"title":"回顾过去 展望未来","slug":"回顾过去-展望未来","date":"2018-01-02T01:53:54.000Z","updated":"2021-05-05T03:16:31.180Z","comments":true,"path":"回顾过去-展望未来/","link":"","permalink":"https://mx-go.github.io/%E5%9B%9E%E9%A1%BE%E8%BF%87%E5%8E%BB-%E5%B1%95%E6%9C%9B%E6%9C%AA%E6%9D%A5/","excerpt":"时间过的可真的是快，转眼间到了2018年，今年的元旦没有出去跨年，而是在家里静静的等待着2018年的到来，不知道是欣喜还是忧郁。2017年我的年度目标只实现了90%，并没有完全达到期望。","text":"时间过的可真的是快，转眼间到了2018年，今年的元旦没有出去跨年，而是在家里静静的等待着2018年的到来，不知道是欣喜还是忧郁。2017年我的年度目标只实现了90%，并没有完全达到期望。 自己最近一年来特别不想熬夜，一熬夜第二天就感觉特别的累。这一年自己也学到了很多的东西，虽然感觉很累，但是觉得很开心。公司放假的安排也出来了，腊月二十四，放假立马就回家，又到了一年抢票的时间。几多欢喜几多愁啊。2018也是自己的本命年，加油！加油！","categories":[{"name":"生活","slug":"生活","permalink":"https://mx-go.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://mx-go.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"详解Tomcat连接池与连接数","slug":"详解Tomcat连接池与连接数","date":"2017-12-28T06:56:06.000Z","updated":"2021-05-05T03:35:41.812Z","comments":true,"path":"详解Tomcat连接池与连接数/","link":"","permalink":"https://mx-go.github.io/%E8%AF%A6%E8%A7%A3Tomcat%E8%BF%9E%E6%8E%A5%E6%B1%A0%E4%B8%8E%E8%BF%9E%E6%8E%A5%E6%95%B0/","excerpt":"引言在使用Tomcat时，经常会遇到连接数、线程数之类的配置，然后自己就去谷歌、百度，没有真正理解Tomcat配置的作用及当前业务环境、服务器配置等情况下Tomcat最优配置。 12345&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;200&quot; acceptCount=&quot;900&quot; enableLookups=&quot;false&quot; compression=&quot;on&quot; compressionMinSize=&quot;1024&quot; compressableMimeType=&quot;text/html,text/xml,text/css,text/javascript&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;UTF-8&quot; maxHttpHeaderSize=&quot;8192&quot;/&gt;","text":"引言在使用Tomcat时，经常会遇到连接数、线程数之类的配置，然后自己就去谷歌、百度，没有真正理解Tomcat配置的作用及当前业务环境、服务器配置等情况下Tomcat最优配置。 12345&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; connectionTimeout=&quot;20000&quot; maxThreads=&quot;1000&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;200&quot; acceptCount=&quot;900&quot; enableLookups=&quot;false&quot; compression=&quot;on&quot; compressionMinSize=&quot;1024&quot; compressableMimeType=&quot;text/html,text/xml,text/css,text/javascript&quot; redirectPort=&quot;8443&quot; URIEncoding=&quot;UTF-8&quot; maxHttpHeaderSize=&quot;8192&quot;/&gt; Tomcat连接器（Connector）上一篇文章说到过Tomcat的配置文件server.xml ：Connector的主要功能，是接收连接请求，创建Request和Response对象用于和请求端交换数据；然后分配线程让Engine（也就是Servlet容器）来处理这个请求，并把产生的Request和Response对象传给Engine。当Engine处理完请求后，也会通过Connector将响应返回给客户端。 可以说，Servlet容器处理请求，是需要Connector进行调度和控制的，Connector是Tomcat处理请求的主干，因此Connector的配置和使用对Tomcat的性能有着重要的影响。这篇文将从Connector入手，讨论一些与Connector有关的重要问题，包括NIO/BIO模式、线程池、连接数等。 根据协议的不同，Connector可以分为HTTP Connector、AJP Connector等，在这篇文章我们只讨论HTTP Connector。 BIO、NIO、APRConnector的protocalConnector在处理HTTP请求时，会使用不同的protocal。不同的Tomcat版本支持的protocal不同，其中最典型的protocol包括BIO、NIO和APR（Tomcat7中支持这3种，Tomcat8增加了对NIO2的支持，而到了Tomcat8.5和Tomcat9.0，则去掉了对BIO的支持）。 BIO是Blocking IO，顾名思义是阻塞的IO；NIO是Non-blocking IO，则是非阻塞的IO。而APR是Apache Portable Runtime，是Apache可移植运行库，利用本地库可以实现高可扩展性、高性能；Apr是在Tomcat上运行高并发应用的首选模式，但是需要安装apr、apr-utils、tomcat-native等包。 指定protocalConnector使用哪种protocol，可以通过**&lt;connector&gt;**元素中的protocol属性进行指定，也可以使用默认值。 指定的protocol取值及对应的协议如下： HTTP/1.1：默认值，使用的协议与Tomcat版本有关 org.apache.coyote.http11.Http11Protocol：BIO org.apache.coyote.http11.Http11NioProtocol：NIO org.apache.coyote.http11.Http11Nio2Protocol：NIO2 org.apache.coyote.http11.Http11AprProtocol：APR 如果没有指定protocol，则使用默认值HTTP/1.1，其含义如下：在Tomcat7中，自动选取使用BIO或APR（如果找到APR需要的本地库，则使用APR，否则使用BIO）；在Tomcat8中，自动选取使用NIO或APR（如果找到APR需要的本地库，则使用APR，否则使用NIO）。 BIO和NIO的不同无论是BIO，还是NIO，Connector处理请求的大致流程是一样的： 在accept队列中接收连接（当客户端向服务器发送请求时，如果客户端与OS完成三次握手建立了连接，则OS将该连接放入accept队列）；在连接中获取请求的数据，生成request；调用servlet容器处理请求；返回response。为了便于后面的说明，首先明确一下连接与请求的关系：连接是TCP层面的（传输层），对应socket；请求是HTTP层面的（应用层），必须依赖于TCP的连接实现；一个TCP连接中可能传输多个HTTP请求。 在BIO实现的Connector中，处理请求的主要实体是JIoEndpoint对象。JIoEndpoint维护了Acceptor和Worker：Acceptor接收socket，然后从Worker线程池中找出空闲的线程处理socket，如果worker线程池没有空闲线程，则Acceptor将阻塞。其中Worker是Tomcat自带的线程池，如果通过配置了其他线程池，原理与Worker类似。 在NIO实现的Connector中，处理请求的主要实体是NIoEndpoint对象。NIoEndpoint中除了包含Acceptor和Worker外，还是用了Poller，处理流程如下图所示 Acceptor接收socket后，不是直接使用Worker中的线程处理请求，而是先将请求发送给了Poller，而Poller是实现NIO的关键。Acceptor向Poller发送请求通过队列实现，使用了典型的生产者-消费者模式。在Poller中，维护了一个Selector对象；当Poller从队列中取出socket后，注册到该Selector中；然后通过遍历Selector，找出其中可读的socket，并使用Worker中的线程处理相应请求。与BIO类似，Worker也可以被自定义的线程池代替。 通过上述过程可以看出，在NIoEndpoint处理请求的过程中，无论是Acceptor接收socket，还是线程处理请求，使用的仍然是阻塞方式；但在“读取socket并交给Worker中的线程”的这个过程中，使用非阻塞的NIO实现，这是NIO模式与BIO模式的最主要区别（其他区别对性能影响较小，暂时略去不提）。而这个区别，在并发量较大的情形下可以带来Tomcat效率的显著提升： 目前大多数HTTP请求使用的是长连接（HTTP/1.1默认keep-alive为true），而长连接意味着，一个TCP的socket在当前请求结束后，如果没有新的请求到来，socket不会立马释放，而是等timeout后再释放。如果使用BIO，“读取socket并交给Worker中的线程”这个过程是阻塞的，也就意味着在socket等待下一个请求或等待释放的过程中，处理这个socket的工作线程会一直被占用，无法释放；因此Tomcat可以同时处理的socket数目不能超过最大线程数，性能受到了极大限制。而使用NIO，“读取socket并交给Worker中的线程”这个过程是非阻塞的，当socket在等待下一个请求或等待释放时，并不会占用工作线程，因此Tomcat可以同时处理的socket数目远大于最大线程数，并发性能大大提高。 acceptCount、maxConnections、maxThreads参数Tomcat处理请求的过程：在accept队列中接收连接（当客户端向服务器发送请求时，如果客户端与OS完成三次握手建立了连接，则OS将该连接放入accept队列）；在连接中获取请求的数据，生成request；调用servlet容器处理请求；返回response。 相对应的，Connector中的几个参数功能如下： acceptCountaccept队列的长度；当accept队列中连接的个数达到acceptCount时，队列满，进来的请求一律被拒绝。默认值是100。 maxConnectionsTomcat在任意时刻接收和处理的最大连接数。当Tomcat接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomcat接收的连接数小于maxConnections。如果设置为-1，则连接数不受限制。 默认值与连接器使用的协议有关：NIO的默认值是10000，APR/native的默认值是8192，而BIO的默认值为maxThreads（如果配置了Executor，则默认值是Executor的maxThreads）。 在windows下，APR/native的maxConnections值会自动调整为设置值以下最大的1024的整数倍；如设置为2000，则最大值实际是1024。 maxThreads请求处理线程的最大数量。默认值是200（Tomcat7和8都是的）。如果该Connector绑定了Executor，这个值会被忽略，因为该Connector将使用绑定的Executor，而不是内置的线程池来执行任务。 maxThreads规定的是最大的线程数目，并不是实际running的CPU数量；实际上，maxThreads的大小比CPU核心数量要大得多。这是因为，处理请求的线程真正用于计算的时间可能很少，大多数时间可能在阻塞，如等待数据库返回数据、等待硬盘读写数据等。因此，在某一时刻，只有少数的线程真正的在使用物理CPU，大多数线程都在等待；因此线程数远大于物理核心数才是合理的。 换句话说，Tomcat通过使用比CPU核心数量多得多的线程数，可以使CPU忙碌起来，大大提高CPU的利用率。 参数设置 maxThreads的设置既与应用的特点有关，也与服务器的CPU核心数量有关。通过前面介绍可以知道，maxThreads数量应该远大于CPU核心数量；而且CPU核心数越大，maxThreads应该越大；应用中CPU越不密集（IO越密集），maxThreads应该越大，以便能够充分利用CPU。当然，maxThreads的值并不是越大越好，如果maxThreads过大，那么CPU会花费大量的时间用于线程的切换，整体效率会降低。 maxConnections的设置与Tomcat的运行模式有关。如果tomcat使用的是BIO，那么maxConnections的值应该与maxThreads一致；如果tomcat使用的是NIO，那么类似于Tomcat的默认值，maxConnections值应该远大于maxThreads。 通过前面的介绍可以知道，虽然tomcat同时可以处理的连接数目是maxConnections，但服务器中可以同时接收的连接数为maxConnections+acceptCount 。acceptCount的设置，与应用在连接过高情况下希望做出什么反应有关系。如果设置过大，后面进入的请求等待时间会很长；如果设置过小，后面进入的请求立马返回connection refused。 线程池ExecutorExecutor元素代表Tomcat中的线程池，可以由其他组件共享使用；要使用该线程池，组件需要通过Executor属性指定该线程池。 Executor是Service元素的内嵌元素。一般来说，使用线程池的是Connector组件；为了使Connector能使用线程池，Executor元素应该放在Connector前面。Executor与Connector的配置举例如下： 123&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix =&quot;catalina-exec-&quot; maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot; /&gt;&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; acceptCount=&quot;1000&quot; /&gt; Executor的主要属性包括： name：该线程池的标记 maxThreads：线程池中最大活跃线程数，默认值200（Tomcat7和8都是） minSpareThreads：线程池中保持的最小线程数，最小值是25 maxIdleTime：线程空闲的最大时间，当空闲超过该值时关闭线程（除非线程数小于minSpareThreads），单位是ms，默认值60000（1分钟） daemon：是否后台线程，默认值true threadPriority：线程优先级，默认值5 namePrefix：线程名字的前缀，线程池中线程名字为：namePrefix+线程编号 查看当前状态上面介绍了Tomcat连接数、线程数的概念以及如何设置，下面说明如何查看服务器中的连接数和线程数。 查看服务器的状态，大致分为两种方案： jconsole工具现成的工具，如JDK自带的jconsole工具可以方便的查看线程信息（此外还可以查看CPU、内存、类、JVM基本信息等），Tomcat自带的manager，收费工具New Relic等。下图是jconsole查看线程信息的界面： Linux命令查看假设Tomcat接收http请求的端口是8083，则可以使用如下语句查看连接情况： 1netstat –nat|grep 8080 结果如下所示： 可以看出，有一个连接处于listen状态，监听请求；除此之外，还有6个已经建立的连接（ESTABLISHED）和0个等待关闭的连接（CLOSE_WAIT）。 原文： https://mp.weixin.qq.com/s?__biz=MjM5NzMyMjAwMA==&amp;mid=2651479428&amp;idx=1&amp;sn=791fed1205da057aba77655aaac9d841&amp;chksm=bd2531fb8a52b8ed0066a8efc76d031ffb6e0d2099fb342129c307f78b4bf0581cbf3bbcb058&amp;mpshare=1&amp;scene=1&amp;srcid=1114Osu1mhmfSobleuByFbEC#rd","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"tomcat","slug":"tomcat","permalink":"https://mx-go.github.io/tags/tomcat/"}]},{"title":"Tomcat入门","slug":"tomcat入门","date":"2017-12-20T06:35:32.000Z","updated":"2021-05-05T03:31:12.098Z","comments":true,"path":"tomcat入门/","link":"","permalink":"https://mx-go.github.io/tomcat%E5%85%A5%E9%97%A8/","excerpt":"引言Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器。说是经常用到，也只是熟悉，还没没有真正达到了解其中的原理和其中配置的意义，最近也找了一些书籍来看，先入门。","text":"引言Tomcat 服务器是一个免费的开放源代码的Web 应用服务器，属于轻量级应用服务器。说是经常用到，也只是熟悉，还没没有真正达到了解其中的原理和其中配置的意义，最近也找了一些书籍来看，先入门。 Tomcat简介Tomcat的下载包解压之后的目录 Tomcat根目录在Tomcat中叫&lt;CATALINA_HOME&gt; &lt;CATALINA_HOME&gt;/bin：存放各种平台下启动和关闭Tomcat的脚本文件。其中有个是catalina.bat，打开这个windows配置文件，在非注释行加入JDK路径,例如 : SET JAVA_HOME=C:\\Program Files\\Java\\jdk1.8.0_141，其中对JDK的优化也在catalina.bat中配置，保存后就配置好Tomcat环境了。 startup.bat是windows下启动Tomcat的脚本文件，shutdown.bat是关闭Tomcat的脚本文件。 &lt;CATALINA_HOME&gt;/conf：存放不同的配置文件（如：server.xml和web.xml） server.xml文件：该文件用于配置和server相关的信息，比如tomcat启动的端口号、配置host主机、配置Context，接下来会重点讲述。 web.xml文件：部署描述文件，这个web.xml中描述了一些默认的servlet，部署每个webapp时，都会调用这个文件，配置该web应用的默认servlet。 tomcat-users.xml文件：配置tomcat的用户密码与权限。 context.xml：定义web应用的默认行为。&lt;CATALINA_HOME&gt;/lib：存放Tomcat运行需要的库文件（Jars）；&lt;CATALINA_HOME&gt;/logs：存放Tomcat执行时的log文件；&lt;CATALINA_HOME&gt;/temp： 存放Tomcat运行时产生的文件，如缓存等；&lt;CATALINA_HOME&gt;/webapps：Tomcat的主要Web发布目录（包括应用程序示例）； &lt;CATALINA_HOME&gt;/work：存放jsp编译后产生的class文件； 【Tomcat的启动过程】Tomcat 先根据**/conf/server.xml** 下的配置启动Server，再加载Service，对于与Engine相匹配的Host，每个Host 下面都有一个或多个Context。 注意：Context 既可配置在server.xml 下，也可配置成一单独的文件，放在conf\\Catalina\\localhost 下，简称应用配置文件。 Web Application 对应一个Context，每个Web Application 由一个或多个Servlet 组成。当一个Web Application 被初始化的时候，它将用自己的ClassLoader 对象载入部署配置文件web.xml 中定义的每个Servlet 类：它首先载入在$CATALINA_HOME/conf/web.xml中部署的Servlet 类，然后载入在自己的Web Application 根目录下WEB-INF/web.xml 中部署的Servlet 类。 web.xml 文件有两部分：Servlet 类定义和Servlet 映射定义。每个被载入的Servlet 类都有一个名字，且被填入该Context 的映射表(mapping table)中，和某种URL 路径对应。当该Context 获得请求时，将查询mapping table，找到被请求的Servlet，并执行以获得请求响应。 Tomcat一个server实例12345678910111213141516171819202122232425262728293031&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; server.xml文档的元素分类和整体结构整体结构server.xml的整体结构如下： 1234567891011&lt;Server&gt; &lt;Service&gt; &lt;Connector/&gt; &lt;Connector/&gt; &lt;Engine&gt; &lt;Host&gt; &lt;Context/&gt;&lt;!-- 现在常常使用自动部署，不推荐配置Context元素，Context小节有详细说明 --&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 该结构中只给出了Tomcat的核心组件，除了核心组件外，Tomcat还有一些其他组件，下面介绍一下组件的分类。 元素分类server.xml文件中的元素可以分为以下4类： （1）顶层元素：&lt;Server&gt;和&lt;Service&gt; &lt;Server&gt;元素是整个配置文件的根元素，&lt;Service&gt;元素则代表一个Engine元素以及一组与之相连的Connector元素。 （2）连接器：&lt;Connector&gt; &lt;Connector&gt;代表了外部客户端发送请求到特定Service的接口；同时也是外部客户端从特定Service接收响应的接口。 （3）容器：&lt;Engine&gt;&lt;Host&gt;&lt;Context&gt; 容器的功能是处理Connector接收进来的请求，并产生相应的响应。Engine、Host和Context都是容器，但它们不是平行的关系，而是父子关系：Engine包含Host，Host包含Context。一个Engine组件可以处理Service中的所有请求，一个Host组件可以处理发向一个特定虚拟主机的所有请求，一个Context组件可以处理一个特定Web应用的所有请求。 （4）内嵌组件：可以内嵌到容器中的组件。实际上，Server、Service、Connector、Engine、Host和Context是最重要的最核心的Tomcat组件，其他组件都可以归为内嵌组件。 核心组件1、Server Server元素在最顶层，代表整个Tomcat容器，因此它必须是server.xml中唯一一个最外层的元素。一个Server元素中可以有一个或多个Service元素。 在第一部分的例子中，在最外层有一个&lt;Server&gt;元素，shutdown属性表示关闭Server的指令；port属性表示Server接收shutdown指令的端口号，设为-1可以禁掉该端口。 Server的主要任务，就是提供一个接口让客户端能够访问到这个Service集合，同时维护它所包含的所有的Service的声明周期，包括如何初始化、如何结束服务、如何找到客户端要访问的Service。 2、Service Service的作用，是在Connector和Engine外面包了一层，把它们组装在一起，对外提供服务。一个Service可以包含多个Connector，但是只能包含一个Engine；其中Connector的作用是从客户端接收请求，Engine的作用是处理接收进来的请求。 在第一部分的例子中，Server中包含一个名称为“Catalina”的Service。实际上，Tomcat可以提供多个Service，不同的Service监听不同的端口。 3、Connector Connector的主要功能，是接收连接请求，创建Request和Response对象用于和请求端交换数据；然后分配线程让Engine来处理这个请求，并把产生的Request和Response对象传给Engine。 通过配置Connector，可以控制请求Service的协议及端口号。在第一部分的例子中，Service包含两个Connector： &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; （1）通过配置第1个Connector，客户端可以通过8080端口号使用http协议访问Tomcat。其中，protocol属性规定了请求的协议，port规定了请求的端口号，redirectPort表示当强制要求https而请求是http时，重定向至端口号为8443的Connector，connectionTimeout表示连接的超时时间。 在这个例子中，Tomcat监听HTTP请求，使用的是8080端口，而不是正式的80端口；实际上，在正式的生产环境中，Tomcat也常常监听8080端口，而不是80端口。这是因为在生产环境中，很少将Tomcat直接对外开放接收请求，而是在Tomcat和客户端之间加一层代理服务器(如nginx)，用于请求的转发、负载均衡、处理静态文件等；通过代理服务器访问Tomcat时，是在局域网中，因此一般仍使用8080端口。 （2）通过配置第2个Connector，客户端可以通过8009端口号使用AJP协议访问Tomcat。AJP协议负责和其他的HTTP服务器(如Apache)建立连接；在把Tomcat与其他HTTP服务器集成时，就需要用到这个连接器。之所以使用Tomcat和其他服务器集成，是因为Tomcat可以用作Servlet/JSP容器，但是对静态资源的处理速度较慢，不如Apache和IIS等HTTP服务器；因此常常将Tomcat与Apache等集成，前者作Servlet容器，后者处理静态资源，而AJP协议便负责Tomcat和Apache的连接。Tomcat与Apache等集成的原理如下图： 4、Engine Engine组件在Service组件中有且只有一个；Engine是Service组件中的请求处理组件。Engine组件从一个或多个Connector中接收请求并处理，并将完成的响应返回给Connector，最终传递给客户端。 前面已经提到过，Engine、Host和Context都是容器，但它们不是平行的关系，而是父子关系：Engine包含Host，Host包含Context。 在第一部分的例子中，Engine的配置语句如下： &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; 其中，name属性用于日志和错误信息，在整个Server中应该唯一。defaultHost属性指定了默认的host名称，当发往本机的请求指定的host名称不存在时，一律使用defaultHost指定的host进行处理；因此，defaultHost的值，必须与Engine中的一个Host组件的name属性值匹配。 5、Host （1）Engine与Host Host是Engine的子容器。Engine组件中可以内嵌1个或多个Host组件，每个Host组件代表Engine中的一个虚拟主机。Host组件至少有一个，且其中一个的name必须与Engine组件的defaultHost属性相匹配。 （2）Host的作用 Host虚拟主机的作用，是运行多个Web应用（一个Context代表一个Web应用），并负责安装、展开、启动和结束每个Web应用。 Host组件代表的虚拟主机，对应了服务器中一个网络名实体(如”www.test.com”，或IP地址”116.25.25.25”)；为了使用户可以通过网络名连接Tomcat服务器，这个名字应该在DNS服务器上注册。 客户端通常使用主机名来标识它们希望连接的服务器；该主机名也会包含在HTTP请求头中。Tomcat从HTTP头中提取出主机名，寻找名称匹配的主机。如果没有匹配，请求将发送至默认主机。因此默认主机不需要是在DNS服务器中注册的网络名，因为任何与所有Host名称不匹配的请求，都会路由至默认主机。 （3）Host的配置 在第一部分的例子中，Host的配置如下： &lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; 下面对其中配置的属性进行说明： name属性指定虚拟主机的主机名，一个Engine中有且仅有一个Host组件的name属性与Engine组件的defaultHost属性相匹配；一般情况下，主机名需要是在DNS服务器中注册的网络名，但是Engine指定的defaultHost不需要，原因在前面已经说明。 unpackWARs指定了是否将代表Web应用的WAR文件解压；如果为true，通过解压后的文件结构运行该Web应用，如果为false，直接使用WAR文件运行Web应用。 Host的autoDeploy和appBase属性，与Host内Web应用的自动部署有关；此外，本例中没有出现的xmlBase和deployOnStartup属性，也与Web应用的自动部署有关。 6、Context （1）Context的作用 Context元素代表在特定虚拟主机上运行的一个Web应用。在后文中，提到Context、应用或Web应用，它们指代的都是Web应用。每个Web应用基于WAR文件，或WAR文件解压后对应的目录（这里称为应用目录）。 Context是Host的子容器，每个Host中可以定义任意多的Context元素。 在第一部分的例子中，可以看到server.xml配置文件中并没有出现Context元素的配置。这是因为，Tomcat开启了自动部署，Web应用没有在server.xml中配置静态部署，而是由Tomcat通过特定的规则自动部署。下面介绍一下Tomcat自动部署Web应用的机制。 （2）Web应用自动部署 Host的配置 要开启Web应用的自动部署，需要配置所在的虚拟主机；配置的方式就是前面提到的Host元素的deployOnStartup和autoDeploy属性。如果deployOnStartup和autoDeploy设置为true，则tomcat启动自动部署：当检测到新的Web应用或Web应用的更新时，会触发应用的部署(或重新部署)。二者的主要区别在于，deployOnStartup为true时，Tomcat在启动时检查Web应用，且检测到的所有Web应用视作新应用；autoDeploy为true时，Tomcat在运行时定期检查新的Web应用或Web应用的更新。除此之外，二者的处理相似。 通过配置deployOnStartup和autoDeploy可以开启虚拟主机自动部署Web应用；实际上，自动部署依赖于检查是否有新的或更改过的Web应用，而Host元素的appBase和xmlBase设置了检查Web应用更新的目录。 其中，appBase属性指定Web应用所在的目录，默认值是webapps，这是一个相对路径，代表Tomcat根目录下webapps文件夹。 xmlBase属性指定Web应用的XML配置文件所在的目录，默认值为conf/&lt;engine_name&gt;/&lt;host_name&gt;，例如第一部分的例子中，主机localhost的xmlBase的默认值是$TOMCAT_HOME/conf/Catalina/localhost。 检查Web应用更新 一个Web应用可能包括以下文件：XML配置文件，WAR包，以及一个应用目录(该目录包含Web应用的文件结构)；其中XML配置文件位于xmlBase指定的目录，WAR包和应用目录位于appBase指定的目录。 Tomcat按照如下的顺序进行扫描，来检查应用更新： A、扫描虚拟主机指定的xmlBase下的XML配置文件 B、扫描虚拟主机指定的appBase下的WAR文件 C、扫描虚拟主机指定的appBase下的应用目录 &lt;Context&gt;元素的配置 Context元素最重要的属性是docBase和path，此外reloadable属性也比较常用。 docBase指定了该Web应用使用的WAR包路径，或应用目录。需要注意的是，在自动部署场景下(配置文件位于xmlBase中)，docBase不在appBase目录中，才需要指定；如果docBase指定的WAR包或应用目录就在docBase中，则不需要指定，因为Tomcat会自动扫描appBase中的WAR包和应用目录，指定了反而会造成问题。 path指定了访问该Web应用的上下文路径，当请求到来时，Tomcat根据Web应用的 path属性与URI的匹配程度来选择Web应用处理相应请求。例如，Web应用app1的path属性是”/app1”，Web应用app2的path属性是”/app2”，那么请求/app1/index.html会交由app1来处理；而请求/app2/index.html会交由app2来处理。如果一个Context元素的path属性为””，那么这个Context是虚拟主机的默认Web应用；当请求的uri与所有的path都不匹配时，使用该默认Web应用来处理。 但是，需要注意的是，在自动部署场景下(配置文件位于xmlBase中)，不能指定path属性，path属性由配置文件的文件名、WAR文件的文件名或应用目录的名称自动推导出来。如扫描Web应用时，发现了xmlBase目录下的app1.xml，或appBase目录下的app1.WAR或app1应用目录，则该Web应用的path属性是”app1”。如果名称不是app1而是ROOT，则该Web应用是虚拟主机默认的Web应用，此时path属性推导为””。 reloadable属性指示tomcat是否在运行时监控在WEB-INF/classes和WEB-INF/lib目录下class文件的改动。如果值为true，那么当class文件改动时，会触发Web应用的重新加载。在开发环境下，reloadable设置为true便于调试；但是在生产环境中设置为true会给服务器带来性能压力，因此reloadable参数的默认值为false。 下面来看自动部署时，xmlBase下的XML配置文件app1.xml的例子： &lt;Context docBase=&quot;D:\\Program Files\\app1.war&quot; reloadable=&quot;true&quot;/&gt; 在该例子中，docBase位于Host的appBase目录之外；path属性没有指定，而是根据app1.xml自动推导为”app1”；由于是在开发环境下，因此reloadable设置为true，便于开发调试。 自动部署举例 最典型的自动部署，就是当我们安装完Tomcat后，$TOMCAT_HOME/webapps目录下有如下文件夹： 当我们启动Tomcat后，可以使用http://localhost:8080/来访问Tomcat，其实访问的就是ROOT对应的Web应用；我们也可以通过http://localhost:8080/docs来访问docs应用，同理我们可以访问examples/host-manager/manager这几个Web应用。 （3）server.xml中静态部署Web应用 除了自动部署，我们也可以在server.xml中通过&lt;context&gt;元素静态部署Web应用。静态部署与自动部署是可以共存的。在实际应用中，并不推荐使用静态部署，因为server.xml 是不可动态重加载的资源，服务器一旦启动了以后，要修改这个文件，就得重启服务器才能重新加载。而自动部署可以在Tomcat运行时通过定期的扫描来实现，不需要重启服务器。 server.xml中使用Context元素配置Web应用，Context元素应该位于Host元素中。举例如下： &lt;Context path=&quot;/&quot; docBase=&quot;D:\\Program Files \\app1.war&quot; reloadable=&quot;true&quot;/&gt; docBase：静态部署时，docBase可以在appBase目录下，也可以不在；本例中，docBase不在appBase目录下。 path：静态部署时，可以显式指定path属性，但是仍然受到了严格的限制：只有当自动部署完全关闭(deployOnStartup和autoDeploy都为false)或docBase不在appBase中时，才可以设置path属性。在本例中，docBase不在appBase中，因此path属性可以设置。 reloadable属性的用法与自动部署时相同。 核心组件的关联1、整体关系 核心组件之间的整体关系，在上一部分有所介绍，这里总结一下： Server元素在最顶层，代表整个Tomcat容器；一个Server元素中可以有一个或多个Service元素。 Service在Connector和Engine外面包了一层，把它们组装在一起，对外提供服务。一个Service可以包含多个Connector，但是只能包含一个Engine；Connector接收请求，Engine处理请求。 Engine、Host和Context都是容器，且 Engine包含Host，Host包含Context。每个Host组件代表Engine中的一个虚拟主机；每个Context组件代表在特定Host上运行的一个Web应用。 2、如何确定请求由谁处理？ 当请求被发送到Tomcat所在的主机时，如何确定最终哪个Web应用来处理该请求呢？ （1）根据协议和端口号选定Service和Engine Service中的Connector组件可以接收特定端口的请求，因此，当Tomcat启动时，Service组件就会监听特定的端口。在第一部分的例子中，Catalina这个Service监听了8080端口（基于HTTP协议）和8009端口（基于AJP协议）。当请求进来时，Tomcat便可以根据协议和端口号选定处理请求的Service；Service一旦选定，Engine也就确定。 通过在Server中配置多个Service，可以实现通过不同的端口号来访问同一台机器上部署的不同应用。 （2）根据域名或IP地址选定Host Service确定后，Tomcat在Service中寻找名称与域名/IP地址匹配的Host处理该请求。如果没有找到，则使用Engine中指定的defaultHost来处理该请求。在第一部分的例子中，由于只有一个Host（name属性为localhost），因此该Service/Engine的所有请求都交给该Host处理。 （3）根据URI选定Context/Web应用 这一点在Context一节有详细的说明：Tomcat根据应用的 path属性与URI的匹配程度来选择Web应用处理相应请求，这里不再赘述。 （4）举例 以请求http://localhost:8080/app1/index.html为例，首先通过协议和端口号（http和8080）选定Service；然后通过主机名（localhost）选定Host；然后通过uri（/app1/index.html）选定Web应用。 3、如何配置多个服务 通过在Server中配置多个Service服务，可以实现通过不同的端口号来访问同一台机器上部署的不同Web应用。 在server.xml中配置多服务的方法非常简单，分为以下几步： （1）复制&lt;Service&gt;元素，放在当前&lt;Service&gt;后面。 （2）修改端口号：根据需要监听的端口号修改&lt;Connector&gt;元素的port属性；必须确保该端口没有被其他进程占用，否则Tomcat启动时会报错，而无法通过该端口访问Web应用。 以Win7为例，可以用如下方法找出某个端口是否被其他进程占用：netstat -aon|findstr “8081″发现8081端口被PID为2064的进程占用，tasklist |findstr “2064″发现该进程为FrameworkService.exe(这是McAfee杀毒软件的进程)。 （3）修改Service和Engine的name属性 （4）修改Host的appBase属性（如webapps2） （5）Web应用仍然使用自动部署 （6）将要部署的Web应用(WAR包或应用目录)拷贝到新的appBase下。 以第一部分的server.xml为例，多个Service的配置如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=&#x27;1.0&#x27; encoding=&#x27;utf-8&#x27;?&gt;&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt; &lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt; &lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name=&quot;Catalina&quot;&gt; &lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;/opt/project/webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt; &lt;Service name=&quot;Catalina2&quot;&gt; &lt;Connector port=&quot;8084&quot; protocol=&quot;HTTP/1.1&quot; connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Connector port=&quot;8010&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; &lt;Engine name=&quot;Catalina2&quot; defaultHost=&quot;localhost&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt; &lt;/Realm&gt; &lt;Host name=&quot;localhost&quot; appBase=&quot;/opt/project/webapps2&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; &lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 再将原webapps下的docs目录拷贝到webapps2中，则通过如下两个接口都可以访问docs应用： http://localhost:8080/docs/ http://localhost:8084/docs/ 其他组件除核心组件外，server.xml中还可以配置很多其他组件。下面只介绍第一部分例子中出现的组件，如果要了解更多内容，可以查看Tomcat官方文档。 1、Listener 123456&lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.core.JasperListener&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt; Listener(即监听器)定义的组件，可以在特定事件发生时执行特定的操作；被监听的事件通常是Tomcat的启动和停止。 监听器可以在Server、Engine、Host或Context中，本例中的监听器都是在Server中。实际上，本例中定义的6个监听器，都只能存在于Server组件中。监听器不允许内嵌其他组件。 监听器需要配置的最重要的属性是className，该属性规定了监听器的具体实现类，该类必须实现了org.apache.catalina.LifecycleListener接口。 下面依次介绍例子中配置的监听器： VersionLoggerListener：当Tomcat启动时，该监听器记录Tomcat、Java和操作系统的信息。该监听器必须是配置的第一个监听器。 AprLifecycleListener：Tomcat启动时，检查APR库，如果存在则加载。APR，即Apache Portable Runtime，是Apache可移植运行库，可以实现高可扩展性、高性能，以及与本地服务器技术更好的集成。 JasperListener：在Web应用启动之前初始化Jasper，Jasper是JSP引擎，把JVM不认识的JSP文件解析成java文件，然后编译成class文件供JVM使用。 JreMemoryLeakPreventionListener：与类加载器导致的内存泄露有关。 GlobalResourcesLifecycleListener：通过该监听器，初始化&lt; GlobalNamingResources&gt;标签中定义的全局JNDI资源；如果没有该监听器，任何全局资源都不能使用。&lt; GlobalNamingResources&gt;将在后文介绍。 ThreadLocalLeakPreventionListener：当Web应用因thread-local导致的内存泄露而要停止时，该监听器会触发线程池中线程的更新。当线程执行完任务被收回线程池时，活跃线程会一个一个的更新。只有当Web应用(即Context元素)的renewThreadsWhenStoppingContext属性设置为true时，该监听器才有效。 2、GlobalNamingResources与Realm 第一部分的例子中，Engine组件下定义了Realm组件： 1234&lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt; &lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot; resourceName=&quot;UserDatabase&quot;/&gt;&lt;/Realm&gt; Realm，可以把它理解成“域”；Realm提供了一种用户密码与web应用的映射关系，从而达到角色安全管理的作用。在本例中，Realm的配置使用name为UserDatabase的资源实现。而该资源在Server元素中使用GlobalNamingResources配置： 123&lt;GlobalNamingResources&gt; &lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot; type=&quot;org.apache.catalina.UserDatabase&quot; description=&quot;User database that can be updated and saved&quot; factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot; pathname=&quot;conf/tomcat-users.xml&quot; /&gt;&lt;/GlobalNamingResources&gt; 3、Valve 在第一部分的例子中，Host元素内定义了Valve组件： 1&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot; prefix=&quot;localhost_access_log.&quot; suffix=&quot;.txt&quot; pattern=&quot;%h %l %u %t &amp;quot;%r&amp;quot; %s %b&quot; /&gt; 单词Valve的意思是“阀门”，在Tomcat中代表了请求处理流水线上的一个组件；Valve可以与Tomcat的容器(Engine、Host或Context)关联。 不同的Valve有不同的特性，下面介绍一下本例中出现的AccessLogValve。 AccessLogValve的作用是通过日志记录其所在的容器中处理的所有请求，在本例中，Valve放在Host下，便可以记录该Host处理的所有请求。AccessLogValve记录的日志就是访问日志，每天的请求会写到一个日志文件里。AccessLogValve可以与Engine、Host或Context关联；在本例中，只有一个Engine，Engine下只有一个Host，Host下只有一个Context，因此AccessLogValve放在三个容器下的作用其实是类似的。 本例的AccessLogValve属性的配置，使用的是默认的配置；下面介绍AccessLogValve中各个属性的作用： （1）className：规定了Valve的类型，是最重要的属性；本例中，通过该属性规定了这是一个AccessLogValve。 （2）directory：指定日志存储的位置，本例中，日志存储在$TOMCAT_HOME/logs目录下。 （3）prefix：指定了日志文件的前缀。 （4）suffix：指定了日志文件的后缀。通过directory、prefix和suffix的配置，在$TOMCAT_HOME/logs目录下，可以看到如下所示的日志文件。 （5）pattern：指定记录日志的格式，本例中各项的含义如下： %h：远程主机名或IP地址；如果有nginx等反向代理服务器进行请求分发，该主机名/IP地址代表的是nginx，否则代表的是客户端。后面远程的含义与之类似，不再解释。 %l：远程逻辑用户名，一律是”-”，可以忽略。 %u：授权的远程用户名，如果没有，则是”-”。 %t：访问的时间。 %r：请求的第一行，即请求方法(get/post等)、uri、及协议。 %s：响应状态，200,404等等。 %b：响应的数据量，不包括请求头，如果为0，则是””-。 例如，下面是访问日志中的一条记录 pattern的配置中，除了上述各项，还有一个非常常用的选项是%D，含义是请求处理的时间(单位是毫秒)，对于统计分析请求的处理速度帮助很大。 开发人员可以充分利用访问日志，来分析问题、优化应用。例如，分析访问日志中各个接口被访问的比例，不仅可以为需求和运营人员提供数据支持，还可以使自己的优化有的放矢；分析访问日志中各个请求的响应状态码，可以知道服务器请求的成功率，并找出有问题的请求；分析访问日志中各个请求的响应时间，可以找出慢请求，并根据需要进行响应时间的优化。 参考文档 Tomcat官方文档 《How Tomcat Works》 《深入分析Java Web技术内幕》 详解 Tomcat 配置文件 server.xml","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"https://mx-go.github.io/tags/tomcat/"}]},{"title":"JVM类加载机制","slug":"JVM类加载机制","date":"2017-12-13T02:03:36.000Z","updated":"2021-05-10T15:12:42.798Z","comments":true,"path":"JVM类加载机制/","link":"","permalink":"https://mx-go.github.io/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"引言之前的博客说了Java虚拟机的运行时数据区域、GC算法、垃圾回收器等知识。距离深入了解还有一段距离，包括虚拟机的类加载机制、性能调优、线程并发等等还都没有涉及到，一直在看周志明的《深入理解Java虚拟机》，越深入去读发现这本书写的真的是经典，解决了自己很多的疑惑。 JVM的类加载机制。虚拟机把描述类的数据从class文件加载到内存中，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。","text":"引言之前的博客说了Java虚拟机的运行时数据区域、GC算法、垃圾回收器等知识。距离深入了解还有一段距离，包括虚拟机的类加载机制、性能调优、线程并发等等还都没有涉及到，一直在看周志明的《深入理解Java虚拟机》，越深入去读发现这本书写的真的是经典，解决了自己很多的疑惑。 JVM的类加载机制。虚拟机把描述类的数据从class文件加载到内存中，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 类加载过程类被加载到虚拟机内存中开始，到卸载出内存为止。它的生命周期分7个阶段，加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）、卸载（Unloading）。其中验证、准备、解析三个部分统称为连接（Linking）。 ## 加载 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 1注意：JVM中的ClassLoader类加载器加载Class发生在此阶段。后面会有描述。 连接验证验证的目的是为了确保Class文件中的字节流包含的信息符合当前虚拟机的要求，而且不会危害虚拟机自身的安全。不同的虚拟机对类验证的实现可能会有所不同，但大致都会完成以下四个阶段的验证：文件格式的验证、元数据的验证、字节码验证和符号引用验证。 文件格式验证 主要验证字节流是否符合calss文件格式的规范，如果符合则把字节流加载到方法区中进行存储。 验证文件头、主次版本等等。 元数据验证主要对字节码描述的信息进行语义分析，保证其描述符合Java语言的要求。 类是否有父类。 是否继承了不允许被继承的类（final修饰过的类）。 如果这个类不是抽象类，是否实现其父类或接口中所有要求实现的方法。 类中的字段、方法是否与父类产生矛盾（如：覆盖父类final类型的字段，或者不符合个则的方法）。 字节码验证该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。 符号引用验证 符号引用中通过字符串描述的全限定名是否能找到对应的类。 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段。 符号引用中的类、字段、方法的访问性（private、protected、public、default）是否可被当前类访问。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意： 1、这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 ​ 2、这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。 假设一个类变量的定义为：public static int value = 3； 那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的putstatic指令是在程序编译后，存放于类构造器（）方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。 下表列出了Java中所有基本数据类型以及reference类型的默认零值： 12注意：只设置类中的静态变量（方法区中），不包括实例变量（堆内存中），实例变量是在对象实例化的时候初始化分配值的。 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 类或接口的解析：判断所要转化成的直接引用是对数组类型，还是普通的对象类型的引用，从而进行不同的解析。 字段解析：对字段进行解析时，会先在本类中查找是否包含有简单名称和字段描述符都与目标相匹配的字段，如果有，则查找结束；如果没有，则会按照继承关系从上往下递归搜索该类所实现的各个接口和它们的父接口，还没有，则按照继承关系从上往下递归搜索其父类，直至查找结束。 类方法解析：对类方法的解析与对字段解析的搜索步骤差不多，只是多了判断该方法所处的是类还是接口的步骤，而且对类方法的匹配搜索，是先搜索父类，再搜索接口。 接口方法解析：与类方法解析步骤类似，只是接口不会有父类，因此，只递归向上搜索父接口就行了。 初始化初始化是类加载过程的最后一步，到了此阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，类变量已经被赋过一次系统要求的初始值，而在初始化阶段，则是根据程序员通过程序指定的主观计划去初始化类变量和其他资源，或者可以从另一个角度来表达：初始化阶段是执行类构造器()方法的过程。 执行类构造器。 初始化静态变量、静态块中的数据等（一个类加载器只会初始化一次）。 子类的调用前保证父类的被调用。 12注意：&lt;clinit&gt;是线程安全的，执行&lt;clinit&gt;的线程需要先获取锁才能进行初始化操作，保证只有一个线程能执行&lt;clinit&gt;(利用此特性可以实现线程安全的懒汉单例模式)。如果在一个类的&lt;clinit&gt;方法中有耗时很长的操作，那就可能造成多个线程阻塞，在实际应用中这种阻塞往往是很隐蔽的。 类加载器类被加载进虚拟机是由类加载器（ClassLoader）来完成的。类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远远不限于类的加载阶段。对于任意一个类，都需要由它的类加载器和这个类本身一同确定其在就Java虚拟机中的唯一性，也就是说，即使两个类来源于同一个Class文件，只要加载它们的类加载器不同，那这两个类就必定不相等。这里的“相等”包括了代表类的Class对象的equals（）、isAssignableFrom（）、isInstance（）等方法的返回结果，也包括了使用instanceof关键字对对象所属关系的判定结果。只有在两个类被同一个类加载器加载的前提下，比较才有意义。否则，即使两个类来自同一个class文件，被同一个JVM加载，但是加载它们的类加载器不同，则这两个类就不相等。这就相当于两个命名空间中的等价类LoaderA::C和LoaderB::C。 类加载器的种类从Java虚拟机的角度来分的话，ClassLoader分为启动类加载器（Bootstrap ClassLoader）和其它的加载器。其中Bootstrap ClassLoader负责加载Java的核心类，该类加载器使用C++语言实现，属于虚拟机自身的一部分。而其它类加载器独立于JVM外部，并且全部继承自抽象类java.lang.ClassLoader。 站在Java开发人员的角度来分的话，ClassLoader分为： 启动类加载器（Bootstrap ClassLoader） 负责加载JAVA_HOME\\lib目录中并且能被虚拟机识别的类库到JVM内存中（如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载），如果名称不符合的类库即使放在lib目录中也不会被加载。该类加载器无法被Java程序直接引用。 扩展类加载器（Extension ClassLoader） 该加载器主要是负责加载JDK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类）。该加载器可以被开发者直接使用。 应用程序类加载器（Application ClassLoader） 该类加载器也称为系统类加载器（System ClassLoader），它负责加载用户类路径（Classpath）上所指定的类库，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 除此之外，还有自定义的类加载器，它们之间的层次关系被称为类加载器的双亲委派模型。该模型要求除了顶层的启动类加载器外，其余的类加载器都应该有自己的父类加载器，而这种父子关系一般通过组合（Composition）关系来实现，而不是通过继承（Inheritance）。 双亲委派模型 如上图所示的类加载器之间的这种层次关系，就称为类加载器的双亲委派模型（Parent Delegation Model）。该模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器和父类加载器不是以继承（Inheritance）的关系来实现，而是通过组合（Composition）关系来复用父加载器的代码。 双亲委派模型的工作过程为：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）时，子加载器才会尝试自己去加载。 使用这种模型来组织类加载器之间的关系的好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如java.lang.Object类，无论哪个类加载器去加载该类，最终都是由启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。否则的话，如果不使用该模型的话，如果用户自定义一个java.lang.Object类且存放在classpath中，那么系统中将会出现多个Object类，应用程序也会变得很混乱。如果我们自定义一个rt.jar中已有类的同名Java类，会发现JVM可以正常编译，但该类永远无法被加载运行。 在rt.jar包中的java.lang.ClassLoader类中，我们可以查看类加载实现过程的代码，具体源码如下： 123456789101112131415161718192021222324252627282930protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; // First, check if the class has already been loaded //首先检查请求的类是否已经被加载过 Class c = findLoadedClass(name); if (c == null) &#123; try &#123; //委派父类加载器加载 if (parent != null) &#123; c = parent.loadClass(name, false); //委派启动类加载器加载 &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; //父类加载器无法完成类加载请求 &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; //本身类加载器进行类加载 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 通过上面代码可以看出，双亲委派模型是通过loadClass()方法来实现的，根据代码以及代码中的注释可以很清楚地了解整个过程其实非常简单：先检查是否已经被加载过，如果没有则调用父加载器的loadClass()方法，如果父加载器为空则默认使用启动类加载器作为父加载器。如果父类加载器加载失败，则先抛出ClassNotFoundException，然后再调用自己的findClass()方法进行加载。 注意，双亲委派模型是Java设计者推荐给开发者的类加载器的实现方式，并不是强制规定的。大多数的类加载器都遵循这个模型，但是JDK中也有较大规模破坏双亲模型的情况，例如线程上下文类加载器（Thread Context ClassLoader）的出现。 总结整个类加载过程中，除了在加载阶段用户应用程序可以自定义类加载器参与之外，其余所有的动作完全由虚拟机主导和控制。到了初始化才开始执行类中定义的Java程序代码，但这里的执行代码只是个开端，它仅限于()方法。类加载过程中主要是将Class文件（准确地讲，应该是类的二进制字节流）加载到虚拟机内存中，真正执行字节码的操作，在加载完成后才真正开始。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://mx-go.github.io/tags/jvm/"}]},{"title":"UML工具-PowerDesigner设计数据库","slug":"UML工具-PowerDesigner设计数据库","date":"2017-12-06T07:47:06.000Z","updated":"2021-05-05T03:33:43.308Z","comments":true,"path":"UML工具-PowerDesigner设计数据库/","link":"","permalink":"https://mx-go.github.io/UML%E5%B7%A5%E5%85%B7-PowerDesigner%E8%AE%BE%E8%AE%A1%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"引言在数据库的开发设计中，PowerDesiger（PD）是一个较为常用的UML工具。PowerDesiger为各类数据模型提供了直观的符号表示，不仅使设计人员能更方便、更快捷地使非计算机专业技术人员展示数据库设计和应用系统设计，使系统设计人员与使用系统的业务人员更易于相互理解和交流，同时也使项目组内的交流更为直观、准确，更便于协调工作，从而加速系统的设计和开发过程。PowerDesiger设计完成后的数据库可直接生成SQL语句。","text":"引言在数据库的开发设计中，PowerDesiger（PD）是一个较为常用的UML工具。PowerDesiger为各类数据模型提供了直观的符号表示，不仅使设计人员能更方便、更快捷地使非计算机专业技术人员展示数据库设计和应用系统设计，使系统设计人员与使用系统的业务人员更易于相互理解和交流，同时也使项目组内的交流更为直观、准确，更便于协调工作，从而加速系统的设计和开发过程。PowerDesiger设计完成后的数据库可直接生成SQL语句。 使用ODBC连接MySQL准备工作PowerDesigner本身是32位的程序（特别重要），故不管在32位或者64位操作系统中，都需要安装32位的MySQL Connector /ODBC。 MySQL Connector /ODBC下载地址：https://dev.mysql.com/downloads/connector/odbc/ 连接数据库 安装完ODBC之后，打开PowerDesigner，新建一个Model，File—&gt;New Model 选择工具栏中的Database—&gt; Update Model from Database，如下图 打开配置对话框，选择[Using a data source]，点击输入框后的图标 配置ODBC数据源 说明：这里提供了ANSI和Unicode两种字符集版本的Driver，Unicode提供更丰富的字符集，一般推荐使用Unicode。 点击完成，配置连接信息。 123456789说明：Data Source Name：指定当前配置的ODBC数据源名称，可随意填写。Description：指定ODBC数据源的描述信息，可根据用途随意填写。TCP/IP Server：采用TCP/IP协议连接服务器，如果是本地填写localhost或者127.0.0.1（根据实际MySQL用户情况选择），如果是远程服务器则填写相应IP地址即可。Port：默认3306，根据实际MySQL的端口设置填写。lNamed Pipe：命名管道方式连接，只适用于widows下的本地连接。连接性能比TCP/IP方式更高，更安全。请按照MySQL的配置文件my.ini中的socket参数指定的值填写，如果没有设置则默认为MySQL（但是目前为止这种方式我还没有测试成功）。User：数据库用户名。Password：数据库密码。Database：数据库中的database。 信息输入完之后可以选择Test测试配置是否正确，点击OK就结束了配置。 到这里已经可以连接数据库了。 设计数据库如果在已有的数据库上需要设计和修改，先取消所有表，再选择需要设计或修改的数据库，选择表，点击ok。 连接后的UML如下，可以新建和修改表 同时可对表进行主外键设计，现在主外键已经很少用到了。 双击表之间的连接线，点击Joins 点击【确定】按钮，即可如我们所愿： 生成建表语句点击Database—&gt;Generate Database 点击【确定】按钮之后，可以在桌面上找到shiro.sql这样的一个文件，打开，即可看到建表语句： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/*==============================================================*//* DBMS name: MySQL 5.0 *//* Created on: 2017.12.6 17:22:25 *//*==============================================================*/drop table if exists shiro.u_permission;drop table if exists shiro.u_role;drop table if exists shiro.u_role_permission;drop table if exists shiro.u_user;drop table if exists shiro.u_user_role;/*==============================================================*//* User: shiro *//*==============================================================*/create user shiro;/*==============================================================*//* Table: u_permission *//*==============================================================*/create table shiro.u_permission( id bigint(20) not null auto_increment, url national varchar(256) comment &#x27;url地址&#x27;, name national varchar(64) comment &#x27;url描述&#x27;, primary key (id));/*==============================================================*//* Table: u_role *//*==============================================================*/create table shiro.u_role( id bigint(20) not null auto_increment, name national varchar(32) comment &#x27;角色名称&#x27;, type national varchar(10) comment &#x27;角色类型&#x27;, primary key (id));/*==============================================================*//* Table: u_role_permission *//*==============================================================*/create table shiro.u_role_permission( rid bigint(20) comment &#x27;角色ID&#x27;, pid bigint(20) comment &#x27;权限ID&#x27;);/*==============================================================*//* Table: u_user *//*==============================================================*/create table shiro.u_user( id bigint(20) not null auto_increment, nickname national varchar(20) comment &#x27;用户昵称&#x27;, email national varchar(128) comment &#x27;邮箱|登录帐号&#x27;, pswd national varchar(32) comment &#x27;密码&#x27;, create_time datetime comment &#x27;创建时间&#x27;, last_login_time datetime comment &#x27;最后登录时间&#x27;, status bigint(1) default 1 comment &#x27;1:有效，0:禁止登录&#x27;, primary key (id));/*==============================================================*//* Table: u_user_role *//*==============================================================*/create table shiro.u_user_role( uid bigint(20) comment &#x27;用户ID&#x27;, rid bigint(20) comment &#x27;角色ID&#x27;);alter table shiro.u_user_role add constraint FK_Reference_1 foreign key (uid) references shiro.u_user (id) on delete restrict on update restrict; 得到SQL语句后可直接导入到数据库。由此我们设计数据库已经完成。 总结这里只是简单介绍了PowerDesigner进行数据库模型设计，自动生成SQL语句等功能。PowerDesigner还有很多技巧和功能在摸索中。","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"tools","slug":"tools","permalink":"https://mx-go.github.io/tags/tools/"},{"name":"sql","slug":"sql","permalink":"https://mx-go.github.io/tags/sql/"}]},{"title":"Java String intern方法","slug":"Java-String-intern方法","date":"2017-12-01T02:27:19.000Z","updated":"2021-05-05T03:23:49.861Z","comments":true,"path":"Java-String-intern方法/","link":"","permalink":"https://mx-go.github.io/Java-String-intern%E6%96%B9%E6%B3%95/","excerpt":"引言String类我们经常使用，但是它的intern()方法之前还真的不太了解，通过谷歌百度一番之后终于搞明白了。 intern()方法设计的初衷，就是重用String对象，以节省内存消耗。","text":"引言String类我们经常使用，但是它的intern()方法之前还真的不太了解，通过谷歌百度一番之后终于搞明白了。 intern()方法设计的初衷，就是重用String对象，以节省内存消耗。 案例123String str1 = new String(&quot;rainbow&quot;) + new String(&quot;horse&quot;);System.out.println(str1.intern() == str1);System.out.println(str1 == &quot;rainbowhorse&quot;); 在JDK1.7下输出结果为： 12truetrue 再将上面的例子加上一行代码： 1234String str2 = &quot;rainbowhorse&quot;; //新加的一行代码，其余不变 String str1 = new String(&quot;rainbow&quot;) + new String(&quot;horse&quot;);System.out.println(str1.intern() == str1);System.out.println(str1 == &quot;rainbowhorse&quot;); 再运行，结果为： 12falsefalse 在JVM运行时数据区中的方法区有一个常量池，但是发现在JDK1.6以后常量池被放置在了堆空间，因此常量池位置的不同影响到了String的intern()方法的表现。 为什么使用intern()方法就如引言所说的，intern()方法设计的初衷，就是重用String对象，以节省内存消耗。下面通过例子来说明： 12345678910111213141516171819202122public class Test &#123; static final int MAX = 100000; static final String[] arr = new String[MAX]; public static void main(String[] args) throws Exception &#123; // 为长度为10的Integer数组随机赋值 Integer[] sample = new Integer[10]; Random random = new Random(1000); for (int i = 0; i &lt; sample.length; i++) &#123; sample[i] = random.nextInt(); &#125; // 记录程序开始时间 long t = System.currentTimeMillis(); // 使用/不使用intern方法为10万个String赋值，值来自于Integer数组的10个数 for (int i = 0; i &lt; MAX; i++) &#123; arr[i] = new String(String.valueOf(sample[i % sample.length])); // arr[i] = new String(String.valueOf(sample[i % sample.length])).intern(); &#125; System.out.println((System.currentTimeMillis() - t) + &quot;ms&quot;); System.gc(); &#125;&#125; 这个主要是为了证明使用intern()比不使用intern()消耗的内存更少。 先定义一个长度为10的Integer数组，并随机为其赋值，在通过for循环为长度为10万的String对象依次赋值，这些值都来自于Integer数组。两种情况分别运行，可通过Window —&gt; Preferences –&gt; Java –&gt; Installed JREs设置JVM启动参数为-agentlib:hprof=heap=dump,format=b，将程序运行完后的hprof置于工程目录下。再通过MAT插件查看该hprof文件。 不使用intern()方法 使用intern()方法 从运行结果来看，不使用intern()的情况下，程序生成了101762个String对象，而使用了intern()方法时，程序仅生成了1772个String对象。证明了intern()节省内存的结论。 但是会发现使用了intern()方法后程序运行时间有所增加。这是因为程序中每次都是用了new String后又进行intern()操作的耗时时间，但是不使用intern()占用内存空间导致GC的时间是要远远大于这点时间的。 深入理解intern()方法JDK1.7后，常量池被放入到堆空间中，这导致intern()函数的功能不同。这点很重要。 看看下面代码，这个例子是网上流传较广的一个例子，我也是照抄过来的。 123456789String s = new String(&quot;1&quot;); s.intern(); String s2 = &quot;1&quot;; System.out.println(s == s2); String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); s3.intern(); String s4 = &quot;11&quot;; System.out.println(s3 == s4); 输出结果为： 12JDK1.6以及以下：false false JDK1.7以及以上：false true 再分别调整上面代码2、3行，7、8行的顺序： 123456789String s = new String(&quot;1&quot;); String s2 = &quot;1&quot;; s.intern(); System.out.println(s == s2); String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); String s4 = &quot;11&quot;; s3.intern(); System.out.println(s3 == s4); 输出结果为： 12JDK1.6以及以下：false false JDK1.7以及以上：false false JDK1.6 在JDK1.6中所有的输出结果都是 false，因为JDK1.6以及以前版本中，常量池是放在 Perm 区（属于方法区）中的，Perm区是和堆区完全分开的。 使用引号声明的字符串都是会直接在字符串常量池中生成的，而new 出来的String对象是放在堆空间中的。所以两者的内存地址肯定是不相同的，即使调用了intern()方法也是不影响的。 intern()方法在JDK1.6中的作用是：比如String s = new String(“rainbowhorse”)，再调用s.intern()，此时返回值还是字符串”rainbowhorse”，表面上看起来好像这个方法没什么用处。但实际上，在JDK1.6中它做了个小动作：检查字符串池里是否存在”rainbowhorse”这么一个字符串，如果存在，就返回池里的字符串；如果不存在，该方法把”rainbowhorse”添加到字符串池中，然后再返回它的引用。 JDK1.7例一分析123456789String s = new String(&quot;1&quot;); s.intern(); String s2 = &quot;1&quot;; System.out.println(s == s2); String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); s3.intern(); String s4 = &quot;11&quot;; System.out.println(s3 == s4); String s = newString(“1”)，生成了常量池中的“1” 和堆空间中的字符串对象。 s.intern()，这一行的作用是s对象去常量池中寻找后发现”1”已经存在于常量池中了。 String s2 = “1”，这行代码是生成一个s2的引用指向常量池中的“1”对象。 结果就是 s 和 s2 的引用地址明显不同。因此返回了false。 String s3 = new String(“1”) + newString(“1”)，这行代码在字符串常量池中生成“1” ，并在堆空间中生成s3引用指向的对象（内容为”11”）。注意此时常量池中是没有 “11”对象的。 s3.intern()，这一行代码，是将 s3中的“11”字符串放入 String 常量池中，此时常量池中不存在“11”字符串，JDK1.6的做法是直接在常量池中生成一个 “11” 的对象。 但是在JDK1.7中，常量池中不需要再存储一份对象了，可以直接存储堆中的引用。这份引用直接指向 s3 引用的对象，也就是说s3.intern() ==s3会返回true。 String s4 = “11”， 这一行代码会直接去常量池中创建，但是发现已经有这个对象了，此时也就是指向 s3 引用对象的一个引用。因此s3 == s4返回了true。 例二分析123456789String s = new String(&quot;1&quot;); String s2 = &quot;1&quot;; s.intern(); System.out.println(s == s2); String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;); String s4 = &quot;11&quot;; s3.intern(); System.out.println(s3 == s4); String s = newString(“1”)，生成了常量池中的“1” 和堆空间中的字符串对象。 String s2 = “1”，这行代码是生成一个s2的引用指向常量池中的“1”对象，但是发现已经存在了，那么就直接指向了它。 s.intern()，这一行在这里就没什么实际作用了。因为”1”已经存在了。 结果就是 s 和 s2 的引用地址明显不同。因此返回了false。 String s3 = new String(“1”) + newString(“1”)，这行代码在字符串常量池中生成“1” ，并在堆空间中生成s3引用指向的对象（内容为”11”）。注意此时常量池中是没有 “11”对象的。 String s4 = “11”， 这一行代码会**直接去生成常量池中的”11”**。 s3.intern()，这一行在这里就没什么实际作用了。因为”11”已经存在了。 结果就是 s3 和 s4 的引用地址明显不同。因此返回了false。 总结从JDK 1.7后，HotSpot 将常量池从永久代移到了元空间，正因为如此，JDK 1.7 后的intern方法在实现上发生了比较大的改变，JDK 1.7后，intern方法还是会先去查询常量池中是否有已经存在，如果存在，则返回常量池中的引用，这一点与之前没有区别，区别在于，如果在常量池找不到对应的字符串，则不会再将字符串拷贝到常量池，而只是在常量池中生成一个对原字符串的引用。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"JVM入门","slug":"JVM入门","date":"2017-11-20T07:27:10.000Z","updated":"2021-05-05T03:25:57.747Z","comments":true,"path":"JVM入门/","link":"","permalink":"https://mx-go.github.io/JVM%E5%85%A5%E9%97%A8/","excerpt":"引言JVM（Java Virtual Machine）Java 虚拟机是整个 Java 平台的基石，是 Java 系统实现硬件无关与操作系统无关的关键部分，是保障用户机器免于恶意代码损害的屏障。Java开发人员不需要了解JVM是如何工作的，但是，了解 JVM 有助于我们更好的开发java 程序。近些天一直在看周志明的《深入理解Java虚拟机》这本书，这本书写的堪称经典，对于JVM的学习非常有帮助。","text":"引言JVM（Java Virtual Machine）Java 虚拟机是整个 Java 平台的基石，是 Java 系统实现硬件无关与操作系统无关的关键部分，是保障用户机器免于恶意代码损害的屏障。Java开发人员不需要了解JVM是如何工作的，但是，了解 JVM 有助于我们更好的开发java 程序。近些天一直在看周志明的《深入理解Java虚拟机》这本书，这本书写的堪称经典，对于JVM的学习非常有帮助。 运行时数据区域JVM将内存主要划分为：方法区、虚拟机栈、本地方法栈、堆、程序计数器。JVM运行时数据区如下： 程序计数器(线程私有)程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，一个处理器都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，所以程序计数器是私有空间。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈(线程私有)生命周期与线程相同。“栈”就是虚拟机栈，或者说是虚拟机栈中局部变量表部分。 局部变量表存放了编译期可知的基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress（指向了一条字节码指令的地址）。其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用一个。 这个区域可能出现的两种异常： 一种是StackOverflowError，当前线程请求的栈深度大于虚拟机所允许的深度时，会抛出这个异常。制造这种异常很简单：将一个函数反复递归自己，最终会出现栈溢出错误（StackOverflowError）。 另一种异常是OutOfMemoryError异常，当虚拟机栈可以动态扩展时（当前大部分虚拟机都可以），如果无法申请足够多的内存就会抛出OutOfMemoryError， 本地方法栈本地方法栈与虚拟机所发挥的作用很相似，他们的区别在于虚拟机栈为执行Java代码方法服务，而本地方法栈是为Native方法服务。与虚拟机栈一样，本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。 Java堆(线程共享区域)Java堆是Java虚拟机所管理内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此区域内存的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。在Java虚拟机规范中的描述就是：所有对象实例及数组都要在堆上分配。随着JIT编译器的发展，所有对象在堆上分配渐渐变得不那么“绝对”了。 Java堆是垃圾收集器管理的主要区域。由于现在的收集器基本上采用的都是分代收集算法，所有Java堆可以细分为：新生代和老年代。在细致分就是把新生代分为：Eden空间、From Survivor空间、To Survivor空间。 Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像磁盘空间一样。 当堆无法再扩展时，会抛出OutOfMemoryError异常。 方法区(线程共享区域)方法区存放的是类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区是各个线程共享区域，我们在写Java代码时，每个线程度可以访问同一个类的静态变量对象。由于使用反射机制的原因，虚拟机很难推测那个类信息不再使用，因此这块区域的回收很难。 1运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 另外，对这块区域主要是针对常量池回收，值得注意的是JDK1.7已经把常量池转移到堆里面了。同样，当方法区无法满足内存分配需求时，会抛出OutOfMemoryError。 GC算法Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人却想出来。 标记-清除算法(Mark-Sweep)最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 它的不足主要有两个： 效率问题，标记和清除两个过程效率都不高； 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法(Copy)为了解决效率问题，复制算法是将内存分为大小相同的两块，每次只使用其中一块。当这块内存用完了，就将还存活的对象复制到另一块内存上面。然后再把已经使用过的内存一次清理掉。这使得每次只对半个区域进行垃圾回收，内存分配时也不用考虑内存碎片情况。 但是，这代价实在是让人无法接受，需要牺牲一般的内存空间。 研究发现，大部分对象(70%~95%)都是“朝生夕死”，所以不需要安装1:1比例划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden空间和一块Survivor空间，默认比例为Eden：Survivor=8:1。新生代区域就是这么划分，每次实例在Eden和一块Survivor中分配，回收时，将存活的对象复制到剩下的另一块Survivor。这样只有10%的内存会被浪费，但是带来的效率却很高。 当剩下的Survivor内存不足时，可以去老年代内存进行分配担保。如何理解分配担保呢，其实就是，内存不足时，去老年代内存空间分配，然后等新生代内存缓过来了之后，把内存归还给老年代，保持新生代中的Eden：Survivor=8:1.另外，两个Survivor分别有自己的名称：From Survivor、To Survivor。二者身份经常调换，即有时这块内存与Eden一起参与分配，有时是另一块。因为他们之间经常相互复制。 标记整理(Mark-Compact)复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会降低。更关键的是，如果不想浪费50%的空间，就需要有额外打的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。 标记整理算法很简单，就是先标记需要回收的对象，然后把所有存活的对象移动到内存的一端，最后直接清理掉边界意外的内存。这样的好处是避免了内存碎片。 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”算法，这种算法只是根据对象存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 在新生代中，每次垃圾收集时都发现有大批对象死去（70%-95%），只有少量存活，那就采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高，没有额外的空间对它进行分配担保，就必须使用“标记-清除”或“标记-整理”算法来进行回收。 HotSpot算法实现枚举根节点可达性分析判断jvm对象是否存活。GCRoots的对象做为起点，从起点开始向下搜索，搜索走过路径叫引用链，当一个对象到GCRoots没有引用链时，判断对象死亡。在jvm中，做为GCRoots的对象： 虚拟机栈(栈桢中的本地变量表)中的引用的对象; 方法区中的类静态属性引用的对象; 方法区中的常量引用的对象; 本地方法栈中JNI的引用的对象 。 从可达性分析中从GC Roots节点找引用链这个操作为例，可做为GC Roots的节点主要在全局性的引用（类如常量或类静态变量）与执行上下文（类如栈桢的本地变量表）中，现在很多应用仅仅方法区就有数百兆，如果要逐个检查这里面的应用，那么必然会逍遥很多的时间。 可达性分析对执行时间的敏感还体现在GC停顿上，因为分析工作必须要再一个能确保一致性的快照中进行这是导致GC进行时必须停顿所有Java线程（STW）的其中一个重要原因，即使在号称（几乎）不会发生停顿的CMS收集器中，枚举根节点时也是必须要停顿的。 垃圾收集器如果说收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。 图中展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，就说明它们可以搭配使用。虚拟机所处的区域，则表示它是属于新生代收集器还是老年代收集器。 概念理解 并发和并行这两个名词都是并发编程中的概念，在谈论垃圾收集器的上下文语境中，它们可以解释如下。 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上。 Minor GC 和 Full GC 新生代GC（Minor GC）：指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。 老年代GC（Major GC / Full GC）：指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。Major GC的速度一般会比Minor GC慢10倍以上。 吞吐量 吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）。虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。 Serial收集器Serial收集器是最基本、发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。 特性：这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。Stop The World(STW) 应用场景：Serial收集器是虚拟机运行在Client模式下的默认新生代收集器。 优势：简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。 ParNew收集器 特性：ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。 应用场景：ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器。 很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器配合工作。在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器——CMS收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。不幸的是，CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。 Serial收集器 VS ParNew收集器：ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越Serial收集器。然而，随着可以使用的CPU的数量的增加，它对于GC时系统资源的有效利用还是很有好处的。 Parallel Scavenge收集器 特性：Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。 应用场景：停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 对比分析： Parallel Scavenge收集器 VS CMS等收集器：Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为“吞吐量优先”收集器。 Parallel Scavenge收集器 VS ParNew收集器：Parallel Scavenge收集器与ParNew收集器的一个重要区别是它具有自适应调节策略。 GC自适应的调节策略：Parallel Scavenge收集器有一个参数-XX:+UseAdaptiveSizePolicy。当这个参数打开之后，就不需要手工指定新生代的大小、Eden与Survivor区的比例、晋升老年代对象年龄等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。 Serial Old收集器 特性：Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记－整理算法。 应用场景： Client模式Serial Old收集器的主要意义也是在于给Client模式下的虚拟机使用。 Server模式如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。 Parallel Old收集器 特性：Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。 应用场景：在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。 这个收集器是在JDK 1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old收集器外别无选择（Parallel Scavenge收集器无法与CMS收集器配合工作）。由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”。直到Parallel Old收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的应用组合。 CMS收集器 特性： CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。CMS收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤： 初始标记（CMS initial mark）初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。 并发标记（CMS concurrent mark）并发标记阶段就是进行GC Roots Tracing的过程。 重新标记（CMS remark）重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，仍然需要“Stop The World”。 并发清除（CMS concurrent sweep）并发清除阶段会清除对象。 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 优点：CMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿。 缺点： CMS收集器对CPU资源非常敏感其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。CMS默认启动的回收线程数是（CPU数量+3）/ 4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大。 CMS收集器无法处理浮动垃圾CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。 由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。 CMS收集器会产生大量空间碎片CMS是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。 空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。 G1收集器 特性：G1（Garbage-First）是一款面向服务端应用的垃圾收集器。HotSpot开发团队赋予它的使命是未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点。 并行与并发G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。 分代收集与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。 空间整合与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。 可预测的停顿这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。 G1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。 执行过程：G1收集器的运作大致可划分为以下几个步骤： 初始标记（Initial Marking）初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking）并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking）最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation）筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 CMS收集器 VS G1收集器： G1收集器几乎可以说还没有经过实际应用的考验，网络上关于G1收集器的性能测试也非常贫乏，如果现在采用的收集器没有出现任何问题，那就没有理由现在去选择G1，如果应用追求低停顿，那G1现在已经可以作为一个可尝试的选择，如果应用追求吞吐量，那么G1并不会带来什么特别的好处。 总结内存回收与垃圾收集器在很多时候都是影响系统性能、并发能力的主要因素之一，虚拟机之所以提供多种不同的收集器以及提供大量的调节参数，是因为只有根据实际应用需求，实现方式选择最优的收集方式才能获取最高的性能，没有固定收集器、参数组合，也就没有最优的调优方法，虚拟机也有没有什么必然的内存回收行为。 虽然我们是在对各个收集器进行比较，但并非为了挑选出一个最好的收集器。因为直到现在为止还没有最好的收集器出现，更加没有万能的收集器，所以我们选择的只是对具体应用最合适的收集器。这点不需要多加解释就能证明：如果有一种放之四海皆准、任何场景下都适用的完美收集器存在，那HotSpot虚拟机就没必要实现那么多不同的收集器了。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://mx-go.github.io/tags/jvm/"}]},{"title":"Java生成PDF","slug":"Java生成PDF","date":"2017-11-13T07:51:53.000Z","updated":"2021-05-05T03:24:56.438Z","comments":true,"path":"Java生成PDF/","link":"","permalink":"https://mx-go.github.io/Java%E7%94%9F%E6%88%90PDF/","excerpt":"引言在某些业务场景中，需要提供相关的电子凭证，比如网银/支付宝中转账的电子回单，签约的电子合同、证书等。方便用户查看，下载，打印。目前常用的解决方案是，把相关数据信息，生成对应的PDF文件返回给用户。之前有写过一篇博客关于JAVA实现HTML转PDF，不同场景下的业务不同，现在需要使用PDF生成证书，这篇博客主要介绍iText的使用。 本博客项目地址：https://github.com/mx-go/java_pdf_demo","text":"引言在某些业务场景中，需要提供相关的电子凭证，比如网银/支付宝中转账的电子回单，签约的电子合同、证书等。方便用户查看，下载，打印。目前常用的解决方案是，把相关数据信息，生成对应的PDF文件返回给用户。之前有写过一篇博客关于JAVA实现HTML转PDF，不同场景下的业务不同，现在需要使用PDF生成证书，这篇博客主要介绍iText的使用。 本博客项目地址：https://github.com/mx-go/java_pdf_demo iText介绍iText是著名的开放源码的站点sourceforge一个项目，是用于生成PDF文档的一个JAVA类库。通过iText不仅可以生成PDF或rtf的文档，而且可以将XML、HTML文件转化为PDF文件。 iText 官网：http://itextpdf.com/ iText 开发文档： http://developers.itextpdf.com/developers-home iText目前有两套版本iText5和iText7。iText5应该是网上用的比较多的一个版本。iText5因为是很多开发者参与贡献代码，因此在一些规范和设计上存在不合理的地方。iText7是后来官方针对iText5的重构，两个版本差别还是挺大的。不过在实际使用中，一般用到的都比较简单，所以不用特别拘泥于使用哪个版本。比如我们在http://mvnrepository.com/中搜索iText，出来的都是iText5的依赖。 iText简单使用添加依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.itextpdf/itextpdf --&gt;&lt;dependency&gt; &lt;groupId&gt;com.itextpdf&lt;/groupId&gt; &lt;artifactId&gt;itextpdf&lt;/artifactId&gt; &lt;version&gt;5.5.11&lt;/version&gt;&lt;/dependency&gt; 测试代码：JavaToPdf 12345678910111213141516171819202122232425262728293031package com.rainbowhorse.test;import com.itextpdf.text.Document;import com.itextpdf.text.DocumentException;import com.itextpdf.text.Paragraph;import com.itextpdf.text.pdf.PdfWriter;import java.io.FileNotFoundException;import java.io.FileOutputStream;/** * 不支持中文 * ClassName: JavaToPdf * @Description: TODO * @author max * @date 2017年11月13日 */public class JavaToPdf &#123; // 生成PDF路径 private static final String DEST = &quot;target/HelloWorld.pdf&quot;; public static void main(String[] args) throws FileNotFoundException, DocumentException &#123; Document document = new Document(); PdfWriter writer = PdfWriter.getInstance(document, new FileOutputStream(DEST)); document.open(); document.add(new Paragraph(&quot;hello world&quot;)); document.close(); writer.close(); &#125;&#125; 运行结果 iText中文支持iText默认是不支持中文的，因此需要添加对应的中文字体,比如黑体simhei.ttf 可参考文档：http://developers.itextpdf.com/examples/font-examples/using-fonts#1227-tengwarquenya1.java 测试代码：JavaToPdfCN 12345678910111213141516171819202122232425262728293031323334353637package com.rainbowhorse.test;import com.itextpdf.text.Document;import com.itextpdf.text.DocumentException;import com.itextpdf.text.Font;import com.itextpdf.text.FontFactory;import com.itextpdf.text.Paragraph;import com.itextpdf.text.pdf.BaseFont;import com.itextpdf.text.pdf.PdfWriter;import java.io.FileNotFoundException;import java.io.FileOutputStream;/** * 支持中文 * ClassName: JavaToPdfCN * @Description: TODO * @author max * @date 2017年11月13日 */public class JavaToPdfCN &#123; // 生成PDF路径 private static final String DEST = &quot;target/HelloWorld_CN.pdf&quot;; // 中文字体（黑体） private static final String FONT = &quot;simhei.ttf&quot;; public static void main(String[] args) throws FileNotFoundException, DocumentException &#123; Document document = new Document(); PdfWriter writer = PdfWriter.getInstance(document, new FileOutputStream(DEST)); document.open(); Font font = FontFactory.getFont(FONT, BaseFont.IDENTITY_H, BaseFont.NOT_EMBEDDED); document.add(new Paragraph(&quot;hello world，我是rainbowhorse。&quot;, font)); document.close(); writer.close(); &#125;&#125; 运行结果 iText-HTML渲染在一些比较复杂的PDF布局中，我们可以通过HTML去生成PDF 可参考文档：http://developers.itextpdf.com/examples/xml-worker-itext5/xml-worker-examples 添加依赖 123456&lt;!-- https://mvnrepository.com/artifact/com.itextpdf.tool/xmlworker --&gt;&lt;dependency&gt; &lt;groupId&gt;com.itextpdf.tool&lt;/groupId&gt; &lt;artifactId&gt;xmlworker&lt;/artifactId&gt; &lt;version&gt;5.5.11&lt;/version&gt;&lt;/dependency&gt; 添加模板：template.html 12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot; /&gt;&lt;title&gt;Title&lt;/title&gt;&lt;style&gt;body &#123; font-family: SimHei;&#125;.red &#123; color: red;&#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;red&quot;&gt;你好，rainbowhorse&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 测试代码：JavaToPdfHtml 123456789101112131415161718192021222324252627282930313233343536373839404142package com.rainbowhorse.test;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.nio.charset.Charset;import com.itextpdf.text.Document;import com.itextpdf.text.DocumentException;import com.itextpdf.text.pdf.PdfWriter;import com.itextpdf.tool.xml.XMLWorkerFontProvider;import com.itextpdf.tool.xml.XMLWorkerHelper;import com.rainbowhorse.test.util.PathUtil;/** * HTML转PDF * ClassName: JavaToPdfHtml * @Description: TODO * @author max * @date 2017年11月13日 */public class JavaToPdfHtml &#123; // 生成PDF路径 private static final String DEST = &quot;target/HelloWorld_CN_HTML.pdf&quot;; // 模板路径 private static final String HTML = PathUtil.getCurrentPath() + &quot;/template.html&quot;; // 中文字体（黑体） private static final String FONT = &quot;simhei.ttf&quot;; public static void main(String[] args) throws IOException, DocumentException &#123; Document document = new Document(); PdfWriter writer = PdfWriter.getInstance(document, new FileOutputStream(DEST)); document.open(); XMLWorkerFontProvider fontImp = new XMLWorkerFontProvider(XMLWorkerFontProvider.DONTLOOKFORFONTS); fontImp.register(FONT); XMLWorkerHelper.getInstance().parseXHtml(writer, document, new FileInputStream(HTML), null, Charset.forName(&quot;UTF-8&quot;), fontImp); document.close(); &#125;&#125; 运行结果 注意： HTML中必须使用标准的语法，标签一定需要闭合。 HTML中如果有中文，需要在样式中添加对应字体的样式。 iText-HTML-Freemarker渲染在实际使用中，HTML内容都是动态渲染的，因此我们需要加入模板引擎支持，可以使用FreeMarker/Velocity，这里使用FreeMarker举例。 添加FreeMarke依赖 123456&lt;!-- https://mvnrepository.com/artifact/org.freemarker/freemarker --&gt;&lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.19&lt;/version&gt;&lt;/dependency&gt; 添加模板：template_freemarker.html 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot; /&gt;&lt;title&gt;Title&lt;/title&gt;&lt;style&gt;body &#123; font-family: SimHei;&#125;.blue &#123; color: blue;&#125;.pos &#123; position: absolute; left: 100px; top: 150px&#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;blue pos&quot;&gt;你好，$&#123;name&#125;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 测试代码：JavaToPdfHtmlFreeMarker 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.rainbowhorse.test;import java.io.ByteArrayInputStream;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.io.StringWriter;import java.io.Writer;import java.nio.charset.Charset;import java.util.HashMap;import java.util.Map;import com.itextpdf.text.Document;import com.itextpdf.text.DocumentException;import com.itextpdf.text.pdf.PdfWriter;import com.itextpdf.tool.xml.XMLWorkerFontProvider;import com.itextpdf.tool.xml.XMLWorkerHelper;import com.rainbowhorse.test.util.PathUtil;import freemarker.template.Configuration;import freemarker.template.Template;/** * FreeMarker模板的HTML转PDF * ClassName: JavaToPdfHtmlFreeMarker * @Description: TODO * @author max * @date 2017年11月13日 */public class JavaToPdfHtmlFreeMarker &#123; // 生成PDF路径 private static final String DEST = &quot;target/HelloWorld_CN_HTML_FREEMARKER.pdf&quot;; // 模板路径 private static final String HTML = &quot;template_freemarker.html&quot;; // 中文字体（黑体） private static final String FONT = &quot;simhei.ttf&quot;; private static Configuration freemarkerCfg = null; static &#123; freemarkerCfg = new Configuration(); // freemarker的模板目录 try &#123; freemarkerCfg.setDirectoryForTemplateLoading(new File(PathUtil.getCurrentPath())); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws IOException, DocumentException &#123; Map&lt;String, Object&gt; data = new HashMap&lt;String, Object&gt;(16); data.put(&quot;name&quot;, &quot;rainbowhorse&quot;); String content = JavaToPdfHtmlFreeMarker.freeMarkerRender(data, HTML); JavaToPdfHtmlFreeMarker.createPdf(content, DEST); &#125; public static void createPdf(String content, String dest) throws IOException, DocumentException &#123; Document document = new Document(); PdfWriter writer = PdfWriter.getInstance(document, new FileOutputStream(dest)); document.open(); XMLWorkerFontProvider fontImp = new XMLWorkerFontProvider(XMLWorkerFontProvider.DONTLOOKFORFONTS); fontImp.register(FONT); XMLWorkerHelper.getInstance().parseXHtml(writer, document, new ByteArrayInputStream(content.getBytes()), null, Charset.forName(&quot;UTF-8&quot;), fontImp); document.close(); &#125; /** * freemarker渲染html */ public static String freeMarkerRender(Map&lt;String, Object&gt; data, String htmlTmp) &#123; Writer out = new StringWriter(); try &#123; // 获取模板,并设置编码方式 Template template = freemarkerCfg.getTemplate(htmlTmp); template.setEncoding(&quot;UTF-8&quot;); // 合并数据模型与模板 template.process(data, out); // 将合并后的数据和模板写入到流中，这里使用的字符流 out.flush(); return out.toString(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125; return null; &#125;&#125; 运行结果 目前为止，我们已经实现了iText通过HTML模板生成PDF的功能，但是实际应用中，我们发现iText并不能对高级的CSS样式进行解析，比如CSS中的position属性等，因此我们要引入新的组件。 Flying Saucer-CSS高级特性支持Flying Saucer is a pure-Java library for rendering arbitrary well-formed XML (or XHTML) using CSS 2.1 for layout and formatting, output to Swing panels, PDF, and images. Flying Saucer是基于iText的，支持对CSS高级特性的解析。 添加依赖 12345678910111213&lt;!-- https://mvnrepository.com/artifact/org.xhtmlrenderer/flying-saucer-pdf --&gt;&lt;dependency&gt; &lt;groupId&gt;org.xhtmlrenderer&lt;/groupId&gt; &lt;artifactId&gt;flying-saucer-pdf&lt;/artifactId&gt; &lt;version&gt;9.1.5&lt;/version&gt;&lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.xhtmlrenderer/flying-saucer-pdf-itext5 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.xhtmlrenderer&lt;/groupId&gt; &lt;artifactId&gt;flying-saucer-pdf-itext5&lt;/artifactId&gt; &lt;version&gt;9.1.5&lt;/version&gt;&lt;/dependency&gt; 添加模板：template_freemarker_fs.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot; /&gt;&lt;title&gt;Title&lt;/title&gt;&lt;style&gt; @page &#123; size:297mm 230mm; @top-left&#123; content:element(header-left); &#125;; @top-right &#123; content: element(header-right) &#125;; @bottom-left &#123; content: element(footer-left) &#125;; @bottom-right &#123; content: element(footer-right) &#125;; &#125;body &#123; font-family: SimHei;&#125;.color &#123; color: green;&#125;.pos &#123; position: absolute; left: 200px; top: 200px; width: 200px; font-size: 20px;&#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;img src=&quot;logo.jpg&quot; /&gt; &lt;div class=&quot;color pos&quot;&gt;你好，$&#123;name&#125;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 测试代码：JavaToPdfHtmlFreeMarker： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.rainbowhorse.test.flyingsaucer;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.io.StringWriter;import java.io.Writer;import java.util.HashMap;import java.util.Map;import org.xhtmlrenderer.pdf.ITextFontResolver;import org.xhtmlrenderer.pdf.ITextRenderer;import com.itextpdf.text.DocumentException;import com.itextpdf.text.pdf.BaseFont;import com.rainbowhorse.test.util.PathUtil;import freemarker.template.Configuration;import freemarker.template.Template;/** * FreeMarker模板的HTML转PDF Flying Saucer * ClassName: JavaToPdfHtmlFreeMarker * @Description: TODO * @author max * @date 2017年11月13日 */public class JavaToPdfHtmlFreeMarker &#123; // 生成PDF路径 private static final String DEST = &quot;target/HelloWorld_CN_HTML_FREEMARKER_FS.pdf&quot;; // 模板路径 private static final String HTML = &quot;template_freemarker_fs.html&quot;; // 中文字体（黑体） private static final String FONT = &quot;simhei.ttf&quot;; // 图片路径 private static final String LOGO_PATH = &quot;file:/&quot; + PathUtil.getCurrentPath() + &quot;/&quot;; private static Configuration freemarkerCfg = null; static &#123; freemarkerCfg = new Configuration(); // freemarker的模板目录 try &#123; freemarkerCfg.setDirectoryForTemplateLoading(new File(PathUtil.getCurrentPath())); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws IOException, DocumentException, com.lowagie.text.DocumentException &#123; Map&lt;String, Object&gt; data = new HashMap&lt;String, Object&gt;(16); data.put(&quot;name&quot;, &quot;rainbowhorse&quot;); String content = JavaToPdfHtmlFreeMarker.freeMarkerRender(data, HTML); JavaToPdfHtmlFreeMarker.createPdf(content, DEST); &#125; /** * freemarker渲染html */ public static String freeMarkerRender(Map&lt;String, Object&gt; data, String htmlTmp) &#123; Writer out = new StringWriter(); try &#123; // 获取模板,并设置编码方式 Template template = freemarkerCfg.getTemplate(htmlTmp); template.setEncoding(&quot;UTF-8&quot;); // 合并数据模型与模板 template.process(data, out); // 将合并后的数据和模板写入到流中，这里使用的字符流 out.flush(); return out.toString(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125; return null; &#125; public static void createPdf(String content, String dest) throws IOException, DocumentException, com.lowagie.text.DocumentException &#123; ITextRenderer render = new ITextRenderer(); ITextFontResolver fontResolver = render.getFontResolver(); fontResolver.addFont(FONT, BaseFont.IDENTITY_H, BaseFont.NOT_EMBEDDED); // 解析html生成pdf render.setDocumentFromString(content); // 解决图片相对路径的问题 render.getSharedContext().setBaseURL(LOGO_PATH); render.layout(); render.createPDF(new FileOutputStream(dest)); &#125;&#125; 运行结果 在某些场景下，HTML中的静态资源是在本地，我们可以使用render.getSharedContext().setBaseURL()加载文件资源,注意资源URL需要使用文件协议 “file://”。 对于生成的pdf页面大小，可以用css的@page属性设置。 PDF转图片在某些场景中，我们可能只需要返回图片格式的电子凭证，我们可以使用Jpedal组件，把PDF转成图片。 添加依赖 123456&lt;!-- https://mvnrepository.com/artifact/org.jpedal/jpedal-lgpl --&gt;&lt;dependency&gt; &lt;groupId&gt;org.jpedal&lt;/groupId&gt; &lt;artifactId&gt;jpedal-lgpl&lt;/artifactId&gt; &lt;version&gt;4.74b27&lt;/version&gt;&lt;/dependency&gt; 测试代码：JavaToPdfImgHtmlFreeMarker 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159package com.rainbowhorse.test.flyingsaucer;import java.awt.image.BufferedImage;import java.io.ByteArrayOutputStream;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.io.StringWriter;import java.io.Writer;import java.util.HashMap;import java.util.Map;import javax.imageio.ImageIO;import org.jpedal.PdfDecoder;import org.jpedal.exception.PdfException;import org.jpedal.fonts.FontMappings;import org.xhtmlrenderer.pdf.ITextFontResolver;import org.xhtmlrenderer.pdf.ITextRenderer;import com.itextpdf.text.DocumentException;import com.itextpdf.text.pdf.BaseFont;import com.rainbowhorse.test.util.PathUtil;import freemarker.template.Configuration;import freemarker.template.Template;/** * Jpedal把pdf转成图片 * ClassName: JavaToPdfImgHtmlFreeMarker * @Description: TODO * @author max * @date 2017年11月13日 */public class JavaToPdfImgHtmlFreeMarker &#123; private static final String DEST = &quot;target/HelloWorld_CN_HTML_FREEMARKER_FS_IMG.png&quot;; private static final String HTML = &quot;template_freemarker_fs.html&quot;; private static final String FONT = &quot;simhei.ttf&quot;; private static final String LOGO_PATH = &quot;file://&quot; + PathUtil.getCurrentPath() + &quot;/logo.png&quot;; private static final String IMG_EXT = &quot;png&quot;; private static Configuration freemarkerCfg = null; static &#123; freemarkerCfg = new Configuration(); // freemarker的模板目录 try &#123; freemarkerCfg.setDirectoryForTemplateLoading(new File(PathUtil.getCurrentPath())); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws IOException, DocumentException, com.lowagie.text.DocumentException &#123; Map&lt;String, Object&gt; data = new HashMap&lt;String, Object&gt;(16); data.put(&quot;name&quot;, &quot;rainbowhorse&quot;); String content = JavaToPdfImgHtmlFreeMarker.freeMarkerRender(data, HTML); ByteArrayOutputStream pdfStream = JavaToPdfImgHtmlFreeMarker.createPdf(content); ByteArrayOutputStream imgSteam = JavaToPdfImgHtmlFreeMarker.pdfToImg(pdfStream.toByteArray(), 2, 1, IMG_EXT); FileOutputStream fileStream = new FileOutputStream(new File(DEST)); fileStream.write(imgSteam.toByteArray()); fileStream.close(); &#125; /** * freemarker渲染html */ public static String freeMarkerRender(Map&lt;String, Object&gt; data, String htmlTmp) &#123; Writer out = new StringWriter(); try &#123; // 获取模板,并设置编码方式 Template template = freemarkerCfg.getTemplate(htmlTmp); template.setEncoding(&quot;UTF-8&quot;); // 合并数据模型与模板 template.process(data, out); // 将合并后的数据和模板写入到流中，这里使用的字符流 out.flush(); return out.toString(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; out.close(); &#125; catch (IOException ex) &#123; ex.printStackTrace(); &#125; &#125; return null; &#125; /** * 根据模板生成pdf文件流 */ public static ByteArrayOutputStream createPdf(String content) &#123; ByteArrayOutputStream outStream = new ByteArrayOutputStream(); ITextRenderer render = new ITextRenderer(); ITextFontResolver fontResolver = render.getFontResolver(); try &#123; fontResolver.addFont(FONT, BaseFont.IDENTITY_H, BaseFont.NOT_EMBEDDED); &#125; catch (com.lowagie.text.DocumentException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; // 解析html生成pdf render.setDocumentFromString(content); // 解决图片相对路径的问题 render.getSharedContext().setBaseURL(LOGO_PATH); render.layout(); try &#123; render.createPDF(outStream); return outStream; &#125; catch (com.lowagie.text.DocumentException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; outStream.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125; /** * 根据pdf二进制文件 生成图片文件 * * @param bytes * pdf二进制 * @param scaling * 清晰度 * @param pageNum * 页数 */ public static ByteArrayOutputStream pdfToImg(byte[] bytes, float scaling, int pageNum, String formatName) &#123; // 推荐的方法打开PdfDecoder PdfDecoder pdfDecoder = new PdfDecoder(true); FontMappings.setFontReplacements(); // 修改图片的清晰度 pdfDecoder.scaling = scaling; ByteArrayOutputStream out = new ByteArrayOutputStream(); try &#123; // 打开pdf文件，生成PdfDecoder对象 pdfDecoder.openPdfArray(bytes); // bytes is byte[] array with PDF // 获取第pageNum页的pdf BufferedImage img = pdfDecoder.getPageAsImage(pageNum); ImageIO.write(img, formatName, out); &#125; catch (PdfException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return out; &#125;&#125; 输出结果 Jpedal支持将指定页PDF生成图片，pdfDecoder.scaling设置图片的分辨率(不同分辨率下文件大小不同) ，支持多种图片格式，具体更多可自行研究。 总结对于电子凭证的技术方案，总结如下: HTML模板+model数据，通过freemarker进行渲染，便于维护和修改。 渲染后的HTML流，可通过Flying Saucer组件生成HTML文件流，或者生成HTML后再转成jpg文件流。 在Web项目中，对应的文件流，可以通过ContentType设置，在线查看/下载，不需通过附件服务。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"分布式下ID生成算法 SnowFlake","slug":"分布式下ID生成算法-SnowFlake","date":"2017-10-30T06:26:21.000Z","updated":"2021-05-05T03:16:19.677Z","comments":true,"path":"分布式下ID生成算法-SnowFlake/","link":"","permalink":"https://mx-go.github.io/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%8BID%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95-SnowFlake/","excerpt":"引言在做系统开发时，系统唯一ID是我们在设计一个系统的时候经常遇到的问题，也常常为这个问题纠结。生成ID的方法有很多，适应不同的场景、需求及性能要求。所以有些比较复杂的系统会有多个ID生成策略。在这里总结一下常用到的ID生成策略。","text":"引言在做系统开发时，系统唯一ID是我们在设计一个系统的时候经常遇到的问题，也常常为这个问题纠结。生成ID的方法有很多，适应不同的场景、需求及性能要求。所以有些比较复杂的系统会有多个ID生成策略。在这里总结一下常用到的ID生成策略。 数据库自增长序列或字段最常见的方式，利用数据库，全表中唯一。如MySQL的AUTO_INCREMENT。 优点 简单，代码方便，性能可以接受。 数字ID天然排序，对分页或者需要排序的结果很有帮助。 缺点 不同数据库语法和实现不同，数据库迁移的时候或多数据库版本支持的时候需要处理。 在单个数据库或读写分离或一主多从的情况下，只有一个主库可以生成。有单点故障的风险。 在性能达不到要求的情况下，比较难于扩展。 如果遇见多个系统需要合并或者涉及到数据迁移会相当痛苦。 分表分库的时候会有麻烦。 优化方案针对主库单点，如果有多个Master库，则每个Master库设置的起始数字不一样，步长一样，可以是Master的个数。比如：Master1 生成的是 1, 4, 7, 10，Master2生成的是2, 5, 8, 11，Master3生成的是3, 6, 9, 12。这样就可以有效生成集群中的唯一ID，也可以大大降低ID生成数据库操作的负载。 UUID常见的方式。可以利用数据库也可以利用程序生成，一般来说全球唯一。 优点 简单，代码方便。 生成ID性能非常好，基本不会有性能问题。 全球唯一，在遇见数据迁移，系统数据合并，或者数据库变更等情况下，可以从容应对。 缺点 没有排序，无法保证趋势递增。 UUID往往是使用字符串存储，查询的效率比较低。 存储空间比较大，如果是海量数据库，就需要考虑存储量的问题。 传输数据量大。 不可读。 Twitter-SnowFlake算法有些时候我们希望能使用简单一些的 ID，并且希望 ID 能够按照时间有序生成，为了解决这个问题，Twitter 发明了 SnowFlake 算法，不依赖第三方介质例如 Redis、数据库，本地生成程序生成分布式自增 ID，这个 ID 只能保证在工作组中的机器生成的 ID 唯一，不能像 UUID 那样保证时空唯一。 算法原理 除了最高位bit标记为不可用以外，其余三组bit占位均可浮动，看具体的业务需求而定。默认情况下41bit的时间戳可以支持该算法使用到2082年，10bit的工作机器id可以支持1023台机器，序列号支持1毫秒产生4095个自增序列id。 SnowFlake – 时间戳这里时间戳的细度是毫秒级，建议使用64位linux系统机器，因为有vdso，gettimeofday()在用户态就可以完成操作，减少了进入内核态的损耗。 SnowFake – 工作机器ID严格意义上来说这个bit段的使用可以是进程级，机器级的话你可以使用MAC地址来唯一标示工作机器，工作进程级可以使用IP+Path来区分工作进程。如果工作机器比较少，可以使用配置文件来设置这个id是一个不错的选择，如果机器过多配置文件的维护是一个灾难性的事情。 SnowFlake – 序列号序列号就是一系列的自增id（多线程建议使用atomic），为了处理在同一毫秒内需要给多条消息分配id，若同一毫秒把序列号用完了，则 “等待至下一毫秒”。 具体实现Sequence类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197/** * Snowflake 生成的 64 位 long 类型的 ID，结构如下:&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1) 01 位标识，由于 long 在 Java 中是有符号的，最高位是符号位，正数是 0，负数是 1，ID 一般使用正数，所以最高位是 0&lt;br&gt; * 2) 41 位时间截(毫秒级)，注意，41 位时间截不是存储当前时间的时间截，而是存储时间截的差值(当前时间 - 开始时间)得到的值， * 开始时间截，一般是业务开始的时间，由我们程序来指定，如 SnowflakeIdWorker 中的 startTimestamp 属性。 * 41 位的时间截，可以使用 70 年: (2^41)/(1000*60*60*24*365) = 69.7 年&lt;br&gt; * 3) 10 位的数据机器位，可以部署在 1024 个节点，包括 5 位 datacenterId 和 5 位 workerId&lt;br&gt; * 4) 12 位序列，毫秒内的计数，12 位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生 4096 个 ID 序号&lt;br&gt; * * SnowFlake 的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生 ID 碰撞(由数据中心 ID 和机器 ID 作区分)，并且效率较 高，经测试，SnowFlake 每秒能够产生约 26 万个 ID。 */public class Sequence &#123; /** 开始时间截 */ private final long twepoch = 1288834974657L; /** 机器id所占的位数 */ private final long workerIdBits = 5L; /** 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** 序列在id中占的位数 */ private final long sequenceBits = 12L; /** 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** 工作机器ID(0~31) */ private long workerId; /** 数据中心ID(0~31) */ private long datacenterId; /** 毫秒内序列(0~4095) */ private long sequence = 0L; /** 上次生成ID的时间截 */ private long lastTimestamp = -1L; public Sequence() &#123; datacenterId = getDatacenterId(maxDatacenterId); workerId = getMaxWorkerId(datacenterId, maxWorkerId); &#125; public Sequence(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&#x27;t be greater than %d or less than 0&quot;, maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&#x27;t be greater than %d or less than 0&quot;, maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; /** * 获取 maxWorkerId * @param datacenterId 数据中心id * @param maxWorkerId 机器id * @return maxWorkerId */ protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) &#123; StringBuilder mpid = new StringBuilder(); mpid.append(datacenterId); String name = ManagementFactory.getRuntimeMXBean().getName(); if (name != null &amp;&amp; !&quot;&quot;.equals(name)) &#123; // GET jvmPid mpid.append(name.split(&quot;@&quot;)[0]); &#125; //MAC + PID 的 hashcode 获取16个低位 return (mpid.toString().hashCode() &amp; 0xffff) % (maxWorkerId + 1); &#125; /** * &lt;p&gt; * 数据标识id部分 * &lt;/p&gt; * @param maxDatacenterId * @return */ protected static long getDatacenterId(long maxDatacenterId) &#123; long id = 0L; try &#123; InetAddress ip = InetAddress.getLocalHost(); NetworkInterface network = NetworkInterface.getByInetAddress(ip); if (network == null) &#123; id = 1L; &#125; else &#123; byte[] mac = network.getHardwareAddress(); if (null != mac) &#123; id = ((0x000000FF &amp; (long) mac[mac.length - 1]) | (0x0000FF00 &amp; (((long) mac[mac.length - 2]) &lt;&lt; 8))) &gt;&gt; 6; id = id % (maxDatacenterId + 1); &#125; &#125; &#125; catch (Exception e) &#123; System.err.println(&quot; getDatacenterId: &quot; + e.getMessage()); &#125; return id; &#125; /** * 获得下一个ID (该方法是线程安全的) * * @return nextId */ public synchronized long nextId() &#123; long timestamp = timeGen(); // 如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123;// 闰秒 long offset = lastTimestamp - timestamp; if (offset &lt;= 5) &#123; try &#123; wait(offset &lt;&lt; 1); timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, offset)); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; else &#123; throw new RuntimeException(String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, offset)); &#125; &#125; //$NON-NLS-解决跨毫秒生成ID序列号始终为偶数的缺陷$ // 如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; // 毫秒内序列溢出 if (sequence == 0) &#123; // 阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123;// 时间戳改变，毫秒内序列重置 sequence = 0L; &#125; /** // 如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; long old = sequence; sequence = (sequence + 1) &amp; sequenceMask; // 毫秒内序列溢出 if (sequence == old) &#123; // 阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123;// 时间戳改变，毫秒内序列重置 sequence = ThreadLocalRandom.current().nextLong(0, 2); &#125; **/ // 上次生成ID的时间截 lastTimestamp = timestamp; // 移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 返回以毫秒为单位的当前时间 * * @return 当前时间(毫秒) */ protected long timeGen() &#123; return SystemClock.now(); &#125;&#125; SystemClock类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 高并发场景下System.currentTimeMillis()的性能问题的优化 * System.currentTimeMillis()的调用比new一个普通对象要耗时的多（具体耗时高出多少我还没测试过，有人说是100倍左右）&lt;p&gt; * System.currentTimeMillis()之所以慢是因为去跟系统打了一次交道&lt;p&gt; * 后台定时更新时钟，JVM退出时，线程自动回收&lt;p&gt; * 10亿：43410,206,210.72815533980582%&lt;p&gt; * 1亿：4699,29,162.0344827586207%&lt;p&gt; * 1000万：480,12,40.0%&lt;p&gt; * 100万：50,10,5.0%&lt;p&gt; */public class SystemClock &#123; private final long period; private final AtomicLong now; private SystemClock(long period) &#123; this.period = period; this.now = new AtomicLong(System.currentTimeMillis()); scheduleClockUpdating(); &#125; private static class InstanceHolder &#123; public static final SystemClock INSTANCE = new SystemClock(1); &#125; private static SystemClock instance() &#123; return InstanceHolder.INSTANCE; &#125; private void scheduleClockUpdating() &#123; ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor(new ThreadFactory() &#123; public Thread newThread(Runnable runnable) &#123; Thread thread = new Thread(runnable, &quot;System Clock&quot;); thread.setDaemon(true); return thread; &#125; &#125;); scheduler.scheduleAtFixedRate(new Runnable() &#123; public void run() &#123; now.set(System.currentTimeMillis()); &#125; &#125;, period, period, TimeUnit.MILLISECONDS); &#125; private long currentTimeMillis() &#123; return now.get(); &#125; public static long now() &#123; return instance().currentTimeMillis(); &#125; public static String nowDate() &#123; return new Timestamp(instance().currentTimeMillis()).toString(); &#125;&#125; 测试12345678910111213141516171819public class IdGen &#123; private static Sequence sequence = new Sequence(); /** * 使用Sequence生成主键，利用Snowflake算法 */ public static String sequenceId() &#123; long nextId = sequence.nextId(); return String.valueOf(nextId); &#125; //测试代码 public static void main(String[] args) &#123; for (int i = 0; i &lt; 1000; i++) &#123; long id = sequenceId(); //System.out.println(Long.toBinaryString(id)); System.out.println(id); &#125;&#125; SnowFlake算法可以根据自身项目的需要进行一定的修改。比如估算未来的数据中心个数，每个数据中心的机器数以及统一毫秒可以能的并发数来调整在算法中所需要的bit数。 优点 不依赖于数据库，灵活方便，且性能优于数据库。 ID按照时间在单机上是递增的。 缺点在单机上是递增的，但是由于涉及到分布式环境，每台机器上的时钟不可能完全同步，也许有时候也会出现不是全局递增的情况。 总结在项目中SnowFlake算法生成ID是第一选择，兼具性能和灵活性。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"}]},{"title":"Java备份和还原MySQL数据库","slug":"Java备份和还原MySQL数据库","date":"2017-09-24T09:43:10.000Z","updated":"2021-05-05T03:24:00.038Z","comments":true,"path":"Java备份和还原MySQL数据库/","link":"","permalink":"https://mx-go.github.io/Java%E5%A4%87%E4%BB%BD%E5%92%8C%E8%BF%98%E5%8E%9FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"引言​ 在项目中经常会用到Java程序备份和还原MySQL数据库的内容，都是大同小异，但程序也会出现各种各样的问题（运行时异常，乱码等）。实现上都是用Runtime执行MySQL的命令行工具，然后读写IO流数据；也有可能是由于使用Java的Runtime来实现备份还原功能，而由于大家的运行时环境有差异才导致代码运行不成功。在这里记录一下自己使用的工具和方法。","text":"引言​ 在项目中经常会用到Java程序备份和还原MySQL数据库的内容，都是大同小异，但程序也会出现各种各样的问题（运行时异常，乱码等）。实现上都是用Runtime执行MySQL的命令行工具，然后读写IO流数据；也有可能是由于使用Java的Runtime来实现备份还原功能，而由于大家的运行时环境有差异才导致代码运行不成功。在这里记录一下自己使用的工具和方法。 使用MySQL自带工具备份备份使用MySQL的mysqldump命令来实现，示例代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455final static Logger logger = LoggerFactory.getLogger(MySQLDatabaseBackupAndRestore.class); /** * Java代码实现MySQL数据库导出 * * @param hostIP MySQL数据库所在服务器地址IP * @param userName 进入数据库所需要的用户名 * @param password 进入数据库所需要的密码 * @param savePath 数据库导出文件保存路径 * @param fileName 数据库导出文件文件名 * @param databaseName 要导出的数据库名 * @return 返回true表示导出成功，否则返回false。 * @author maxu */ public static boolean backUpDatabase(String hostIP, String userName, String password, String databaseName, String savePath, String fileName) throws InterruptedException &#123; File saveFile = new File(savePath); if (!saveFile.exists()) &#123;// 如果目录不存在 saveFile.mkdirs();// 创建文件夹 &#125; if (!savePath.endsWith(File.separator)) &#123; savePath = savePath + File.separator; &#125; PrintWriter printWriter = null; BufferedReader bufferedReader = null; try &#123; printWriter = new PrintWriter(new OutputStreamWriter(new FileOutputStream(savePath + fileName), &quot;utf8&quot;)); Process process = Runtime.getRuntime().exec(&quot; D:\\\\DevTools\\\\MySQL\\\\MySQL5.7\\\\bin\\\\mysqldump.exe -h&quot; + hostIP + &quot; -u&quot; + userName + &quot; -p&quot; + password + &quot; --set-charset=UTF8 &quot; + databaseName); InputStreamReader inputStreamReader = new InputStreamReader(process.getInputStream(), &quot;utf8&quot;); bufferedReader = new BufferedReader(inputStreamReader); String line; while ((line = bufferedReader.readLine()) != null) &#123; printWriter.println(line); &#125; printWriter.flush(); if (process.waitFor() == 0) &#123;//0 表示线程正常终止。 logger.info(&quot;数据库已备份到——&gt;&gt;&quot; + savePath); return true; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (bufferedReader != null) &#123; bufferedReader.close(); &#125; if (printWriter != null) &#123; printWriter.close(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return false; &#125; 还原1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 final static Logger logger = LoggerFactory.getLogger(MySQLDatabaseBackupAndRestore.class); /** * Java代码实现MySQL数据库还原 * * @param hostIP MySQL数据库所在服务器地址IP * @param userName 进入数据库所需要的用户名 * @param password 进入数据库所需要的密码 * @param path 需要还原数据库文件的路径 * @param fileName 需要还原数据库文件的名称 * @param databaseName 需要还原的数据库名称 * @return 返回true表示还原成功，否则返回false。 */ public static boolean restoreDatabase(String hostIP, String userName, String password, String databaseName, String path, String fileName) throws InterruptedException &#123; OutputStream out = null; BufferedReader br = null; PrintStream ps = null; try &#123; // 调用mysql的cmd:cmd命令在后台执行，没有命令窗口出现或者一闪而过的情况 Process process = Runtime.getRuntime().exec(&quot;cmd /c start /b D:\\\\DevTools\\\\MySQL\\\\MySQL5.7\\\\bin\\\\mysql -h&quot; + hostIP + &quot; -u&quot; + userName + &quot; -p&quot; + password + &quot; --default-character-set=utf8 &quot; + databaseName); out = process.getOutputStream();//控制台的输入信息作为输出流 StringBuffer sb = new StringBuffer(&quot;&quot;); br = new BufferedReader(new InputStreamReader(new FileInputStream(path + fileName), &quot;utf8&quot;)); String outStr; String line; while ((line = br.readLine()) != null) &#123; sb.append(line + &quot;\\r\\n&quot;); &#125; outStr = sb.toString(); ps = new PrintStream(out, true, &quot;utf8&quot;); ps.write(outStr.getBytes());// OutputStreamWriter writer = new OutputStreamWriter(out, &quot;utf8&quot;);// writer.write(outStr); // 注：这里如果用缓冲方式写入文件的话，会导致中文乱码，用flush()方法则可以避免// writer.flush();// writer.close(); if (process.waitFor() == 0) &#123; //0 表示线程正常终止。 return true; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; finally &#123; try &#123; if (ps != null) &#123; ps.close(); &#125; if (br != null) &#123; br.close(); &#125; if (out != null)&#123; out.close(); &#125; &#125; catch (IOException e1) &#123; e1.printStackTrace(); &#125; &#125; return false;&#125; 测试 1234567891011121314151617181920212223public static void main(String[] args)&#123; //数据库备份 /*try &#123; if (backUpDatabase(&quot;localhost&quot;, &quot;root&quot;, &quot;root&quot;, &quot;taotao&quot;, &quot;D:/&quot;, &quot;taotao.sql&quot;)) &#123; logger.info(&quot;数据库成功备份！！&quot;); &#125; else &#123; logger.info(&quot;数据库备份失败！！&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;*/ //数据库恢复 try &#123; if (restoreDatabase(&quot;localhost&quot;, &quot;root&quot;, &quot;root&quot;, &quot;taotao&quot;, &quot;D:/&quot;, &quot;taotao.sql&quot;)) &#123; logger.info(&quot;数据库恢复成功！！&quot;); &#125; else &#123; logger.info(&quot;数据库恢复失败！！&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 代码下载点击：下载 Windows下bat命令工作环境 Windows Server 2003 ，MySQL安装目录 D:\\DevTools\\MySQL , WinRAR 安装目录 C:\\Program Files\\WinRAR\\WinRAR.exe 备份数据存储的路径为 D:\\数据备份，好了下面开始写DOS批处理命令了。代码如下: 123456789101112131415color 9rem ---------------------数据库备份开始-----------------------@echo offset &quot;Ymd=%DATE:~0,4%%DATE:~5,2%%DATE:~8,2%%TIME:~0,2%%TIME:~3,2%%TIME:~6,2%&quot; REM 日期格式：20170924200727 md &quot;D:\\%ymd%&quot; &quot;D:\\DevTools\\MySQL\\MySQL5.7\\bin\\mysqldump.exe&quot; --opt -Q taotao -uroot -proot &gt; D:\\%Ymd%\\taotao.sqlREM ..... 这里可以添加更多的命令，要看你有多少个数据库，其中 -Q 后面是数据库名称 -p紧跟后面是密码REM echo Winrar loading... REM &quot;C:\\Program Files\\WinRAR\\WinRAR.exe&quot; a -ep1 -r -o+ -m5 -df &quot;D:\\数据备份\\%Ymd%.rar&quot; &quot;D:\\数据备份\\%Ymd%&quot; @echo onrem ---------------------数据库备份完成-----------------------pause 把上面的命令保存为 backup.bat ，双击运行，就开始备份数据了。 第 一句是建立一个变量 %Ymd% ，通过 %date% 这个系统变量得到日期，%date:,4% 表示取日期的前面4个字符就是年份，%%date:5,2% 表示取日期第5个字符开始的2个字符就是月份，%date:~8,2% 这个就是日期号数，如 2017-09-24 这个日期最后得到的结果是 20170924 第二句就是使用变量 %Ymd% 的值建立一个空的文件夹。 第三句开始就是使用MySQL的命令对数据库mysql进行备份，并存储在 D:\\数据备份%ymd% 这个文件夹下面，这里可以有很多类似的命令，备份多个数据库。 最后就是使用 WinRAR 对备份的数据进行压缩，并存储为以 %Ymd% 变量值建立的RAR文件名，同时删除备份的 %Ymd% 目录。 如果你想让系统自动定期备份，就可以通过系统的任务计划定期执行这个命令。 但是用windows下bat命令备份有一个致命缺点：备份时数据库会暂时断开。(30M断开5s左右) 总结第二种方式的缺点太致命：备份时数据库会暂时断开。 所以第一种方式将会是我们在开发中首选的方式，因为第二种方式的缺点对用户体验的影响太大了。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"系统中功能点的版本控制","slug":"系统中功能点的版本控制","date":"2017-09-21T10:40:41.000Z","updated":"2021-05-05T03:20:45.607Z","comments":true,"path":"系统中功能点的版本控制/","link":"","permalink":"https://mx-go.github.io/%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%8A%9F%E8%83%BD%E7%82%B9%E7%9A%84%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/","excerpt":"引言​ 开发过程中我们会使用版本控制工具，如SVN、Git等。但是我们一样会遇到一种情形：在一套试题系统中，有新建题目、编辑题目、删除题目等功能，且题目可以被多个人修改，每人修改一次即是一个版本。现在的需求就是需要记录每一次修改的详细信息，每次版本之间的差异，甚至还可以版本回滚。 ​ 例如题目编号为20170919170800000061的题目被A创建，依次被B、C、D各修改了一次，此时需要比较B和A间的差异、C和B间的差异、D和C间的差异，到最后审核阶段如果B 的版本比较符合，则需要把试题版本内容回滚到B版本作为最后的版本。","text":"引言​ 开发过程中我们会使用版本控制工具，如SVN、Git等。但是我们一样会遇到一种情形：在一套试题系统中，有新建题目、编辑题目、删除题目等功能，且题目可以被多个人修改，每人修改一次即是一个版本。现在的需求就是需要记录每一次修改的详细信息，每次版本之间的差异，甚至还可以版本回滚。 ​ 例如题目编号为20170919170800000061的题目被A创建，依次被B、C、D各修改了一次，此时需要比较B和A间的差异、C和B间的差异、D和C间的差异，到最后审核阶段如果B 的版本比较符合，则需要把试题版本内容回滚到B版本作为最后的版本。 仔细分析一下题干，我们的需求是1.比较版本的差异，2.版本的回滚。之前有考虑过两种方案： 修改时在前端进行比较，只记录版本的差异，后台只需要进行存取即可。 把所有版本信息全部存储在数据库，在请求时后台进行比较差异。 第一种方案带来的问题是没法进行版本回滚，只记录下来了差异，回滚时将会是灾难，那么第二种方案才是较合适的选择。 下图是数据库中的版本修改记录 题目的所有信息全部存储在itemJson中，比较版本间的差异即是比较版本间的itemJson，现在的目标就是要提取两个版本中itemJson中的差异。 通过从网上查找资料找到了两种比较合适的方法，值得借鉴一下。 版本差异（比较Json的方法）计较两个Json(X，Y)，其中可能情况： X和Y中均有相同字段 X中存在Y中不存在的字段 Y中存在X中不存在的字段 需要掌握： 各个字段的用处和意义 字段在Map、Json、JavaBean、List、JsonString形态之间的转换 通过Map间接比较引入Maven依赖123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.0&lt;/version&gt;&lt;/dependency&gt; 定义静态工具类123456789101112131415//处理json字符串public static &lt;T&gt; T readJsonToObject(String jsonString, TypeReference&lt;T&gt; tr) &#123; ObjectMapper objectMapper = new ObjectMapper(); if (jsonString == null || &quot;&quot;.equals(jsonString)) &#123; return null; &#125; else &#123; try &#123; return (T) objectMapper.readValue(jsonString, tr); &#125; catch (Exception e) &#123; logger.debug(&quot;json error:&quot; + e); &#125; &#125; return null;&#125; 定义Map比较的工具类​ 通过google的guava表达式中的 *Maps.difference(map1,map2)*方法进行比较，单此方法可比较正常的Map和String内容，对于List方式的比较，同时进行了数值和list内容顺序的比较，显然不符合我们的匹配规则，所以我们要对这个方法配合List的containAll方法进一步做封装。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public static List&lt;Map&lt;String, String&gt;&gt; compareMap(Map&lt;String, Object&gt; oldVersion, Map&lt;String, Object&gt; newVersion) &#123; MapDifference&lt;String, Object&gt; difference = Maps.difference(oldVersion, newVersion); // 获取所有不同点 Map&lt;String, MapDifference.ValueDifference&lt;Object&gt;&gt; differenceMap = difference.entriesDiffering(); List&lt;Map&lt;String, String&gt;&gt; result = new ArrayList&lt;&gt;(); Iterator diffIterator = differenceMap.entrySet().iterator(); while (diffIterator.hasNext()) &#123; Map.Entry entry = (java.util.Map.Entry) diffIterator.next(); MapDifference.ValueDifference&lt;Object&gt; valueDifference = (MapDifference.ValueDifference&lt;Object&gt;) entry .getValue(); boolean isList = valueDifference.leftValue() instanceof List &amp;&amp; valueDifference.rightValue() instanceof List; boolean isMap = valueDifference.leftValue() instanceof Map &amp;&amp; valueDifference.rightValue() instanceof Map; if (!isList &amp;&amp; !isMap) &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String fieldKey = String.valueOf(entry.getKey()); // 选择题中选项内容改变 if (oldVersion.get(&quot;content&quot;) != null &amp;&amp; oldVersion.get(&quot;name&quot;) != null) &#123; map.put(&quot;fieldName&quot;, judgeOption(oldVersion.get(&quot;name&quot;).toString())); &#125; else &#123; map.put(&quot;fieldName&quot;, judgeFiledName(fieldKey)); &#125; map.put(&quot;fieldKey&quot;, fieldKey); map.put(&quot;oldValue&quot;, judgeFiledKey(fieldKey, valueDifference.leftValue().toString())); map.put(&quot;newValue&quot;, judgeFiledKey(fieldKey, valueDifference.rightValue().toString())); result.add(map); &#125; // 处理结果是否为List,则递归执行比较规则 if (valueDifference.leftValue() instanceof List &amp;&amp; valueDifference.rightValue() instanceof List) &#123; JSONArray j = JSONArray.parseArray(JSON.toJSONString(valueDifference.leftValue())); JSONArray p = JSONArray.parseArray(JSON.toJSONString(valueDifference.rightValue())); JSONObject js = new JSONObject(); JSONObject js1 = new JSONObject(); for (int i = 0; i &lt; j.size(); i++) &#123; js.put(i + &quot;&quot;, j.get(i)); &#125; for (int i = 0; i &lt; p.size(); i++) &#123; js1.put(i + &quot;&quot;, p.get(i)); &#125; Map&lt;String, Object&gt; requestMap = JsonUtils.readJsonToObject(js.toString(), new TypeReference&lt;Map&lt;String, Object&gt;&gt;() &#123; &#125;); Map&lt;String, Object&gt; requestMap1 = JsonUtils.readJsonToObject(js1.toString(), new TypeReference&lt;Map&lt;String, Object&gt;&gt;() &#123; &#125;); List&lt;Map&lt;String, String&gt;&gt; m = compareMap(requestMap, requestMap1); //当修改多个选项 for (int i = 0; i &lt; m.size(); i++) &#123; result.add(compareMap(requestMap, requestMap1).get(i)); &#125; &#125; // 处理结果是否为Map,则递归执行比较规则 if (valueDifference.leftValue() instanceof Map &amp;&amp; valueDifference.rightValue() instanceof Map) &#123; result.add(compareMap((Map&lt;String, Object&gt;) valueDifference.leftValue(), (Map&lt;String, Object&gt;) valueDifference.rightValue()).get(0)); &#125; &#125; // 若A中有B中不存在的值 Map&lt;String, Object&gt; entriesOnlyOnLeft = difference.entriesOnlyOnLeft(); if (entriesOnlyOnLeft != null &amp;&amp; !entriesOnlyOnLeft.isEmpty()) &#123; Iterator it = entriesOnlyOnLeft.entrySet().iterator(); while (it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = (java.util.Map.Entry) it.next(); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String fieldKey = entry.getKey(); map.put(&quot;fieldKey&quot;, fieldKey); map.put(&quot;fieldName&quot;, judgeFiledName(fieldKey)); map.put(&quot;oldValue&quot;, judgeFiledKey(fieldKey, String.valueOf(entry.getValue()))); map.put(&quot;newValue&quot;, &quot;&quot;); result.add(map); &#125; &#125; // 若B中有A中不存在的值 Map&lt;String, Object&gt; onlyOnRightMap = difference.entriesOnlyOnRight(); if (onlyOnRightMap != null &amp;&amp; !onlyOnRightMap.isEmpty()) &#123; Iterator it = onlyOnRightMap.entrySet().iterator(); while (it.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = (java.util.Map.Entry) it.next(); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String fieldKey = String.valueOf(entry.getKey()); map.put(&quot;fieldKey&quot;, fieldKey); map.put(&quot;fieldName&quot;, judgeFiledName(fieldKey)); map.put(&quot;oldValue&quot;, &quot;&quot;); map.put(&quot;newValue&quot;, judgeFiledKey(fieldKey, String.valueOf(entry.getValue()))); result.add(map); &#125; &#125; return result; &#125; 定义静态调用方法1234567public static List&lt;Map&lt;String, String&gt;&gt; compareJSON(String jsonOld, String jsonNew) &#123; Map&lt;String, Object&gt; oldVersion = JsonUtils.readJsonToObject(jsonOld, new TypeReference&lt;Map&lt;String, Object&gt;&gt;() &#123; &#125;); Map&lt;String, Object&gt; newVersion = JsonUtils.readJsonToObject(jsonNew, new TypeReference&lt;Map&lt;String, Object&gt;&gt;() &#123; &#125;); return compareMap(oldVersion, newVersion); &#125; 返回结果经过处理后的返回结果 1234567891011121314151617181920212223242526272829303132333435363738[ &#123; &quot;newValue&quot;: &quot;10&quot;, &quot;fieldName&quot;: &quot;分数&quot;, &quot;fieldKey&quot;: &quot;score&quot;, &quot;oldValue&quot;: &quot;8&quot; &#125;, &#123; &quot;newValue&quot;: &quot;10&quot;, &quot;fieldName&quot;: &quot;教材依据&quot;, &quot;fieldKey&quot;: &quot;teachingMaterialBasis&quot;, &quot;oldValue&quot;: &quot;2&quot; &#125;, &#123; &quot;newValue&quot;: &quot;2&quot;, &quot;fieldName&quot;: &quot;大纲依据&quot;, &quot;fieldKey&quot;: &quot;syllabusBasis&quot;, &quot;oldValue&quot;: &quot;1&quot; &#125;, &#123; &quot;newValue&quot;: &quot;1.0&quot;, &quot;fieldName&quot;: &quot;难度系数&quot;, &quot;fieldKey&quot;: &quot;difficult&quot;, &quot;oldValue&quot;: &quot;0.4&quot; &#125;, &#123; &quot;newValue&quot;: &quot;掌握&quot;, &quot;fieldName&quot;: &quot;能力层次&quot;, &quot;fieldKey&quot;: &quot;abilityLevel&quot;, &quot;oldValue&quot;: &quot;熟悉&quot; &#125;, &#123; &quot;newValue&quot;: &quot;测试关键词&quot;, &quot;fieldName&quot;: &quot;关键字&quot;, &quot;fieldKey&quot;: &quot;keyWord&quot;, &quot;oldValue&quot;: &quot;个&quot; &#125; ] 查看所有源码点击：下载 转为JavaBean比较将itemJson字符串转化为JavaBean，比较JavaBean之前的差异。比较JavaBean间的差异可以用Javers。 引入Javers的Maven依赖12345&lt;dependency&gt; &lt;groupId&gt;org.javers&lt;/groupId&gt; &lt;artifactId&gt;javers-core&lt;/artifactId&gt; &lt;version&gt;3.5.0&lt;/version&gt;&lt;/dependency&gt; 将itemJson转为JavaBean方式一：利用Jackson工具类JsonUtils12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class JsonUtils &#123; // 定义jackson对象 private static final ObjectMapper MAPPER = new ObjectMapper(); /** * 将对象转换成json字符串。 * &lt;p&gt;Title: pojoToJson&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * @param data * @return */ public static String objectToJson(Object data) &#123; try &#123; String string = MAPPER.writeValueAsString(data); return string; &#125; catch (JsonProcessingException e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 将json结果集转化为对象 * * @param jsonData json数据 * @param clazz 对象中的object类型 * @return */ public static &lt;T&gt; T jsonToPojo(String jsonData, Class&lt;T&gt; beanType) &#123; try &#123; T t = MAPPER.readValue(jsonData, beanType); return t; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125; /** * 将json数据转换成pojo对象list * &lt;p&gt;Title: jsonToList&lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * @param jsonData * @param beanType * @return */ public static &lt;T&gt;List&lt;T&gt; jsonToList(String jsonData, Class&lt;T&gt; beanType) &#123; JavaType javaType = MAPPER.getTypeFactory().constructParametricType(List.class, beanType); try &#123; List&lt;T&gt; list = MAPPER.readValue(jsonData, javaType); return list; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; Json转Pojo12Item item1 = JsonUtils.jsonToPojo(itemJsonOld, Item.class);Item item2 = JsonUtils.jsonToPojo(itemJsonNew, Item.class); 方式二：利用fastJson引入Maven依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.1.26&lt;/version&gt;&lt;/dependency&gt; Json转Pojo12Item item1 = JSONObject.parseObject(json3, Item.class);Item item2 = JSONObject.parseObject(json4, Item.class); 利用Javers比较JavaBean1234567891011Javers j = JaversBuilder.javers().build(); Diff diff = j.compare(item1, item2); if (diff.hasChanges()) &#123; List&lt;Change&gt; changes = diff.getChanges(); for (Change change : changes) &#123; if (change instanceof ValueChange) &#123; ValueChange valChange = (ValueChange) change; System.out.println(valChange.getPropertyName() + &quot; -- &quot; + valChange.getLeft() + &quot;--&quot; + valChange.getRight()); &#125; &#125; &#125; 版本回滚​ 其实版本回滚在上面的比较中已经说了，就是把需要回滚的版本itemJson转化为JavaBean传给前台，同时生成一份最新的版本为当前版本，记录操作人、操作时间等等记录即可。需要了解及使用Gson、fastJson、Jackson的使用，及使用工具将Map、Json、JavaBean、List、JsonString对象之间状态的转换。 总结 熟悉业务。 掌握Map、Json、JavaBean、List、JsonString对象之间状态的转换。 版本需要存储所有信息便于回滚。 个人倾向使用Javers比较JavaBean进行比较版本差异。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"Spring+Mybatis之Mapper热部署","slug":"Spring-Mybatis之Mapper热部署","date":"2017-09-15T08:52:07.000Z","updated":"2021-05-05T03:13:42.629Z","comments":true,"path":"Spring-Mybatis之Mapper热部署/","link":"","permalink":"https://mx-go.github.io/Spring-Mybatis%E4%B9%8BMapper%E7%83%AD%E9%83%A8%E7%BD%B2/","excerpt":"引言​ Spring+Mybatis经常用，在项目中最痛苦的就是修改mapper文件的时候需要重启一下项目，每修改一次就需要重启一次项目。项目小还好，如果项目大，重启一次项目简直是要命。所以，去网上查资料看有没有办法让mybatis热部署，每次更新mapper文件不需要重启项目。 ​ 功夫不负有心人，终于找到了，这玩意只要发现mapper文件被修改，就会重新加载被修改的mapper文件。且只加载被修改的mapper文件！这个可省事了，效率又高，简直爽到爆。","text":"引言​ Spring+Mybatis经常用，在项目中最痛苦的就是修改mapper文件的时候需要重启一下项目，每修改一次就需要重启一次项目。项目小还好，如果项目大，重启一次项目简直是要命。所以，去网上查资料看有没有办法让mybatis热部署，每次更新mapper文件不需要重启项目。 ​ 功夫不负有心人，终于找到了，这玩意只要发现mapper文件被修改，就会重新加载被修改的mapper文件。且只加载被修改的mapper文件！这个可省事了，效率又高，简直爽到爆。 创建MapperRefresh刷新类在src下创建一个util包，包下面创建一个类，类名为：MapperRefresh 代码为下面的一串，注意修改下mybatis-refresh.properties 的路径。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359package com.talkweb.nets.netsTestLib.data.util;import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.InputStream; import java.lang.reflect.Field; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.Set; import org.apache.commons.lang3.StringUtils; import org.apache.ibatis.builder.xml.XMLMapperBuilder; import org.apache.ibatis.executor.ErrorContext; import org.apache.ibatis.session.Configuration; import org.apache.log4j.Logger; import org.springframework.core.NestedIOException; import org.springframework.core.io.Resource; import com.google.common.collect.Sets; /** * 刷新MyBatis Mapper XML 线程 * @author ThinkGem 这个是原著的作者，我只是直接拿来用了，原著莫怪 * @version 2016-5-29 */ public class MapperRefresh implements java.lang.Runnable &#123; public static Logger log = Logger.getLogger(MapperRefresh.class); private static String filename = &quot;mybatis-refresh.properties&quot;; //注意修改路径 private static Properties prop = new Properties(); private static boolean enabled; // 是否启用Mapper刷新线程功能 private static boolean refresh; // 刷新启用后，是否启动了刷新线程 private Set&lt;String&gt; location; // Mapper实际资源路径 private Resource[] mapperLocations; // Mapper资源路径 private Configuration configuration; // MyBatis配置对象 private Long beforeTime = 0L; // 上一次刷新时间 private static int delaySeconds; // 延迟刷新秒数 private static int sleepSeconds; // 休眠时间 private static String mappingPath; // xml文件夹匹配字符串，需要根据需要修改 static &#123; try &#123; prop.load(MapperRefresh.class.getResourceAsStream(filename)); &#125; catch (Exception e) &#123; e.printStackTrace(); System.out.println(&quot;Load mybatis-refresh “&quot;+filename+&quot;” file error.&quot;); &#125; enabled = &quot;true&quot;.equalsIgnoreCase(getPropString(&quot;enabled&quot;)); delaySeconds = getPropInt(&quot;delaySeconds&quot;); sleepSeconds = getPropInt(&quot;sleepSeconds&quot;); mappingPath = getPropString(&quot;mappingPath&quot;); delaySeconds = delaySeconds == 0 ? 50 : delaySeconds; sleepSeconds = sleepSeconds == 0 ? 3 : sleepSeconds; mappingPath = StringUtils.isBlank(mappingPath) ? &quot;mappings&quot; : mappingPath; log.debug(&quot;[enabled] &quot; + enabled); log.debug(&quot;[delaySeconds] &quot; + delaySeconds); log.debug(&quot;[sleepSeconds] &quot; + sleepSeconds); log.debug(&quot;[mappingPath] &quot; + mappingPath); &#125; public static boolean isRefresh() &#123; return refresh; &#125; public MapperRefresh(Resource[] mapperLocations, Configuration configuration) &#123; this.mapperLocations = mapperLocations; this.configuration = configuration; &#125; @Override public void run() &#123; beforeTime = System.currentTimeMillis(); log.debug(&quot;[location] &quot; + location); log.debug(&quot;[configuration] &quot; + configuration); if (enabled) &#123; // 启动刷新线程 final MapperRefresh runnable = this; new Thread(new java.lang.Runnable() &#123; @Override public void run() &#123; if (location == null)&#123; location = Sets.newHashSet(); log.debug(&quot;MapperLocation&#x27;s length:&quot; + mapperLocations.length); for (Resource mapperLocation : mapperLocations) &#123; String s = mapperLocation.toString().replaceAll(&quot;\\\\\\\\&quot;, &quot;/&quot;); s = s.substring(&quot;file [&quot;.length(), s.lastIndexOf(mappingPath) + mappingPath.length()); if (!location.contains(s)) &#123; location.add(s); log.debug(&quot;Location:&quot; + s); &#125; &#125; log.debug(&quot;Locarion&#x27;s size:&quot; + location.size()); &#125; try &#123; Thread.sleep(delaySeconds * 1000); &#125; catch (InterruptedException e2) &#123; e2.printStackTrace(); &#125; refresh = true; System.out.println(&quot;========= Enabled refresh mybatis mapper =========&quot;); while (true) &#123; try &#123; for (String s : location) &#123; runnable.refresh(s, beforeTime); &#125; &#125; catch (Exception e1) &#123; e1.printStackTrace(); &#125; try &#123; Thread.sleep(sleepSeconds * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;, &quot;MyBatis-Mapper-Refresh&quot;).start(); &#125; &#125; /** * 执行刷新 * @param filePath 刷新目录 * @param beforeTime 上次刷新时间 * @throws NestedIOException 解析异常 * @throws FileNotFoundException 文件未找到 * @author ThinkGem */ @SuppressWarnings(&#123; &quot;rawtypes&quot;, &quot;unchecked&quot; &#125;) private void refresh(String filePath, Long beforeTime) throws Exception &#123; // 本次刷新时间 Long refrehTime = System.currentTimeMillis(); // 获取需要刷新的Mapper文件列表 List&lt;File&gt; fileList = this.getRefreshFile(new File(filePath), beforeTime); if (fileList.size() &gt; 0) &#123; log.debug(&quot;Refresh file: &quot; + fileList.size()); &#125; for (int i = 0; i &lt; fileList.size(); i++) &#123; InputStream inputStream = new FileInputStream(fileList.get(i)); String resource = fileList.get(i).getAbsolutePath(); try &#123; // 清理原有资源，更新为自己的StrictMap方便，增量重新加载 String[] mapFieldNames = new String[]&#123; &quot;mappedStatements&quot;, &quot;caches&quot;, &quot;resultMaps&quot;, &quot;parameterMaps&quot;, &quot;keyGenerators&quot;, &quot;sqlFragments&quot; &#125;; for (String fieldName : mapFieldNames)&#123; Field field = configuration.getClass().getDeclaredField(fieldName); field.setAccessible(true); Map map = ((Map)field.get(configuration)); if (!(map instanceof StrictMap))&#123; Map newMap = new StrictMap(StringUtils.capitalize(fieldName) + &quot;collection&quot;); for (Object key : map.keySet())&#123; try &#123; newMap.put(key, map.get(key)); &#125;catch(IllegalArgumentException ex)&#123; newMap.put(key, ex.getMessage()); &#125; &#125; field.set(configuration, newMap); &#125; &#125; // 清理已加载的资源标识，方便让它重新加载。 Field loadedResourcesField = configuration.getClass().getDeclaredField(&quot;loadedResources&quot;); loadedResourcesField.setAccessible(true); Set loadedResourcesSet = ((Set)loadedResourcesField.get(configuration)); loadedResourcesSet.remove(resource); //重新编译加载资源文件。 XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(inputStream, configuration, resource, configuration.getSqlFragments()); xmlMapperBuilder.parse(); &#125; catch (Exception e) &#123; throw new NestedIOException(&quot;Failed to parse mapping resource: &#x27;&quot; + resource + &quot;&#x27;&quot;, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; System.out.println(&quot;Refresh file: &quot; + mappingPath + StringUtils.substringAfterLast(fileList.get(i).getAbsolutePath(), mappingPath)); if (log.isDebugEnabled()) &#123; log.debug(&quot;Refresh file: &quot; + fileList.get(i).getAbsolutePath()); log.debug(&quot;Refresh filename: &quot; + fileList.get(i).getName()); &#125; &#125; // 如果刷新了文件，则修改刷新时间，否则不修改 if (fileList.size() &gt; 0) &#123; this.beforeTime = refrehTime; &#125; &#125; /** * 获取需要刷新的文件列表 * @param dir 目录 * @param beforeTime 上次刷新时间 * @return 刷新文件列表 */ private List&lt;File&gt; getRefreshFile(File dir, Long beforeTime) &#123; List&lt;File&gt; fileList = new ArrayList&lt;File&gt;(); File[] files = dir.listFiles(); if (files != null) &#123; for (int i = 0; i &lt; files.length; i++) &#123; File file = files[i]; if (file.isDirectory()) &#123; fileList.addAll(this.getRefreshFile(file, beforeTime)); &#125; else if (file.isFile()) &#123; if (this.checkFile(file, beforeTime)) &#123; fileList.add(file); &#125; &#125; else &#123; System.out.println(&quot;Error file.&quot; + file.getName()); &#125; &#125; &#125; return fileList; &#125; /** * 判断文件是否需要刷新 * @param file 文件 * @param beforeTime 上次刷新时间 * @return 需要刷新返回true，否则返回false */ private boolean checkFile(File file, Long beforeTime) &#123; if (file.lastModified() &gt; beforeTime) &#123; return true; &#125; return false; &#125; /** * 获取整数属性 * @param key * @return */ private static int getPropInt(String key) &#123; int i = 0; try &#123; i = Integer.parseInt(getPropString(key)); &#125; catch (Exception e) &#123; &#125; return i; &#125; /** * 获取字符串属性 * @param key * @return */ private static String getPropString(String key) &#123; return prop == null ? null : prop.getProperty(key); &#125; /** * 重写 org.apache.ibatis.session.Configuration.StrictMap 类 * 来自 MyBatis3.4.0版本，修改 put 方法，允许反复 put更新。 */ public static class StrictMap&lt;V&gt; extends HashMap&lt;String, V&gt; &#123; private static final long serialVersionUID = -4950446264854982944L; private String name; public StrictMap(String name, int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); this.name = name; &#125; public StrictMap(String name, int initialCapacity) &#123; super(initialCapacity); this.name = name; &#125; public StrictMap(String name) &#123; super(); this.name = name; &#125; public StrictMap(String name, Map&lt;String, ? extends V&gt; m) &#123; super(m); this.name = name; &#125; @SuppressWarnings(&quot;unchecked&quot;) public V put(String key, V value) &#123; // ThinkGem 如果现在状态为刷新，则刷新(先删除后添加) if (MapperRefresh.isRefresh()) &#123; remove(key); MapperRefresh.log.debug(&quot;refresh key:&quot; + key.substring(key.lastIndexOf(&quot;.&quot;) + 1)); &#125; // ThinkGem end if (containsKey(key)) &#123; throw new IllegalArgumentException(name + &quot; already contains value for &quot; + key); &#125; if (key.contains(&quot;.&quot;)) &#123; final String shortKey = getShortName(key); if (super.get(shortKey) == null) &#123; super.put(shortKey, value); &#125; else &#123; super.put(shortKey, (V) new Ambiguity(shortKey)); &#125; &#125; return super.put(key, value); &#125; public V get(Object key) &#123; V value = super.get(key); if (value == null) &#123; throw new IllegalArgumentException(name + &quot; does not contain value for &quot; + key); &#125; if (value instanceof Ambiguity) &#123; throw new IllegalArgumentException(((Ambiguity) value).getSubject() + &quot; is ambiguous in &quot; + name + &quot; (try using the full name including the namespace, or rename one of the entries)&quot;); &#125; return value; &#125; private String getShortName(String key) &#123; final String[] keyparts = key.split(&quot;\\\\.&quot;); return keyparts[keyparts.length - 1]; &#125; protected static class Ambiguity &#123; private String subject; public Ambiguity(String subject) &#123; this.subject = subject; &#125; public String getSubject() &#123; return subject; &#125; &#125; &#125; &#125; 重写SqlSessionFactoryBeanMyBatis有几个不太好的地方，是当实体类别名重名的时候，Mapper XML有错误的时候，系统启动时会一直等待无法正常启动（其实是加载失败后又重新加载，进入了死循环），这里重写下SqlSessionFactoryBean.java文件，解决这个问题，在这个文件里也加入启动上面写的线程类： 1、修改实体类重名的时候抛出并打印异常，否则系统会一直递归造成无法启动。2、MapperXML有错误的时候抛出并打印异常，否则系统会一直递归造成无法启动。3、加入启动MapperRefresh.java线程服务。 思路就是用我们自己重写的SqlSessionFactoryBean.class替换mybatis-spring-1.2.2.jar中的SqlSessionFactoryBean.class。 在当前项目下新建一个包：右键 src &gt; new Package &gt; org.mybatis.spring，创建SqlSessionFactoryBean.java类。 复制下面一串代码到SqlSessionFactoryBean.java，注意导入MapperRefresh正确的包。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313package org.mybatis.spring;import java.io.IOException;import java.sql.SQLException;import java.util.Properties;import javax.sql.DataSource;import org.apache.ibatis.builder.xml.XMLConfigBuilder;import org.apache.ibatis.builder.xml.XMLMapperBuilder;import org.apache.ibatis.executor.ErrorContext;import org.apache.ibatis.logging.Log;import org.apache.ibatis.logging.LogFactory;import org.apache.ibatis.mapping.DatabaseIdProvider;import org.apache.ibatis.mapping.Environment;import org.apache.ibatis.plugin.Interceptor;import org.apache.ibatis.reflection.factory.ObjectFactory;import org.apache.ibatis.reflection.wrapper.ObjectWrapperFactory;import org.apache.ibatis.session.Configuration;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.ibatis.transaction.TransactionFactory;import org.apache.ibatis.type.TypeAliasRegistry;import org.apache.ibatis.type.TypeHandler;import org.apache.ibatis.type.TypeHandlerRegistry;import org.mybatis.spring.transaction.SpringManagedTransactionFactory;import org.springframework.beans.factory.FactoryBean;import org.springframework.beans.factory.InitializingBean;import org.springframework.context.ApplicationEvent;import org.springframework.context.ApplicationListener;import org.springframework.context.event.ContextRefreshedEvent;import org.springframework.core.NestedIOException;import org.springframework.core.io.Resource;import org.springframework.jdbc.datasource.TransactionAwareDataSourceProxy;import org.springframework.util.Assert;import org.springframework.util.ObjectUtils;import org.springframework.util.StringUtils;import com.talkweb.nets.netsTestLib.data.util.MapperRefresh;public class SqlSessionFactoryBean implements FactoryBean&lt;SqlSessionFactory&gt;, InitializingBean, ApplicationListener&lt;ApplicationEvent&gt; &#123; private static final Log logger = LogFactory.getLog(SqlSessionFactoryBean.class); private Resource configLocation; private Resource[] mapperLocations; private DataSource dataSource; private TransactionFactory transactionFactory; private Properties configurationProperties; private SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); private SqlSessionFactory sqlSessionFactory; private String environment = SqlSessionFactoryBean.class.getSimpleName(); private boolean failFast; private Interceptor[] plugins; private TypeHandler&lt;?&gt;[] typeHandlers; private String typeHandlersPackage; private Class&lt;?&gt;[] typeAliases; private String typeAliasesPackage; private Class&lt;?&gt; typeAliasesSuperType; private DatabaseIdProvider databaseIdProvider; private ObjectFactory objectFactory; private ObjectWrapperFactory objectWrapperFactory; public void setObjectFactory(ObjectFactory objectFactory) &#123; this.objectFactory = objectFactory; &#125; public void setObjectWrapperFactory(ObjectWrapperFactory objectWrapperFactory) &#123; this.objectWrapperFactory = objectWrapperFactory; &#125; public DatabaseIdProvider getDatabaseIdProvider() &#123; return this.databaseIdProvider; &#125; public void setDatabaseIdProvider(DatabaseIdProvider databaseIdProvider) &#123; this.databaseIdProvider = databaseIdProvider; &#125; public void setPlugins(Interceptor[] plugins) &#123; this.plugins = plugins; &#125; public void setTypeAliasesPackage(String typeAliasesPackage) &#123; this.typeAliasesPackage = typeAliasesPackage; &#125; public void setTypeAliasesSuperType(Class&lt;?&gt; typeAliasesSuperType) &#123; this.typeAliasesSuperType = typeAliasesSuperType; &#125; public void setTypeHandlersPackage(String typeHandlersPackage) &#123; this.typeHandlersPackage = typeHandlersPackage; &#125; public void setTypeHandlers(TypeHandler&lt;?&gt;[] typeHandlers) &#123; this.typeHandlers = typeHandlers; &#125; public void setTypeAliases(Class&lt;?&gt;[] typeAliases) &#123; this.typeAliases = typeAliases; &#125; public void setFailFast(boolean failFast) &#123; this.failFast = failFast; &#125; public void setConfigLocation(Resource configLocation) &#123; this.configLocation = configLocation; &#125; public void setMapperLocations(Resource[] mapperLocations) &#123; this.mapperLocations = mapperLocations; &#125; public void setConfigurationProperties(Properties sqlSessionFactoryProperties) &#123; this.configurationProperties = sqlSessionFactoryProperties; &#125; public void setDataSource(DataSource dataSource) &#123; if ((dataSource instanceof TransactionAwareDataSourceProxy)) &#123; this.dataSource = ((TransactionAwareDataSourceProxy) dataSource).getTargetDataSource(); &#125; else this.dataSource = dataSource; &#125; public void setSqlSessionFactoryBuilder(SqlSessionFactoryBuilder sqlSessionFactoryBuilder) &#123; this.sqlSessionFactoryBuilder = sqlSessionFactoryBuilder; &#125; public void setTransactionFactory(TransactionFactory transactionFactory) &#123; this.transactionFactory = transactionFactory; &#125; public void setEnvironment(String environment) &#123; this.environment = environment; &#125; public void afterPropertiesSet() throws Exception &#123; Assert.notNull(this.dataSource, &quot;Property &#x27;dataSource&#x27; is required&quot;); Assert.notNull(this.sqlSessionFactoryBuilder, &quot;Property &#x27;sqlSessionFactoryBuilder&#x27; is required&quot;); this.sqlSessionFactory = buildSqlSessionFactory(); &#125; protected SqlSessionFactory buildSqlSessionFactory() throws IOException &#123; XMLConfigBuilder xmlConfigBuilder = null; Configuration configuration; if (this.configLocation != null) &#123; xmlConfigBuilder = new XMLConfigBuilder(this.configLocation.getInputStream(), null, this.configurationProperties); configuration = xmlConfigBuilder.getConfiguration(); &#125; else &#123; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Property &#x27;configLocation&#x27; not specified, using default MyBatis Configuration&quot;); &#125; configuration = new Configuration(); configuration.setVariables(this.configurationProperties); &#125; if (this.objectFactory != null) &#123; configuration.setObjectFactory(this.objectFactory); &#125; if (this.objectWrapperFactory != null) &#123; configuration.setObjectWrapperFactory(this.objectWrapperFactory); &#125; if (StringUtils.hasLength(this.typeAliasesPackage)) &#123; String[] typeAliasPackageArray = StringUtils.tokenizeToStringArray(this.typeAliasesPackage, &quot;,; \\t\\n&quot;); for (String packageToScan : typeAliasPackageArray) &#123; // 修改处：ThinkGem 修改实体类重名的时候抛出并打印异常，否则系统会一直递归造成无法启动 try &#123; configuration.getTypeAliasRegistry().registerAliases(packageToScan, typeAliasesSuperType == null ? Object.class : typeAliasesSuperType); &#125; catch (Exception ex) &#123; logger.error(&quot;Scanned package: &#x27;&quot; + packageToScan + &quot;&#x27; for aliases&quot;, ex); throw new NestedIOException(&quot;Scanned package: &#x27;&quot; + packageToScan + &quot;&#x27; for aliases&quot;, ex); &#125; finally &#123; ErrorContext.instance().reset(); &#125; // 修改处：ThinkGem end if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Scanned package: &#x27;&quot; + packageToScan + &quot;&#x27; for aliases&quot;); &#125; &#125; &#125; if (!ObjectUtils.isEmpty(this.typeAliases)) &#123; for (Class typeAlias : this.typeAliases) &#123; configuration.getTypeAliasRegistry().registerAlias(typeAlias); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Registered type alias: &#x27;&quot; + typeAlias + &quot;&#x27;&quot;); &#125; &#125; &#125; if (!ObjectUtils.isEmpty(this.plugins)) &#123; for (Interceptor plugin : this.plugins) &#123; configuration.addInterceptor(plugin); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Registered plugin: &#x27;&quot; + plugin + &quot;&#x27;&quot;); &#125; &#125; &#125; if (StringUtils.hasLength(this.typeHandlersPackage)) &#123; String[] typeHandlersPackageArray = StringUtils.tokenizeToStringArray(this.typeHandlersPackage, &quot;,; \\t\\n&quot;); for (String packageToScan : typeHandlersPackageArray) &#123; configuration.getTypeHandlerRegistry().register(packageToScan); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Scanned package: &#x27;&quot; + packageToScan + &quot;&#x27; for type handlers&quot;); &#125; &#125; &#125; if (!ObjectUtils.isEmpty(this.typeHandlers)) &#123; for (TypeHandler typeHandler : this.typeHandlers) &#123; configuration.getTypeHandlerRegistry().register(typeHandler); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Registered type handler: &#x27;&quot; + typeHandler + &quot;&#x27;&quot;); &#125; &#125; &#125; if (xmlConfigBuilder != null) &#123; try &#123; xmlConfigBuilder.parse(); if (logger.isDebugEnabled()) logger.debug(&quot;Parsed configuration file: &#x27;&quot; + this.configLocation + &quot;&#x27;&quot;); &#125; catch (Exception ex) &#123; throw new NestedIOException(&quot;Failed to parse config resource: &quot; + this.configLocation, ex); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; if (this.transactionFactory == null) &#123; this.transactionFactory = new SpringManagedTransactionFactory(); &#125; Environment environment = new Environment(this.environment, this.transactionFactory, this.dataSource); configuration.setEnvironment(environment); if (this.databaseIdProvider != null) &#123; try &#123; configuration.setDatabaseId(this.databaseIdProvider.getDatabaseId(this.dataSource)); &#125; catch (SQLException e) &#123; throw new NestedIOException(&quot;Failed getting a databaseId&quot;, e); &#125; &#125; if (!ObjectUtils.isEmpty(this.mapperLocations)) &#123; for (Resource mapperLocation : this.mapperLocations) &#123; if (mapperLocation == null) &#123; continue; &#125; try &#123; XMLMapperBuilder xmlMapperBuilder = new XMLMapperBuilder(mapperLocation.getInputStream(), configuration, mapperLocation.toString(), configuration.getSqlFragments()); xmlMapperBuilder.parse(); &#125; catch (Exception e) &#123; // 修改处：ThinkGem MapperXML有错误的时候抛出并打印异常，否则系统会一直递归造成无法启动 logger.error(&quot;Failed to parse mapping resource: &#x27;&quot; + mapperLocation + &quot;&#x27;&quot;, e); throw new NestedIOException(&quot;Failed to parse mapping resource: &#x27;&quot; + mapperLocation + &quot;&#x27;&quot;, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Parsed mapper file: &#x27;&quot; + mapperLocation + &quot;&#x27;&quot;); &#125; &#125; // 修改处：ThinkGem 启动刷新MapperXML定时器（有助于开发者调试）。 new MapperRefresh(this.mapperLocations, configuration).run(); &#125; else if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Property &#x27;mapperLocations&#x27; was not specified or no matching resources found&quot;); &#125; return this.sqlSessionFactoryBuilder.build(configuration); &#125; public SqlSessionFactory getObject() throws Exception &#123; if (this.sqlSessionFactory == null) &#123; afterPropertiesSet(); &#125; return this.sqlSessionFactory; &#125; public Class&lt;? extends SqlSessionFactory&gt; getObjectType() &#123; return this.sqlSessionFactory == null ? SqlSessionFactory.class : this.sqlSessionFactory.getClass(); &#125; public boolean isSingleton() &#123; return true; &#125; public void onApplicationEvent(ApplicationEvent event) &#123; if ((this.failFast) &amp;&amp; ((event instanceof ContextRefreshedEvent))) &#123; this.sqlSessionFactory.getConfiguration().getMappedStatementNames(); &#125; &#125;&#125; 接下来我们就需要把这个SqlSessionFactoryBean.java文件编译成class文件，然后再复制到mybatis-spring-1.2.2.jar包里面 。重新部署当前项目 Servers &gt; Tomcat 8.x &gt; 右键你的项目 Remove deployment 然后再 Add Deployment…你的项目。 去Tomcat 8的根目录找到对应的SqlSessionFactoryBean.class文件复制出来。 这里记得检查一下编译过的class文件是否正确，将你编译好的SqlSessionFactoryBean.class文件再次拖入，用jd-gui.exe(一款JAVA反编译工具)比较是不是和上面写的代码对应！！！！ 检查无误之后，把SqlSessionFactoryBean.class复制到mybatis-spring-1.2.2.jar(是你本地项目中的jar)包中，替换原来的class文件。 创建mybatis-refresh.properties文件一切准备就绪，还剩下最后一个属性文件， 创建mybatis-refresh.properties文件，记得把文件格式改成UTF-8。 mybatis-refresh.properties文件内容为： 12345678#是否开启刷新线程enabled=true#延迟启动刷新程序的秒数delaySeconds=60 #刷新扫描间隔的时长秒数sleepSeconds=3#扫描Mapper文件的资源路径mappingPath=mapper 测试 删除org.mybatis.spring包及下面的SqlSessionFactoryBean.java文件。 启动项目，然后随便修改一个mapper.xml文件，然后稍等片刻，在控制台出现如下输出，就表示你成功啦！这样就不用重启项目，也能加载到你修改的mapper.xml文件了 。 注意 注意各个文件的位置和名称。 注意MapperRefresh.java文件中mybatis-refresh.properties的路径。 注意用jd-gui.exe检查编译后的SqlSessionFactoryBean.class文件。","categories":[{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"mybatis","slug":"mybatis","permalink":"https://mx-go.github.io/tags/mybatis/"}]},{"title":"Spring-AOP两种配置方式","slug":"spring-aop两种配置方式","date":"2017-09-09T11:44:46.000Z","updated":"2021-05-05T03:29:55.709Z","comments":true,"path":"spring-aop两种配置方式/","link":"","permalink":"https://mx-go.github.io/spring-aop%E4%B8%A4%E7%A7%8D%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F/","excerpt":"引言AOPAOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。","text":"引言AOPAOP（Aspect Oriented Programming），即面向切面编程，可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事务。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 AOP核心概念1、横切关注点 对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点 2、切面（Aspect） 类是对物体特征的抽象，切面就是对横切关注点的抽象 3、连接点（Joinpoint） 被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器 4、切入点（Pointcut） 对连接点进行拦截的定义 5、通知（Advice） 所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类 6、目标对象 代理的目标对象 7、织入（Weave） 将切面应用到目标对象并导致代理对象创建的过程 8、引入（Introduction） 在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段 Spring对AOP的支持Spring中AOP代理由Spring的IOC容器负责生成、管理，其依赖关系也由IOC容器负责管理。因此，AOP代理可以直接使用容器中的其它bean实例作为目标，这种关系可由IOC容器的依赖注入提供。Spring创建代理的规则为： 1、默认使用Java动态代理来创建AOP代理，这样就可以为任何接口实例创建代理了 2、当需要代理的类不是代理接口的时候，Spring会切换为使用CGLIB代理，也可强制使用CGLIB AOP编程其实是很简单的事情，纵观AOP编程，程序员只需要参与三个部分： 1、定义普通业务组件 2、定义切入点，一个切入点可能横切多个业务组件 3、定义增强处理，增强处理就是在AOP框架为普通业务组件织入的处理动作 所以进行AOP编程的关键就是定义切入点和定义增强处理，一旦定义了合适的切入点和增强处理，AOP框架将自动生成AOP代理，即：代理对象的方法=增强处理+被代理对象的方法。 Spring配置AOP的两种方式注解配置AOP注解配置AOP（使用 AspectJ 类库实现的），大致分为三步： 使用注解@Aspect来定义一个切面，在切面中定义切入点(@Pointcut),通知类型(@Before, @AfterReturning,@After,@AfterThrowing,@Around). 开发需要被拦截的类。 将切面配置到xml中，当然，我们也可以使用自动扫描Bean的方式。这样的话，那就交由Spring AOP容器管理。 applicationContext的配置 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.1.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd&quot;&gt; &lt;!-- proxy-target-class等于true是强制使用cglib代理，proxy-target-class默认是false，如果你的类实现了接口 就走JDK代理，如果没有，走cglib代理 --&gt; &lt;!-- 对于单例模式建议使用cglib代理，虽然JDK动态代理比cglib代理速度快，但性能不如cglib --&gt; &lt;!-- 激活自动代理功能 打开aop对@Aspectj的注解支持 ,相当于为注解提供解析功能--&gt; &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt; &lt;!-- 激活组件扫描功能,在包com.spring.aop及其子包下面自动扫描通过注解配置的组件 --&gt; &lt;context:component-scan base-package=&quot;com.spring.aop&quot;/&gt; &lt;!-- 切面 --&gt; &lt;bean id=&quot;serviceAspect&quot; class=&quot;com.spring.aop.aspect.ServiceAspect&quot; /&gt;&lt;/beans&gt; 为Aspect切面类添加注解 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.spring.aop.aspect;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.After;import org.aspectj.lang.annotation.AfterReturning;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Before;import org.aspectj.lang.annotation.Pointcut;import org.springframework.stereotype.Component;/** * 系统服务组件Aspect切面Bean *///声明这是一个组件@Component//声明这是一个切面Bean@Aspectpublic class ServiceAspect &#123; private final static Log log = LogFactory.getLog(ServiceAspect.class); //配置切入点,该方法无方法体,主要为方便同类中其他方法使用此处配置的切入点 @Pointcut(&quot;execution(* com.spring.aop.service..*(..))&quot;) public void aspect()&#123; &#125; /* * 配置前置通知,使用在方法aspect()上注册的切入点 * 同时接受JoinPoint切入点对象,可以没有该参数 */ @Before(&quot;aspect()&quot;) public void before(JoinPoint joinPoint)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;before &quot; + joinPoint); &#125; &#125; //配置后置通知,使用在方法aspect()上注册的切入点 @After(&quot;aspect()&quot;) public void after(JoinPoint joinPoint)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;after &quot; + joinPoint); &#125; &#125; //配置环绕通知,使用在方法aspect()上注册的切入点 @Around(&quot;aspect()&quot;) public void around(JoinPoint joinPoint)&#123; long start = System.currentTimeMillis(); try &#123; ((ProceedingJoinPoint) joinPoint).proceed(); long end = System.currentTimeMillis(); if(log.isInfoEnabled())&#123; log.info(&quot;around &quot; + joinPoint + &quot;\\tUse time : &quot; + (end - start) + &quot; ms!&quot;); &#125; &#125; catch (Throwable e) &#123; long end = System.currentTimeMillis(); if(log.isInfoEnabled())&#123; log.info(&quot;around &quot; + joinPoint + &quot;\\tUse time : &quot; + (end - start) + &quot; ms with exception : &quot; + e.getMessage()); &#125; &#125; &#125; //配置后置返回通知,使用在方法aspect()上注册的切入点 @AfterReturning(&quot;aspect()&quot;) public void afterReturn(JoinPoint joinPoint)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;afterReturn &quot; + joinPoint); &#125; &#125; //配置抛出异常后通知,使用在方法aspect()上注册的切入点 @AfterThrowing(pointcut=&quot;aspect()&quot;, throwing=&quot;ex&quot;) public void afterThrow(JoinPoint joinPoint, Exception ex)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;afterThrow &quot; + joinPoint + &quot;\\t&quot; + ex.getMessage()); &#125; &#125; &#125; UserService.java 123456789101112131415161718192021222324252627282930313233343536package com.spring.aop.service;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import com.spring.mvc.bean.User;/** * 用户服务模型 */public class UserService &#123; private final static Log log = LogFactory.getLog(UserService.class); public User get(long id)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;getUser method . . .&quot;); &#125; return new User(); &#125; public void save(User user)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;saveUser method . . .&quot;); &#125; &#125; public boolean delete(long id) throws Exception&#123; if(log.isInfoEnabled())&#123; log.info(&quot;delete method . . .&quot;); throw new Exception(&quot;spring aop ThrowAdvice演示&quot;); &#125; return false; &#125; &#125; 测试代码 12345678910111213141516171819202122232425262728293031323334package com.spring.aop;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import com.spring.aop.service.UserService;import com.spring.mvc.bean.User;/** * Spring AOP测试 */public class Tester &#123; private final static Log log = LogFactory.getLog(Tester.class); public static void main(String[] args) &#123; //启动Spring容器 ApplicationContext context = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); //获取service组件 UserService service = (UserService) context.getBean(&quot;userService&quot;); //以普通的方式调用UserService对象的三个方法 User user = service.get(1L); service.save(user); try &#123; service.delete(1L); &#125; catch (Exception e) &#123; if(log.isWarnEnabled())&#123; log.warn(&quot;Delete user : &quot; + e.getMessage()); &#125; &#125; &#125;&#125; 控制台输出如下： 12345678910111213141516INFO [spring.aop.aspect.ServiceAspect:40] before execution(User com.spring.aop.service.UserService.get(long))INFO [spring.aop.service.UserService:19] getUser method . . .INFO [spring.aop.aspect.ServiceAspect:60] around execution(User com.spring.aop.service.UserService.get(long)) Use time : 42 ms!INFO [spring.aop.aspect.ServiceAspect:48] after execution(User com.spring.aop.service.UserService.get(long))INFO [spring.aop.aspect.ServiceAspect:74] afterReturn execution(User com.spring.aop.service.UserService.get(long))INFO [spring.aop.aspect.ServiceAspect:40] before execution(void com.spring.aop.service.UserService.save(User))INFO [spring.aop.service.UserService:26] saveUser method . . .INFO [spring.aop.aspect.ServiceAspect:60] around execution(void com.spring.aop.service.UserService.save(User)) Use time : 2 ms!INFO [spring.aop.aspect.ServiceAspect:48] after execution(void com.spring.aop.service.UserService.save(User))INFO [spring.aop.aspect.ServiceAspect:74] afterReturn execution(void com.spring.aop.service.UserService.save(User))INFO [spring.aop.aspect.ServiceAspect:40] before execution(boolean com.spring.aop.service.UserService.delete(long))INFO [spring.aop.service.UserService:32] delete method . . .INFO [spring.aop.aspect.ServiceAspect:65] around execution(boolean com.spring.aop.service.UserService.delete(long)) Use time : 5 ms with exception : spring aop ThrowAdvice演示INFO [spring.aop.aspect.ServiceAspect:48] after execution(boolean com.spring.aop.service.UserService.delete(long))INFO [spring.aop.aspect.ServiceAspect:74] afterReturn execution(boolean com.spring.aop.service.UserService.delete(long))WARN [studio.spring.aop.Tester:32] Delete user : Null return value from advice does not match primitive return type for: public boolean com.spring.aop.service.UserService.delete(long) throws java.lang.Exception 可以看到，正如我们预期的那样，虽然我们并没有对UserSerivce类包括其调用方式做任何改变，但是Spring仍然拦截到了其中方法的调用，或许这正是AOP的魔力所在。 XML配置AOPXML配置 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.1.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd&quot;&gt; &lt;!-- 系统服务组件的切面Bean --&gt; &lt;bean id=&quot;serviceAspect&quot; class=&quot;com.spring.aop.aspect.ServiceAspect&quot;/&gt; &lt;!-- AOP配置 --&gt; &lt;aop:config&gt; &lt;!-- 声明一个切面,并注入切面Bean,相当于@Aspect --&gt; &lt;aop:aspect id=&quot;simpleAspect&quot; ref=&quot;serviceAspect&quot;&gt; &lt;!-- 配置一个切入点,相当于@Pointcut --&gt; &lt;aop:pointcut expression=&quot;execution(* com.spring.aop.service..*(..))&quot; id=&quot;simplePointcut&quot;/&gt; &lt;!-- 配置通知,相当于@Before、@After、@AfterReturn、@Around、@AfterThrowing --&gt; &lt;aop:before pointcut-ref=&quot;simplePointcut&quot; method=&quot;before&quot;/&gt; &lt;aop:after pointcut-ref=&quot;simplePointcut&quot; method=&quot;after&quot;/&gt; &lt;aop:after-returning pointcut-ref=&quot;simplePointcut&quot; method=&quot;afterReturn&quot;/&gt; &lt;aop:after-throwing pointcut-ref=&quot;simplePointcut&quot; method=&quot;afterThrow&quot; throwing=&quot;ex&quot;/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; ServiceAspect.java 1234567891011121314151617181920212223//配置前置通知,拦截返回值为com.spring.mvc.bean.User的方法@Before(&quot;execution(com.spring.mvc.bean.User com.spring.aop.service..*(..))&quot;)public void beforeReturnUser(JoinPoint joinPoint)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;beforeReturnUser &quot; + joinPoint); &#125;&#125;//配置前置通知,拦截参数为com.spring.mvc.bean.User的方法@Before(&quot;execution(* com.spring.aop.service..*(com.spring.mvc.bean.User))&quot;)public void beforeArgUser(JoinPoint joinPoint)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;beforeArgUser &quot; + joinPoint); &#125;&#125;//配置前置通知,拦截含有long类型参数的方法,并将参数值注入到当前方法的形参id中@Before(&quot;aspect()&amp;&amp;args(id)&quot;)public void beforeArgId(JoinPoint joinPoint, long id)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;beforeArgId &quot; + joinPoint + &quot;\\tID:&quot; + id); &#125;&#125; UserService.java 123456789101112131415161718192021222324252627282930313233343536package com.spring.aop.service;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import com.spring.mvc.bean.User;/** * 用户服务模型 */public class UserService &#123; private final static Log log = LogFactory.getLog(UserService.class); public User get(long id)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;getUser method . . .&quot;); &#125; return new User(); &#125; public void save(User user)&#123; if(log.isInfoEnabled())&#123; log.info(&quot;saveUser method . . .&quot;); &#125; &#125; public boolean delete(long id) throws Exception&#123; if(log.isInfoEnabled())&#123; log.info(&quot;delete method . . .&quot;); throw new Exception(&quot;spring aop ThrowAdvice演示&quot;); &#125; return false; &#125; &#125; 总结SpringAop可以用来： Spring声明式事务管理配置。 在执行方法前,判断是否具有权限。 对部分函数的调用进行日志记录。监控部分重要函数，若抛出指定的异常，可以以短信或邮件方式通知相关人员。 使用Spring AOP实现MySQL数据库读写分离。 信息过滤 ……","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"}]},{"title":"跨页面(Tab/Window)通信的几种方法","slug":"跨页面-Tab-Window-通信的几种方法","date":"2017-09-01T02:32:43.000Z","updated":"2021-05-05T03:17:09.979Z","comments":true,"path":"跨页面-Tab-Window-通信的几种方法/","link":"","permalink":"https://mx-go.github.io/%E8%B7%A8%E9%A1%B5%E9%9D%A2-Tab-Window-%E9%80%9A%E4%BF%A1%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95/","excerpt":"​ 今天开发一个功能遇到一个需求，在A页面点击查看详情后打开B页面进行修改或删除，删除后B页面关闭，然后刷新A页面里面的数据。相当于就是两个页面之间进行通讯，作为后端的我第一想法是利用webSocket 进行通讯，之后通过谷歌和百度找出了更为简便的方法。","text":"​ 今天开发一个功能遇到一个需求，在A页面点击查看详情后打开B页面进行修改或删除，删除后B页面关闭，然后刷新A页面里面的数据。相当于就是两个页面之间进行通讯，作为后端的我第一想法是利用webSocket 进行通讯，之后通过谷歌和百度找出了更为简便的方法。 利用webSocket进行通讯​ 第一想法是这个，但是这样的话工作量巨大而且还需要后端支持，太麻烦了，对于我这种懒人直接就放弃了，去寻找有没有更简便的方法。 定时器不断检查cookies变化在stackoverflow上看到一个方案，大致思路是： 在页面A设置一个使用 setInterval 定时器不断刷新，检查 Cookies 的值是否发生变化，如果变化就进行刷新的操作。 由于 Cookies 是在同域可读的，所以在页面 B 审核的时候改变 Cookies 的值，页面 A 自然是可以拿到的。这样做确实可以实现我想要的功能，但是这样的方法相当浪费资源。虽然在这个性能过盛的时代，浪费不浪费也感觉不出来，但是这种实现方案，确实不够优(zhuāng)雅（bī）。 localStorage的事件功夫不负有心人，后来发现 window 有一个 StorageEvent ，每当 localStorage 改变的时候可以触发这个事件。（这个原理就像你给一个DOM 绑定了 click 事件，当你点击它的时候，就会自动触发。）也就是说，我给 window 绑定这个事件后，每当我改变 localStorage 的时候，他都会触发这个事件。 123window.addEventListener(&#x27;storage&#x27;, function (event) &#123; console.log(event);&#125;); 这个回调中的event与普通的EVNET,基本差不多，但是它比其他的event多了如下几个属性: 属性 描述 key 受影响的 localStorage 的 key newValue 新的值 oldValue 旧的值 url 触发此事件的url 每当一个页面改变了 localStorage 的值，都会触发这个事件。也就是说可以很容易的通过改变 localStorage 的值，来实现浏览器中跨页面( tab / window )之间的通讯。记住这个事件只有在 localStorage 发生改变的时候才会被触发，如果没改变则不会触发此事件。 123localStorage.setItem(&#x27;delete&#x27;,1); //触发localStorage.setItem(&#x27;delete&#x27;,1); //不触发localStorage.setItem(&#x27;delete&#x27;,2); //触发 在使用的时候务必注意这一点。最终实现代码: 页面A： 123456//页面 Awindow.addEventListener(&#x27;storage&#x27;, function (event) &#123; if(event.key === &#x27;delete_verify_list&#x27;)&#123; //页面操作 &#125;&#125;); 页面B： 1234567891011121314//页面 B/** * 获取一个随机id * @return &#123;String&#125; - 返回一个5位的随机字符串 */function randomId() &#123; return (Math.random() * 1E18).toString(36).slice(0, 5).toUpperCase();&#125;//每当需要页面A更新时 执行此方法if (localStorage) &#123; //为保证每次页面A都执行，此处我设置里一个随机字符串 localStorage.setItem(&#x27;delete_verify_list&#x27;, randomId());&#125; 参考：https://ponyfoo.com/articles/cross-tab-communication","categories":[{"name":"前端","slug":"前端","permalink":"https://mx-go.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"JAVA实现HTML转PDF","slug":"JAVA实现HTML转PDF","date":"2017-07-27T05:22:32.000Z","updated":"2021-05-05T03:25:20.950Z","comments":true,"path":"JAVA实现HTML转PDF/","link":"","permalink":"https://mx-go.github.io/JAVA%E5%AE%9E%E7%8E%B0HTML%E8%BD%ACPDF/","excerpt":"​ 最近公司里面有一个任务，在线题卡，就是把客户在线编辑的题卡样式保存下来，然后可以导出为PDF格式。于是上网找了一系列的资料，找到了以下两种方法： 使用wkhtmltox 使用iText+Flying Saucer 但是还是强烈推荐用第一种方法。","text":"​ 最近公司里面有一个任务，在线题卡，就是把客户在线编辑的题卡样式保存下来，然后可以导出为PDF格式。于是上网找了一系列的资料，找到了以下两种方法： 使用wkhtmltox 使用iText+Flying Saucer 但是还是强烈推荐用第一种方法。 使用wkhtmltox(推荐)wkhtmltox实现网页转换成图片或PDF 命令实现 进入wkhtmltox官网软件下载 ：https://wkhtmltopdf.org/downloads.html 安装完成后进入${home}/bin目录下有两个exe文件，通过名称就可以辨别wkhtmltoimage.exe是将HTML转化为image，wkhtmltopdf.exe是将HTML转化为PDF文件，这正是我们想要的。 进入${home}/bin目录下打开cmd输入以下命令验证 12wkhtmltopdf HTML路径 保存路径如： wkhtmltopdf www.baidu.com d:\\test.pdf 生成完成后会出现Done。 代码实现JAVA代码中调用wkhtmltopdf生成PDF文件，以下为代码片段 1234567891011121314151617181920212223242526272829303132333435363738/** * HTMLTOPPDF * 利用wkhtmltopdf生成PDF */public class HtmlToPDF &#123; //wkhtmltopdf.exe安装路径 public static final String toPdfTool = &quot;E:\\\\SmallTools\\\\wkhtmltox\\\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe&quot;; //需要生成PDF的URL public static final String srcPath = &quot;http://www.jianshu.com/p/4d65857ffe5e&quot;; public static void main(String[] args) throws Exception&#123; //设置纸张大小: A4, Letter, etc. String pageSize = &quot;A4&quot;; //生成后存放路径 String destPath = &quot;E:\\\\PDF生成教程及讲解.pdf&quot;; convert(pageSize, destPath); &#125; public static void convert(String pageSize, String destPath)&#123; File file = new File(destPath); File parent = file.getParentFile(); if (!parent.exists())&#123; parent.mkdirs(); &#125; StringBuilder cmd = new StringBuilder(); cmd.append(toPdfTool).append(&quot; &quot;); cmd.append(&quot;--page-size &quot;); cmd.append(pageSize).append(&quot; &quot;); cmd.append(srcPath).append(&quot; &quot;); cmd.append(destPath); try &#123; Runtime.getRuntime().exec(cmd.toString()); &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 详细参数说明可参考：http://www.jianshu.com/p/4d65857ffe5e 使用iText+Flying Saucer123456789itext可实现 1.可以进行块的创建2.表格的使用3.设置页面的事件4.字体的设置5.图片的设置（包含水印）6.HTML转化成PDF（支持css,javascript）7.表单创建8.PDF之间的操作等详细的内容可以查看网站的说明。 Maven配置12345678910&lt;dependency&gt; &lt;groupId&gt;com.itextpdf&lt;/groupId&gt; &lt;artifactId&gt;itextpdf&lt;/artifactId&gt; &lt;version&gt;5.8.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.xhtmlrenderer&lt;/groupId&gt; &lt;artifactId&gt;flying-saucer-pdf&lt;/artifactId&gt; &lt;version&gt;9.1.6&lt;/version&gt;&lt;/dependency&gt; 代码片段1234567891011121314151617181920212223/** * 生成pdf，添加生成pdf所使用的字符集.注：这里字符集要和模板中使用的字符集一一致。 */public class HtmlToPDF &#123; public static void main(String[] args) throws Exception&#123; Document document = new Document(PageSize.A4.rotate()); //设置为A4纸大小 ITextRenderer renderer = new ITextRenderer(); ITextFontResolver fontResolver = renderer.getFontResolver(); fontResolver.addFont(&quot;D:/simsun.ttc&quot;, BaseFont.IDENTITY_H, BaseFont.NOT_EMBEDDED); // step 2 PdfWriter writer = PdfWriter.getInstance(document, new FileOutputStream(&quot;D:\\\\pdf.pdf&quot;)); // step 3 document.open(); // step 4 XMLWorkerHelper.getInstance().parseXHtml(writer, document, new FileInputStream(&quot;D:/a.html&quot;)); //step 5 document.close(); System.out.println( &quot;PDF Created!&quot; ); &#125;&#125; 注意事项 .输入的HTML页面必须是标准的XHTML页面。页面的顶上必须是这样的格式： 12&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt; &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt; 生成PDF，添加生成PDF所使用的字符集.注：这里字符集要和模板中使用的字符集一一致。 比如:java中使用宋体 renderer.getFontResolver().addFont(“C:/Windows/Fonts/simsun.ttc”, BaseFont.IDENTITY_H, BaseFont.NOT_EMBEDDED); 那么HTML的body中样式必须加上 style=’font-family:SimSun’，要是使用其他字符生成pdf时候，中文就会不显示生成PDF 设置PDF的页面大小模板页面中添加该样式：@page { size: 8.5in 11in; }这时候生成PDF页面正好是A4纸大小 所需的jar包，下载点我。核心jar是修改后的 比较和总结比较itext 1231. java生成PDF大部分都是用itext，itext的确是java开源组件的第一选择。不过itext也有局限，就是要自己写模版，系统中的表单数量有好几百个，为每个表单做一个导出模版不现实。2. 并且itext中文适配不是很好和换行问题。3. 且对HTML格式要求严格。 wkhtmltopdf 1231. 生成PDF时会自动根据你在HTML页面中H标签生成树形目录结构。2. 小巧方便，转换速度快。3. 跨平台，在Liunx下用，在win下也可以用。 总结​ 综上比较，wkhtmltopdf是将HTML转为图片或是PDF最好的选择。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"静态服务器搭建及前端知识点","slug":"静态服务器搭建及前端知识点","date":"2017-06-13T06:24:21.000Z","updated":"2021-05-10T15:16:46.992Z","comments":true,"path":"静态服务器搭建及前端知识点/","link":"","permalink":"https://mx-go.github.io/%E9%9D%99%E6%80%81%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%89%8D%E7%AB%AF%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"","text":"引言​ 虽然是做后台开发，但是很多时候自己也兼顾了前台，并不是所有的项目都是前后台分离开发，所以在开发期间自己也总结和学习了前端了一些小知识，在这里进行总结，以便自己温习。 NodeJS搭建静态资源服务器对Node.js只有浅显的认识，但是有时候又要自己搭建静态服务器进行测试。搭建静态服务器需要以下几个步骤： 下载node.js，进入node.js官网下载http://nodejs.cn对应的版本。 安装node.js。 启动node.js，在命令行输入命令安装需要的模块，依次执行命令。 123npm install expressnpm install requestnpm install http-server 简单的静态服务器新建server.js，内容为 1234567891011var express = require(&#x27;express&#x27;);var http = require(&quot;http&quot;);var request = require(&#x27;request&#x27;);var app = express();//启动端口为81var port = process.env.PORT||81; //静态资源存放的路径 app.use(express.static(&#x27;E:/SmallTools/StaticServer&#x27;));http.createServer(app).listen(port);console.log(&quot;服务启动成功&quot;); 启动server.js 通过http请求访问a.html页面 可以访问说明搭建成功！ 带反向代理静态服务器搭建新建server-kaow-school.js，内容为 123456789101112131415161718192021222324var express = require(&#x27;express&#x27;);var http = require(&quot;http&quot;);var https = require(&#x27;https&#x27;);var request = require(&#x27;request&#x27;);var app = express();//app.disable(&#x27;x-powered-by&#x27;);var port = process.env.PORT||81;app.use(express.static(&#x27;E:/SmallTools/StaticServer&#x27;));function proxy(app,route,remoteDomain)&#123; app.use(route,function(req,res)&#123; var url = remoteDomain+req.url; req.pipe(request(url)).pipe(res); &#125;);&#125;//10.9.4.215:8380 测试服务器ipproxy(app,&#x27;/163&#x27;,&#x27;http://www.163.com&#x27;);//proxy(app,&#x27;/MonitorService/&#x27;,&#x27;http://10.9.4.215:9192/MonitorService/&#x27;); http.createServer(app).listen(port);console.log(&quot;服务器启动完成,请使用locahost:&quot;+port+&quot;访问&quot;); 启动server-kaow-school.js 通过http请求访问b.html页面 访问/163 可以访问说明带反向代理的静态服务器搭建成功！ 前端知识点 ## JS字符串截取空白trim()的原型实现 123String.prototype.trim = function()&#123; return this.replace( /(^\\s*)|(\\s*$)/g , &#x27;&#x27;&quot;);&#125; JS屏蔽键盘按键12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;body oncontextmenu=&quot;return false&quot; onselectstart=&quot;return false&quot; ondragstart=&quot;return false&quot; onbeforecopy=&quot;return false&quot; onmouseup=document.selection.empty() oncopy=document.selection.empty() onselect=document.selection.empty()&gt;&lt;/body&gt; 讲上面红色显示的插入到网页中就可以实现鼠标右击无效禁止选择 onselectstart=&quot;return false&quot; 禁止拖放 ondragstart=&quot;return false&quot; 禁止拷贝 ncopy=document.selection.empty() 禁止保存(放在head里面) &lt;noscript&gt;&lt;iframe src=&quot;*.htm&quot;&gt;&lt;/iframe&gt;&lt;/noscript&gt;禁止粘贴 &lt;input type=text onpaste=&quot;return false&quot;&gt;关闭输入法 &lt;input style=&quot;ime-mode:disabled&quot;&gt;屏蔽鼠标右键 function document.oncontextmenu()&#123;event.returnValue=false;&#125;屏蔽F1帮助 function window.onhelp()&#123;return false&#125; 屏蔽其他键function document.onkeydown() &#123; if ((window.event.altKey)&amp;&amp; ((window.event.keyCode==37)|| //屏蔽 Alt+ 方向键 ← (window.event.keyCode==39))) //屏蔽 Alt+ 方向键 → &#123; alert(&quot;不准你使用ALT+方向键前进或后退网页！&quot;); event.returnValue=false; &#125; /* 注：这还不是真正地屏蔽 Alt+ 方向键， 因为 Alt+ 方向键弹出警告框时，按住 Alt 键不放， 用鼠标点掉警告框，这种屏蔽方法就失效了。以后若 有哪位高手有真正屏蔽 Alt 键的方法，请告知。*/ if ((event.keyCode==8) || //屏蔽退格删除键 (event.keyCode==116)|| //屏蔽 F5 刷新键 (event.ctrlKey &amp;&amp; event.keyCode==82))&#123; //Ctrl + R event.keyCode=0; event.returnValue=false; &#125; 屏蔽F11 if (event.keyCode==122)&#123;event.keyCode=0;event.returnValue=false;&#125;屏蔽 Ctrl+n if (event.ctrlKey &amp;&amp; event.keyCode==78) event.returnValue=false; if (event.shiftKey &amp;&amp; event.keyCode==121) event.returnValue=false; //屏蔽 shift+F10 if (window.event.srcElement.tagName == &quot;A&quot; &amp;&amp; window.event.shiftKey) window.event.returnValue = false; //屏蔽 shift 加鼠标左键新开一网页 if ((window.event.altKey)&amp;&amp;(window.event.keyCode==115))&#123; //屏蔽Alt+F4 window.showModelessDialog(&quot;about:blank&quot;,&quot;&quot;,&quot;dialogWidth:1px;dialogheight:1px&quot;); return false; &#125; &#125;屏蔽打印：&lt;style&gt; @media print&#123; * &#123;display:none&#125; &#125; &lt;/style&gt; HTML之间传值(通过解析url)123456789101112131415161718192021222324var hrefInfo = getUrlVars(window.location.href); // 得到参数信息 if (hrefInfo.logId &amp;&amp; hrefInfo.logId != &quot;undefined&quot;) &#123; fillData(hrefInfo.logId); logId = hrefInfo.logId; &#125; else &#123; &#125;//解析url中的参数function getUrlVars(hrf) &#123; var vars = [], hash; var locationHref = !hrf ? window.location.href : hrf; locationHref = locationHref.replace(/#/g, &quot;&quot;); if (locationHref.indexOf(&#x27;%&#x27;) &gt; 0) &#123; locationHref = unescape(locationHref); &#125; var hashes = locationHref.slice(locationHref.indexOf(&#x27;?&#x27;) + 1).split(&#x27;&amp;&#x27;); for ( var i = 0; i &lt; hashes.length; i++) &#123; hash = hashes[i].split(&#x27;=&#x27;); vars.push(hash[0]); vars[hash[0]] = hash[1]; &#125; return vars;&#125; Jquery获取radio,checkbox123456789101112//获取radio的id $(&quot;input[name=&#x27;r&#x27;]:checked&quot;).attr(&quot;id&quot;); //获得checkbox数目$(&quot;input[name=&#x27;c&#x27;]:checked&quot;).length;//遍历checkbox$(&quot;input[name=&#x27;c&#x27;]:check&quot;).eq(i).attr(&quot;id&quot;);//全选checkbox$(&quot;input[name=&#x27;c&#x27;]:checkbox&quot;).attr(&quot;checked&quot;,&quot;true&quot;);//获取选中的checkbox $(&quot;input[name=&#x27;c&#x27;]:checked&quot;).map(function()&#123;return $(this).val();&#125;).get().join(&quot;,&quot;);//获取下拉框选中的id $(&quot;#s option:selected&quot;).attr(&quot;value&quot;); Jquery页面查询(数据量大时禁用)12345678910111213141516 function search()&#123; var nameSearch = $(&quot;#itemName&quot;).val(); //搜索框ID var tableObj = $(&quot;#itemList tr:gt(0)&quot;); // table的ID if(nameSearch.trim()!=&quot;&quot;)&#123; tableObj.hide(); tableObj.each(function()&#123; var tr = $(this); var fuHe = tr.children(&quot;:eq(0)&quot;).html(); if(fuHe.indexOf(nameSearch)==0)&#123; tr.show(); &#125; &#125;); &#125;else&#123; tableObj.show(); &#125; &#125; Jquery 回车(Enter)移到下一个输入框1234567891011121314$(document).ready(function () &#123; $(&#x27;input:text:first&#x27;).focus(); $(&#x27;input:text&#x27;).bind(&quot;keydown&quot;, function (e) &#123; if (e.which == 13) &#123; //Enter key e.preventDefault(); //to skip default behaviour of enter key var nextinput = $(&#x27;input:text&#x27;)[$(&#x27;input:text&#x27;).index(this) + 1]; if (nextinput != undefined) &#123; nextinput.focus(); &#125; else &#123; alert(&quot;没有下一个输入框！&quot;); &#125; &#125; &#125;); &#125;); JS,Jquery获取各种屏幕的宽度和高度12345678910111213141516171819202122232425262728//Javascript:网页可见区域宽： document.body.clientWidth网页可见区域高： document.body.clientHeight网页可见区域宽： document.body.offsetWidth (包括边线的宽)网页可见区域高： document.body.offsetHeight (包括边线的高)网页正文全文宽： document.body.scrollWidth网页正文全文高： document.body.scrollHeight网页被卷去的高： document.body.scrollTop网页被卷去的左： document.body.scrollLeft网页正文部分上： window.screenTop网页正文部分左： window.screenLeft屏幕分辨率的高： window.screen.height屏幕分辨率的宽： window.screen.width屏幕可用工作区高度： window.screen.availHeight屏幕可用工作区宽度： window.screen.availWidth //JQuery:$(document).ready(function()&#123; alert($(window).height()); //浏览器当前窗口可视区域高度 alert($(document).height()); //浏览器当前窗口文档的高度 alert($(document.body).height());//浏览器当前窗口文档body的高度 alert($(document.body).outerHeight(true));//浏览器当前窗口文档body的总高度 包括border padding margin alert($(window).width()); //浏览器当前窗口可视区域宽度 alert($(document).width());//浏览器当前窗口文档对象宽度 alert($(document.body).width());//浏览器当前窗口文档body的宽度 alert($(document.body).outerWidth(true));//浏览器当前窗口文档body的总宽度 包括border padding margin&#125;) Ajax,Get时请求异步缓存问题用Ajax的Get方式请求同一个地址获取数据时，经常碰到回调函数成功执行，前台又有数据的情况，但是无法请求到后台获得最新的数据。原因是ajax存在异步缓存的问题。 因为ajax本身自带有实时异步请求的功能，而IE缓存导致请求时不会请求后台，会直接读取缓存的数据。 解决办法： ajax get请求时比较简单 只需将cache设置为false就好。 123456789$.ajax(&#123; type: &#x27;get&#x27;, //get请求时 url: &#x27;....&#x27;, cache: false, //不缓存 data: &#123; &#125;, success: function (result) &#123; // &#125; &#125;); 访问就在URL后面加上 URL?+new Date();[总之就是使每次访问的URL字符串不一样的] 设计WEB页面的时候 也应该遵守这个原则，因为请求同一个地址会直接读取缓存，所以可以在参数中加一个随机数数 让每次参数不一样就好。","categories":[{"name":"前端","slug":"前端","permalink":"https://mx-go.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"微信公众号网页开发","slug":"微信公众号网页开发","date":"2017-06-01T07:27:34.000Z","updated":"2021-05-05T03:20:34.187Z","comments":true,"path":"微信公众号网页开发/","link":"","permalink":"https://mx-go.github.io/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%BD%91%E9%A1%B5%E5%BC%80%E5%8F%91/","excerpt":"引言最近一直参与公司开发公众号，关于项目实施平台PC端简化为微信公众号，主要架构为前台H5，使用时的微信的WeUI的SDK，后台就是现在流行的SpringMVC+Mybaties，参与了全程开发，开发过程中也遇到了不少的问题，现在记录下来，希望以后能够用得到。","text":"引言最近一直参与公司开发公众号，关于项目实施平台PC端简化为微信公众号，主要架构为前台H5，使用时的微信的WeUI的SDK，后台就是现在流行的SpringMVC+Mybaties，参与了全程开发，开发过程中也遇到了不少的问题，现在记录下来，希望以后能够用得到。 HTML页面之间传值JSP之间传值已经很熟悉，HTML之间传值是通过解析URL获取所需参数。 12//URL传值URL + &quot;?logId=&quot; + logId; 12345678910111213141516171819202122232425262728//获取所需参数var hrefInfo = getUrlVars(window.location.href); if (hrefInfo.logId &amp;&amp; hrefInfo.logId != &quot;undefined&quot;) &#123; fillData(hrefInfo.logId); logId = hrefInfo.logId; &#125; else &#123;&#125;// 得到url中的参数function getUrlVars(hrf) &#123; var vars = [], hash; var locationHref = !hrf ? window.location.href : hrf; locationHref = locationHref.replace(/#/g, &quot;&quot;); if (locationHref.indexOf(&#x27;%&#x27;) &gt; 0) &#123; locationHref = unescape(locationHref); &#125; var hashes = locationHref.slice(locationHref.indexOf(&#x27;?&#x27;) + 1).split(&#x27;&amp;&#x27;); for ( var i = 0; i &lt; hashes.length; i++) &#123; hash = hashes[i].split(&#x27;=&#x27;); vars.push(hash[0]); vars[hash[0]] = hash[1]; &#125; return vars;&#125; JS、JQuery获取各种屏幕的高度和宽度在移动端经常会用到获取屏幕的高度和宽度，在这里总结一下。 12345678910111213Javascript:document.body.clientWidth //网页可见区域宽document.body.clientHeight //网页可见区域高document.body.offsetWidth (包括边线的宽) //网页可见区域宽document.body.offsetHeight (包括边线的高) //网页可见区域高document.body.scrollWidth //网页正文全文宽document.body.scrollHeight //网页正文全文高document.body.scrollTop //网页被卷去的高document.body.scrollLeft //网页被卷去的左window.screenTop //网页正文部分上window.screen.width //屏幕分辨率的宽window.screen.availHeight //屏幕可用工作区高度window.screen.availWidth //屏幕可用工作区宽度 123456789101112JQuery:$(document).ready(function()&#123;alert($(window).height()); //浏览器当前窗口可视区域高度alert($(document).height()); //浏览器当前窗口文档的高度alert($(document.body).height()); //浏览器当前窗口文档body的高度alert($(document.body).outerHeight(true));//浏览器当前窗口文档body的总高度 包括border padding marginalert($(window).width()); //浏览器当前窗口可视区域宽度alert($(document).width()); //浏览器当前窗口文档对象宽度alert($(document.body).width()); //浏览器当前窗口文档body的宽度alert($(document.body).outerWidth(true));//浏览器当前窗口文档body的总宽度 包括border padding margin&#125;) 微信浏览器缓存清理微信浏览器缓存一直都是相当恶心的存在，只要页面加载，那么静态页面就会被缓存，通过Google和百度找到了以下两种方法： 设置HTTP头部通过这只HTTP头部禁止浏览器缓存，效果没有达到要求，不建议使用 Android下可在微信中打开http://debugx5.qq.com清除微信缓存。 1234567891011&lt;html manifest=&quot;IGNORE.manifest&quot;&gt; &lt;meta charset=&quot;utf-8&quot;&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt;&lt;meta http-equiv=&quot;pragma&quot; content=&quot;no-cache&quot;&gt;&lt;meta http-equiv=&quot;cache-control&quot; content=&quot;no-cache&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, user-scalable=no&quot;&gt;&lt;link rel=&quot;shortcut icon&quot; href=&quot;../../view/images/favicon.ico&quot; type=&quot;image/x-icon&quot; /&gt; 更新版本号HTTP头部禁止缓存不能用，就只能每次都更新版本号(加随机数)来达到自己的要求了。 使用SeaJs拦截所有.js和.css并在尾部加上随机数。 引入SeaJs1&lt;script src=&quot;../../util/sea.js&quot;&gt;&lt;/script&gt; 配置seajs_config.js 需要配置seajs_config.js全局变量，每一个HTML页面都要引入，关于更多SeaJs配置http://yslove.net/seajs/ 1234567891011var time = new Date().getTime();var sea_config = &#123; &quot;base&quot;:&quot;/&quot;, //web发布路径 &quot;debug&quot;:&quot;true&quot;, //2:每次从后台获取新的js,true:console出bug,false:默认 &quot;charset&quot;:&quot;utf-8&quot;, //字符集 preload: [&quot;util/jquery-1.8.0.min.js&quot;], //预加载jquery map: [ //配置映射，用来版本更新强制浏览器刷新 [&#x27;.js&#x27;,&#x27;.js?version=&#x27; + time], [&#x27;.css&#x27;,&#x27;.css?version=&#x27; + time] ]&#125;; 12345//HTML页面引入&lt;script src=&quot;../../config/seaConfig/seajs_config.js&quot;&gt;&lt;/script&gt;&lt;script&gt; seajs.config(sea_config);&lt;/script&gt; Ajax请求缓存 在编码期间，因为有个角色是查看所有项目且数据量也比较大，所以把Ajax请求方式从POST改为了GET，结果就发现Ajax请求被缓存，只有第一次查询有效，其后全部是从缓存中取，查询资料后才发现是POST改为GET引起的 解决方法一12345678910//ajax get请求时比较简单 只需将cache设置为false就好 $.ajax(&#123; type: &#x27;get&#x27;,//get请求时 url: &#x27;........&#x27;, cache: false,//不缓存 data: &#123; &#125;, success: function (result) &#123; &#125; &#125;); 解决方法二1234访问就在URL后面加上[总之就是使每次访问的URL字符串不一样的]URL?+new Date();设计WEB页面的时候 也应该遵守这个原则因为请求同一个地址会直接读取缓存，所以可以在参数中加一个随机数数 让每次参数不一样就好 IOS下Iframe滚动问题 移动端在IOS下的问题居多，后来测试组测出的bug多数属于在IOS下属性不兼容问题，其中就有IOS下Iframe里面页面无法滚动，解决方法如下 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html lang=&quot;zh-cn&quot;&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot; /&gt;&lt;title&gt;IOS frame 滚动条 demo&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;style&gt;#wrapper&#123;height:500px;-webkit-overflow-scrolling:touch;overflow:auto;&#125;&lt;/style&gt;&lt;div class=&quot;container&quot;&gt; 我是一堆很长。很长，很高，很高的内容。&lt;/div&gt;&lt;script src=&quot;../jquery.js&quot;&gt;&lt;/script&gt;&lt;script&gt; var UA = navigator.userAgent; var forIOS = function()&#123; if(!UA.match(/iPad/) &amp;&amp; !UA.match(/iPhone/) &amp;&amp; !UA.match(/iPod/))&#123; return; &#125; if($(&#x27;#wrapper&#x27;).length)&#123;return;&#125; $(&#x27;body&#x27;).children().not(&#x27;script&#x27;).wrapAll(&#x27;&lt;div id=&quot;wrapper&quot;&gt;&lt;/div&gt;&#x27;); &#125;();&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 总结这次是我第一次开发微信端，从前端的不熟悉到熟练，自己成长了许多。同时遇到了很多问题，尤其是在IOS下的兼容问题，比如还有像IOS下fixed属性不能用等问题。很多东西只有自己摸索才知道，这次也算是让自己在全栈工程师的道路上又进了一步。","categories":[{"name":"前端","slug":"前端","permalink":"https://mx-go.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"移动端","slug":"移动端","permalink":"https://mx-go.github.io/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF/"}]},{"title":"MySQL优化","slug":"MySQL优化","date":"2017-04-17T04:31:55.000Z","updated":"2021-05-10T15:19:14.340Z","comments":true,"path":"MySQL优化/","link":"","permalink":"https://mx-go.github.io/MySQL%E4%BC%98%E5%8C%96/","excerpt":"","text":"引言数据库在每个项目中都会用到，现在又分为两个门派，一种关系型数据库，常见的有MySQL、SQL Server、Oracle、DB2等。另一种是非关系型数据库，也就是NoSQL( Not Only SQL)，常见的NOSQL数据库有Redis 、MongoDB、Cassandra等。数据库的优化直接影响到网站的性能，在这里记录一下MySQL的优化。 关于MySQLMySQL 是一个跨平台的开源关系型数据库管理系统，目前 MySQL 被广泛地应用在 Internet 上的中小型网站中。由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，许多中小型网站为了降低网站总体拥有成本而选择了 MySQL 作为网站数据库。比如淘宝、京东等知名公司也都在使用。 MySQL的存储引擎有分为很多种。MyISAM、InnoDB等。每个引擎的特性都不一样，可以在不同的情况下选择不同的存储引擎。 MySQL的优化对于一个小项目来说，MySQL优化与否可能没有那么重要，带来的优化效果也没有那么明显。但是如果面对的是一个千万级的大表、千万级甚至上亿的数据量时，优化是必不可少的。那么要从如下几方面来做优化： 存储引擎一般情况可以选择MyISAM存储引擎，如果需要事务支持必须使用InnoDB存储引擎。 MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持以及外部键等高级数据库功能。 命名规则本着约定优先于配置（Convention Over Configuration）的原则，表的命名规则一样很重要。 MySQL数据库、表、字段等名称统一使用小写，单词间用_下划线分隔。 表名和字段名不宜过长（不超过64个字符）。 建议数据库统一设置编码为utf8，不仅仅是为了应付数据库间导入导出过程中、因编码格式不统一而导致的恼人的乱码问题，也是因为utf8是一种万国码（Unicode）。 语句+索引索引的合理建立和查询语句的优化可以迅速提升数据库性能。 设计阶段就需要预计QPS（Query Per Second）及数据规模，参考业务场景对数据的要求，合理设计表结构（参考mysql在线DDL问题），甚至违反设计范式做到适当冗余。生产环境分析慢日志，优化语句。索引的设计需要知道索引是怎么用的，比如innodb的加锁机制。 垃圾查询拖慢性能。不合理的schema设计也会导致数据存取慢。索引的作用不必多说，但如innodb下，错的索引带来的可能不只是查询变慢。 MySQL语句优化是我们最常见也是开发过程中最需要注意的。各种关键字的使用场合、多表之间的关联(据说阿里的要求是关联表不超多三个)、索引的合理使用、批量插入、批量更新、批量删除、临时表的使用等等。 缓存当数据库的压力太大时可以将一部分压力转嫁到缓存（我常用的是Redis），其流程如下： 复制及读写分离这个是大多数场景下都是必须的。因为复制可以实现备份、高可用、负载均衡。 其中读写分离可以在应用层做，效率高，也可以用三方工具，如360的atlas。 切分切分包括垂直切分和水平切分，实现方式上又包括分库、分表。 垂直切分保证业务的独立性，防止不同业务争抢资源，毕竟业务是有优先级的。 水平切分主要用于突破单机瓶颈。除了主主外，只有切分能真正做到将负载分配下去。 切分后也可对不同片数据进行不同优化。如按时间切分，超过一定时间数据不允许修改，就可以引入压缩了，数据传输及读取减少很多。 根据业务垂直切分。业务内部分库、分表。一般都需要修改应用。除分表外，其余实现不是很复杂。有第三方组件可用，但通用高效又灵活的方式，还是自己写client。 垂直切分一般都要做，只不过业务粒度大小而已。 分库有是经常用的，就算当前压力小，也尽量分出几个逻辑库出来。等规模上去了，很方便就迁移扩展。 水平拆分有一定难度，但如果将来一定会到这个规模，又可能用到，建议越早做越好。因为对应用的改动较大，而且迁移成本高。 总结MySQL总结可以说是： 优化SQL，优化结构，优化存储。 对于MySQL的优化我还需要进一步提高，从表的设计建立到后期的维护考虑的问题有很多，每一步都需要注意。没有DBA，只有自己来实现。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"}]},{"title":"Linux基本命令","slug":"Linux基本命令","date":"2017-04-07T07:59:22.000Z","updated":"2021-12-29T14:48:17.451Z","comments":true,"path":"Linux基本命令/","link":"","permalink":"https://mx-go.github.io/Linux%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/","excerpt":"引言之前的公司有用过Linux，自己也学习了一段时间，但是很久没有用了，最近又在腾讯云租了个空间把系统装成Centos系统了，所以又把Linux系统重新捡起来，重温下Linux的基本知识。","text":"引言之前的公司有用过Linux，自己也学习了一段时间，但是很久没有用了，最近又在腾讯云租了个空间把系统装成Centos系统了，所以又把Linux系统重新捡起来，重温下Linux的基本知识。 Linux简介简介Linux，免费开源，多用户多任务系统。基于Linux有多个版本的衍生。RedHat、Ubuntu、Debian 安装VMware或VirtualBox虚拟机。Linux的定义和历史右转百度百科。具体安装步骤，找百度。 常用版本我常用的Linux版本有两个Centos和Ubuntu，全都是开源免费的,其中Ubuntu属于桌面版。 123Centos是免费的企业版Linux操作系统。是RedHat企业版的优化操作系统。具体可以参照百科：http://baike.baidu.com/view/26404.htm。里面有详解。另附其官网:http://www.centos.org/。另外，它适合作为服务器用。 1Ubuntu之前有在环境中开发过项目，虽然时间不久，但还是有所体会。免费、无毒、免折腾、比较接近底层。 基本命令基础命令 Linux 操作系统位数识别: uname -a（uname -p） Linux 32位操作系统：Linux x86 i586 i386 i686 i… Linux 64位操作系统：Linux x64x86_64 X64 … man 命令不会用了，找男人 如：man ls ifconfig 显示系统信息 ls 或ll 查看目录文件 pwd 查看目前路径 cat 文件名 从第一个字节开始正向查看文件的内容 head -2 file1 查看一个文件的前两行 tail -2 file1 查看一个文件的最后两行 mv 老名 新名 重命名/剪切 cp 老文件路径+文件名 新文件路径（+文件名） 复制 cd 进入个人的主目录 cd 路径名 进入新路径 cd .. 后退一步 date 显示系统日期 shutdown -h now 关闭系统(1) shutdown -r now 重启(1) reboot 重启(2) halt 关机(推荐) logout 注销 mkdir dir1 创建一个叫做 ‘dir1’ 的目录’ rm -f file1 删除一个叫做 ‘file1’ 的文件’ rmdir dir1 删除一个叫做 ‘dir1’ 的目录’ rm -rf dir1 删除一个叫做 ‘dir1’ 的目录并同时删除其内 find / -name file1 从 ‘/‘ 开始进入根文件系统搜索文件和目录 tar -zxvf archive.tar 解压一个包 rpm -ivh package.rpm 安装一个rpm包 高级一点的命令，也是比较难懂、需要实践和琢磨的命令： chmod +权限(ugo) (u、g、o表示user、group、other) 三种基本权限 R 读 数值表示为4 W 写 数值表示为2 X 可执行 数值表示为1 ​ 例如：chmod 777 表示user、group、other都具有RWX权限。 grep [options] grep命令是一种强大的文本搜索工具 grep ‘test’ d*显示所有以d开头的文件中包含 test的行。 egrep [options] 或 egrep “a|b” filename 搜索包含a或b的行 ps [options] 对进程进行监测和控制 ps -aux|grep 8080 查看8080端口占用情况 yum [options][command] [package ...] 工具 yum list 列出当前系统中安装的所有包 wget [OPTION]… [URL]… wget是一个从网络上自动下载文件的自由工具 wget http://example.com/file.iso 从网上下载单个文件 crontab定时任务基本使用通过crontab 命令，可以在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。这个命令非常适合周期性的日志分析或数据备份等工作。 crontab文件格式 分 时 日 月 星期 要运行的命令 第1列分钟0～59 第2列小时0～23（0表示子夜） 第3列日1～31 第4列月1～12 第5列星期0～7（0和7表示星期天） 第6列要运行的命令 命令 12345678#列出crontab文件$ crontab -l#编辑crontab文件$ crontab -e#删除crontab文件$ crontab -r 使用实例 1234567891011121314# 每1分钟执行一次myCommand$ * * * * * myCommand# 每小时的第3和第15分钟执行$ 3,15 * * * * myCommand# 每晚的21:30重启smb$ 30 21 * * * /etc/init.d/smb restart# 每周六、周日的1 : 10重启smb$ 10 1 * * 6,0 /etc/init.d/smb restart# 每一小时重启smb$ * */1 * * * /etc/init.d/smb restart 使用实例(定时备份MySQL) 在/usr/soft下新建脚本mysqlbak.sh 123456789101112131415161718192021222324252627#!/bin/bash#备份路径BACKUP=/usr/soft/sql#当前时间DATETIME=$(date +%Y-%m-%d_%H%M%S)echo &quot;==备份开始==&quot;echo &quot;备份文件存放于$&#123;BACKUP&#125;/$DATETIME.tar.gz&quot;#数据库地址HOST=localhost#数据库用户名DB_USER=root#数据库密码DB_PW=root#创建备份目录[ ! -d &quot;$&#123;BACKUP&#125;/$DATETIME&quot; ] &amp;&amp; mkdir -p &quot;$&#123;BACKUP&#125;/$DATETIME&quot;#后台系统数据库DATABASE=test/usr/bin/mysqldump -u$&#123;DB_USER&#125; -p$&#123;DB_PW&#125; --host=$HOST -q -R --databases $DATABASE | gzip &gt; $&#123;BACKUP&#125;/$DATETIME/$DATABASE.sql.gz#压缩成tar.gz包cd $BACKUPtar -zcvf $DATETIME.tar.gz $DATETIME#删除备份目录rm -rf $&#123;BACKUP&#125;/$DATETIME#删除10天前备份的数据find $BACKUP -mtime +10 -name &quot;*.tar.gz&quot; -exec rm -rf &#123;&#125; \\;echo &quot;===备份成功===&quot; 赋予权限 1$ chmod 777 mysqlbak.sh 添加至定时任务 123456// 编辑定时任务列表$ crontab -e// 加入以下内容#每隔一个小时执行一次00 */1 * * * /usr/soft/mysqlbak.sh 注意 新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。 当crontab失效时，可以尝试service crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。 千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。 在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+%Y%m%d’。 …………… 总结Linux博大精深，有很多的命令自己使用的比较少也没有用到，用到的时候再去查资料。 更多的命令可以查看http://www.cnblogs.com/skillup/articles/1877812.html","categories":[{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"基础","slug":"Linux/基础","permalink":"https://mx-go.github.io/categories/Linux/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"JAVA实现简单网络爬虫","slug":"JAVA实现简单爬虫","date":"2017-04-01T06:17:39.000Z","updated":"2021-05-05T03:25:09.562Z","comments":true,"path":"JAVA实现简单爬虫/","link":"","permalink":"https://mx-go.github.io/JAVA%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%88%AC%E8%99%AB/","excerpt":"","text":"爬虫基本理解 通俗一点，爬虫是用来快速、批量获取我们在网络需要的东西，过滤掉不需要的东西，比如我可以爬一个网站的所有图片省的一张一张去保存，也可以爬其他数据来做研究、统计、数据分析，即是： (1) 对抓取目标的描述或定义； (2) 对网页或数据的分析与过滤； (3) 对URL的搜索策略。 很多语言都可以做爬虫，在这里记录JAVA做一个简单的爬虫，等以后学会其他语言了再用其他语言做爬虫，哈哈… 实现爬虫需要知识点 简单HTML、CSS、JS等前端知识 正则表达式（很重要，用于过滤不需要的信息） JAVA语言知识（可换成其他语言） 参数 首先你要给它一个种子链接URL 在种子链接的页面查找其他的URL，重复1步骤 有链接有页面，然后你可以在页面中查找需要的内容 简单爬虫代码在这里做个示例：把网站https://www.baidu.com/home/news/data/newspage?nid=7953839918275534&amp;n_type=0&amp;p_from=1 图片全部down下来并保存到本地磁盘的操作。 JAVA基本方式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public class Reptile &#123; public static String doGet(String urlStr) throws Exception &#123; URL url; String html = &quot;&quot;; try &#123; url = new URL(urlStr); HttpURLConnection connection = (HttpURLConnection) url.openConnection(); connection.setRequestProperty(&quot;Accept&quot;, &quot;text/html&quot;); connection.setRequestProperty(&quot;Accept-Charset&quot;, &quot;utf-8&quot;); connection.setRequestProperty(&quot;Accept-Language&quot;, &quot;en-US,en&quot;); connection.setRequestProperty(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.160 Safari/537.22&quot;); connection.setRequestMethod(&quot;GET&quot;); connection.setConnectTimeout(5000); connection.setDoInput(true); connection.setDoOutput(true); if (connection.getResponseCode() == 200) &#123; System.out.println(&quot;已连接，正在解析。。。。。。&quot;); InputStream in = connection.getInputStream(); html = StreamTool.inToStringByByte(in); &#125; else &#123; System.out.println(connection.getResponseCode()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new Exception(&quot;get请求失败&quot;); &#125; return html; &#125; public static void main(String[] args) throws Exception &#123; Reptile reptile = new Reptile() String htmlStr = Reptile.doGet(&quot;https://www.baidu.com/home/news/data/ newspagenid=7953839918275534&amp;n_type=0&amp;p_from=1&quot;); File f = new File(&quot;E://imgs&quot;); if (!f.exists()) &#123; f.mkdirs(); &#125; Pattern pattern = Pattern.compile(&quot;&lt;img.*src=(.*?)[^&gt;]*?&gt;&quot;); //匹配Imag标签 Matcher matcher = pattern.matcher(htmlStr); // 定义一个matcher用来做匹配 System.out.println(&quot;正在下载&quot;); while (matcher.find()) &#123; String imgs = matcher.group(); Matcher srcMatcher = Pattern.compile(&quot;https:\\&quot;?(.*?)(\\&quot;|&gt;|\\\\s+)&quot;).matcher(imgs); while (srcMatcher.find()) &#123; String src = srcMatcher.group().substring(0,srcMatcher.group().length() - 1); System.out.println(src); // 获取后缀名 String imageName = src.substring(src.lastIndexOf(&quot;/&quot;) + 1,src.length()); reptile.downLoad(src, imageName); //下载图片到本地 &#125; &#125; &#125; //下载图片到本地 public void downLoad(String src, String imageName) throws Exception &#123; URL url = new URL(src); URLConnection uri = url.openConnection(); InputStream is = uri.getInputStream(); // 获取数据流 // 写入数据流 OutputStream os = new FileOutputStream(new File(&quot;E://imgs&quot;, imageName)); byte[] buf = new byte[1024]; int len = 0; while ((len = is.read(buf)) != -1) &#123; os.write(buf, 0, len); &#125; os.close(); is.close(); &#125;&#125; JAVA基本方法主要是利用JAVA中的正则表达式匹配我们我需要的元素，然后再进行其他操作。简单、粗暴。 Jsoup方式 Jsoup 是一个 Java 的开源HTML解析器，可直接解析某个URL地址、HTML文本内容。同时提供了一套非常省力的API，可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。可以直接使用DOM或者JQuery方法和表达式取出数据。 需要下载JAR包，下载地址：点我 Jsoup API：详见：http://www.open-open.com/jsoup/ 工具类StreamTool ：将byte对象转化为String对象 1234567891011121314public class StreamTool &#123;// 将byte对象转化为String对象 public static String inToStringByByte(InputStream in) throws Exception &#123; ByteArrayOutputStream outStr = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int len = 0; StringBuilder content = new StringBuilder(); while ((len = in.read(buffer)) != -1) &#123; content.append(new String(buffer, 0, len, &quot;UTF-8&quot;)); &#125; outStr.close(); return content.toString(); &#125;&#125; 基本实现类Reptile 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public class Reptile &#123; public static String doGet(String urlStr) throws Exception &#123; URL url; String html = &quot;&quot;; try &#123; url = new URL(urlStr); HttpURLConnection connection = (HttpURLConnection) url.openConnection(); //伪装爬虫，不然会报403错误 connection.setRequestProperty(&quot;Accept&quot;, &quot;text/html&quot;); connection.setRequestProperty(&quot;Accept-Charset&quot;, &quot;utf-8&quot;); connection.setRequestProperty(&quot;Accept-Language&quot;, &quot;en-US,en&quot;); connection.setRequestProperty(&quot;User-Agent&quot;,&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.22 (KHTML, like Gecko) Chrome/25.0.1364.160 Safari/537.22&quot;); connection.setRequestMethod(&quot;GET&quot;); // 定义请求方式 connection.setConnectTimeout(5000); connection.setDoInput(true); //设置是否向httpUrlConnection输出， 默认情况下是false; connection.setDoOutput(true); // 设置是否从httpUrlConnection读入，默认情况下是true; if (connection.getResponseCode() == 200) &#123; //连接成功 System.out.println(&quot;已连接，正在解析。。。。。。&quot;); InputStream in = connection.getInputStream(); html = StreamTool.inToStringByByte(in); &#125; else &#123; System.out.println(connection.getResponseCode()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new Exception(&quot;get请求失败&quot;); &#125; return html; &#125; public static void main(String[] args) throws Exception &#123; URL url ; InputStream is = null; OutputStream os = null; String urlStr = &quot;https://www.baidu.com/home/news/data/newspage?nid=7953839918275534&amp;n_type=0&amp;p_from=1&quot;; String htmlStr = Reptile.doGet(urlStr); Document doc = Jsoup.parse(htmlStr); // 将获取的网页 HTML 源代码转化为 Document对象 File f = new File(&quot;E://imgs&quot;); //把文件存在E://imgs if (!f.exists()) &#123; f.mkdirs(); &#125; Elements pngs = doc.select(&quot;img[src]&quot;); //获取所有图片// Elements pngs = doc.select(&quot;img[src$=.png]&quot;);只爬取png图片 int i = 1; //计数 for (Element e : pngs) &#123; String src = e.attr(&quot;src&quot;); // 获取img中的src路径 String imageName = src.substring(src.lastIndexOf(&quot;/&quot;) + 1, src.length()); // 获取后缀名 System.out.println(&quot;正在下载第&quot; + i + &quot;张图片：&quot;+ imageName); URL url = new URL(src); // 连接url URLConnection uri = url.openConnection(); is = uri.getInputStream(); // 获取数据流 os = new FileOutputStream(new File(&quot;E://imgs&quot;,imageName));// 写入数据流 byte[] buf = new byte[1024]; int len = 0; while ((len = is.read(buf)) != -1) &#123; os.write(buf, 0, len); &#125; i++; &#125; os.close(); is.close(); System.out.println(&quot;共有&quot; + (i-1) + &quot;张图片。&quot;); &#125;&#125; 总结在这里只做个一个简单的爬虫示例，通过两种方式的比较后，发现Jsoup更佳。 JAVA基本的方式能用正则表达式来匹配所需要的元素，灵活性不高。 Jsoup这个强大的工具提供了DOM和JQuery方法，可以直接操作节点，同时也支持正则表达式，更加的灵活、省力，同时选择性、可玩性和扩展性更高。Jsoup更多的方法可以查看Jsoup的API。 现在已经有很多开源的爬虫的框架供我们选择，比如webmagic、Heritrix等，可以适当选择。 附还有一种更为简单强大的方式，在Linux环境下，利用wget命令只需要一行命令就可以实现以上功能。 1wget -m -H -nd -l 1 -t 1 -A .jpg,.png,.jpeg,.JPEG -e robots=off -P /opt/download --no-check-certificate https://www.baidu.com/home/news/data/newspage?nid=7953839918275534&amp;n_type=0&amp;p_from=1 在下篇博客写一下Linux的基本命令。","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tools","slug":"tools","permalink":"https://mx-go.github.io/tags/tools/"}]},{"title":"JAVA定时调度 Timer和Executors","slug":"JAVA定时调度-Timer和Executors","date":"2017-03-27T09:42:49.000Z","updated":"2021-05-05T03:24:19.031Z","comments":true,"path":"JAVA定时调度-Timer和Executors/","link":"","permalink":"https://mx-go.github.io/JAVA%E5%AE%9A%E6%97%B6%E8%B0%83%E5%BA%A6-Timer%E5%92%8CExecutors/","excerpt":"近期在公司做了一个关于定时执行任务的功能（没有使用框架定时），查了一下资料，有Thread、Timer和Executors三种方法，之前使用的是Timer，但是详细查了资料觉得Executors更优，所以在这里比较一下它们的区别。","text":"近期在公司做了一个关于定时执行任务的功能（没有使用框架定时），查了一下资料，有Thread、Timer和Executors三种方法，之前使用的是Timer，但是详细查了资料觉得Executors更优，所以在这里比较一下它们的区别。 Thread类这是最基本的，创建一个Thread，然后让它在while循环里一直运行着，通过sleep方法来达到定时任务的效果。这样可以快速简单的实现，代码如下： 12345678910111213141516171819202122public class Task1 &#123; public static void main(String[] args) &#123; // run in a second final long timeInterval = 1000; Runnable runnable = new Runnable() &#123; public void run() &#123; while (true) &#123; // ------- code for task to run System.out.println(&quot;Hello !!&quot;); // ------- ends here try &#123; Thread.sleep(timeInterval); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;; Thread thread = new Thread(runnable); thread.start(); &#125; &#125; Thread的做定时任务的几率不大，因为不可控制启动停止时间、不能指定想要的delay时间。 Timer类 于第一种方式相比，优势 : (1) 当启动和去取消任务时可以控制 ; (2) 第一次执行任务时可以指定你想要的delay时间。 在实现时，Timer类可以调度任务，TimerTask则是通过在run()方法里实现具体任务。 Timer实例可以调度多任务，它是线程安全的。 当Timer的构造器被调用时，它创建了一个线程，这个线程可以用来调度任务。 12345678910111213141516public class Task2 &#123; public static void main(String[] args) &#123; TimerTask task = new TimerTask() &#123; @Override public void run() &#123; // task to run goes here System.out.println(&quot;Hello !!!&quot;); &#125; &#125;; Timer timer = new Timer(); long delay = 0; long intevalPeriod = 1 * 1000; // schedules the task to be run in an interval timer.scheduleAtFixedRate(task, delay, intevalPeriod); &#125; // end of main &#125; 缺点：如果TimerTask抛出未检查的异常，Timer将会产生无法预料的行为。Timer线程并不捕获异常，所以 TimerTask抛出的未检查的异常会终止timer线程。这种情况下，Timer也不会再重新恢复线程的执行了;它错误的认为整个Timer都被取消了。此时，已经被安排但尚未执行的TimerTask永远不会再执行了，新的任务也不能被调度了。 Executors ScheduledExecutorService是从Java SE5的java.util.concurrent里，做为并发工具类被引进的，这是最理想的定时任务实现方式。 相比于上两个方法，它有以下好处 : (1) 相比于Timer的单线程，它是通过线程池的方式来执行任务的 ; (2) 可以很灵活的去设定第一次执行任务delay时间 ; (3) 提供了良好的约定，以便设定执行的时间间隔 。 下面是实现代码，我们通过ScheduledExecutorService展示这个例子，通过代码里参数的控制，首次执行加了delay时间。 1234567891011121314public class Task3 &#123; public static void main(String[] args) &#123; Runnable runnable = new Runnable() &#123; public void run() &#123; // task to run goes here System.out.println(&quot;Hello !!&quot;); &#125; &#125;; ScheduledExecutorService service = Executors .newSingleThreadScheduledExecutor(); // 第二个参数为首次执行的延时时间，第三个参数为定时执行的间隔时间 service.scheduleAtFixedRate(runnable, 10, 1, TimeUnit.SECONDS); &#125; &#125; 线程池能按时间计划来执行任务，允许用户设定计划执行任务的时间。 当任务较多时，线程池可能会自动创建更多的工作线程来执行任务 。 支持多个任务并发执行。 总结Timer是单线程的。所以task都是串行执行。假如其中一个task执行需要很长的时间，那其他的task只能干巴巴的等着。 ScheduledThreadPoolExecutor是一个可以重复执行任务的线程池，并且可以指定任务的间隔和延迟时间。它作为比Timer/TimerTask更加通用的替代品。因为它允许多个服务线程，接受不同的时间单位，且不需要继承TimeTask（仅仅需要实现Runnable接口）。配置ScheduledThreadPoolExecutor为单线程，则与使用Timer等效。 上述，基本说明了在以后的开发中尽可能使用ScheduledExecutorService(JDK1.5以后)替代Timer。 下面是自己做的功能，通过短信API定时查询教师回复信息并更新数据库。 123456789101112131415161718192021222324252627282930/** * 定时查询教师回复状态 * @param a */public void getStatusSchedule(final Date replyEnd)&#123; final SendMessage sendMsg = new SendMessage(); final ScheduledExecutorService service = Executors.newSingleThreadScheduledExecutor(); service.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; Date nowDate = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).parse(new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).format(new Date()));//当前时间 //若截至时间在当前时间之前执行定时任务 否则不执行 if (!nowDate.before(replyEnd)) &#123; service.shutdown(); //停止任务 return; &#125;else &#123; Map&lt;String,Object&gt; map = sendMsg.getReplyMsg(); //获取回复信息 if(!map.isEmpty())&#123; //当map不为空时执行 updateMsgStatus(map); //更新数据库 &#125; &#125; &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, 1, 1, TimeUnit.MINUTES); //执行后第一次查询在1分钟之后，每隔1分钟查询一次。 &#125;","categories":[{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"浅谈共享单车","slug":"浅谈共享单车","date":"2017-03-24T09:40:22.000Z","updated":"2021-05-05T03:17:19.946Z","comments":true,"path":"浅谈共享单车/","link":"","permalink":"https://mx-go.github.io/%E6%B5%85%E8%B0%88%E5%85%B1%E4%BA%AB%E5%8D%95%E8%BD%A6/","excerpt":"​ 要说目前最火爆的互联网现象，当属共享单车。这里所谓的共享，本质上指的是需求共享。就骑车的需求，从一个地方骑到另一个地方，就是用户触点（产品投放）、产品操作（骑行过程）、付费模式（支付）的流程，从个体上来讲，这个流程是单向的。但在“共享”的模式下，扫码骑走，停车即走，把不同的人，在不同的时间和地点，相同的骑行需求，通过产品操作节点，形成需求闭环，停车点同时又是骑行出发点，这就是需求共享。","text":"​ 要说目前最火爆的互联网现象，当属共享单车。这里所谓的共享，本质上指的是需求共享。就骑车的需求，从一个地方骑到另一个地方，就是用户触点（产品投放）、产品操作（骑行过程）、付费模式（支付）的流程，从个体上来讲，这个流程是单向的。但在“共享”的模式下，扫码骑走，停车即走，把不同的人，在不同的时间和地点，相同的骑行需求，通过产品操作节点，形成需求闭环，停车点同时又是骑行出发点，这就是需求共享。 共享单车是指企业与政府合作，在地铁、学校、公交站点、居民区、商业区、公共服务区等提供自行车单车共享服务，是共享经济的一种新形态。 ​ 2016年底以来，国内共享单车突然就火爆了起来，而在街头，仿佛一夜之间，共享单车已经到了“泛滥”的地步，各大城市路边排满各种颜色的共享单车。 场景分析​ 我们站在用户角度，无非就是找车，然后骑车，交钱。 在“寻车-用车-骑车-还车”的场景闭环中，需要考虑的问题有很多，列举以下若干种： 什么样的寻车方式更符合大众的日常行为？ 用户与单车之间如何建立一一对应的联系？ 使用何种开锁构件实现远程开锁和上锁？ 计费方式及费用节点、价格、操作流程分别采取什么方案？ 如何对车辆进行远程管理？ 如何防止逃费、盗窃、破坏等衍生问题？ 场景分析的过程，就是解决以上若干问题的过程，针对这些问题，分别提出不同的业务流程和技术方案。 业务逻辑分析以摩拜单车为例，用户-管理平台-单车 之间的关系如下图: 技术实现方案​ 现在共享单车最火的要数*摩拜单车和OFO小黄车*了，摩拜采用智能锁而ofo采用的是机械锁。 1 机械锁​ 原理：机械锁的原理很简单，只需要打开软件，输入对应的车牌号就可以了，其实就是后台查询数据库，判断单车是否处于正常状态，返回给用户开锁密码，用户拿着开锁密码开锁。 2 智能锁​ 原理：对于单车的远程开锁机制，采用远程通信控制机械构件的电磁运动来实现。远程通信可采用传统的SIM卡通信的方式。 一、手机扫描自行车，获得自行车唯一的ID标志，手机接着会像服务器提交一个请求（提交信息里包含：用户信息，请求动作，车辆ID）；二、服务器收到用户开锁请求，此时会根据请求信息，接着向指定ID的自行车发出开锁指令;三、自行车收到服务器请求，会执行相应的开锁动作。 智能锁是耗费电能的，所以摩拜单车车篮中装有太阳能电池板，减少人力物力维护的成本、简单、高效。 ​ 这是一个典型的大容量互联网O2O场景，连结用户、车辆，管理平台进行实时处理效率要求非常高，需制定可靠、高效的网络方案。根据业务流程，我们梳理出网络节点的职能，并从成本考虑使用最优方案： ​ 明确流程，界面，那么接下来的任务就是通过用户语言去实现产品流程了，即界面设计与开发实现，这里我们就不阐述了。 一点感想​ 从2016年到现在已有近半年时间，共享单车的竞争也愈演愈烈，近几天，共享单车从免费到红包“撒钱” 导致竞争升级，共享单车方便了我们的出行，但是带来的问题也很多，政府也在不断的规范使用。现在都在处于资本投入和烧钱大战中，希望共享单车一直存活下去，同时希望大家能合理、合法使用。 之前有听说过摩拜的扫一扫可以远程使用，假如我需要车又没有注册，我可以拍照给有车的朋友，让他们帮我远程扫就可以开启，亲测：不行！还是自己乖乖注册一个吧。","categories":[{"name":"杂谈","slug":"杂谈","permalink":"https://mx-go.github.io/categories/%E6%9D%82%E8%B0%88/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://mx-go.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"Markdown语法指南","slug":"Markdown语法","date":"2017-03-21T14:51:10.000Z","updated":"2021-05-05T03:27:35.488Z","comments":true,"path":"Markdown语法/","link":"","permalink":"https://mx-go.github.io/Markdown%E8%AF%AD%E6%B3%95/","excerpt":"花了一段时间把自己的个人博客搭建好了，但是博客必须是要用Markdown书写，所以查了一下Markdown编辑器的语法，在这里做个记录。","text":"花了一段时间把自己的个人博客搭建好了，但是博客必须是要用Markdown书写，所以查了一下Markdown编辑器的语法，在这里做个记录。 Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。Markdown的语法简洁明了、学习容易，而且功能比纯文本更强，因此有很多人用它写博客。世界上最流行的博客平台WordPress和大型CMS如Joomla、Drupal都能很好的支持Markdown。完全采用Markdown编辑器的博客平台有Ghost和Typecho。 基本技巧1 代码如果你只想高亮语句中的某个函数名或关键字，可以使用 `function_name()` 实现 通常编辑器根据代码片段适配合适的高亮方法，但你也可以用 ``` 包裹一段代码，并指定一种语言 12345​```javascript$(document).ready(function () &#123; alert(&#x27;hello world&#x27;);&#125;);​``` 支持的语言：actionscript, apache, bash, clojure, cmake, coffeescript, cpp, cs, css, d, delphi, django, erlang, go, haskell, html, http, ini, java, javascript, json, lisp, lua, markdown, matlab, nginx, objectivec, perl, php, python, r, ruby, scala, smalltalk, sql, tex, vbscript, xml 也可以使用 4 空格缩进，再贴上代码，实现相同的的效果 123 def g(x): yield from range(x, 0, -1) yield from range(x) 2 标题文章内容较多时，可以用标题分段： 12345678标题1======标题2-----## 大标题 ##### 小标题 ### 3 粗斜体123*斜体文本* _斜体文本_**粗体文本** __粗体文本__***粗斜体文本*** ___粗斜体文本___ 4 链接4.1 常用链接方法 12文字链接 ![链接名称](http://链接网址)网址链接 &lt;http://链接网址&gt; 4.2 高级链接技巧 123456这个链接用 1 作为网址变量 [Google][1].这个链接用 yahoo 作为网址变量 [Yahoo!][yahoo].然后在文档的结尾为变量赋值（网址） [1]: http://www.google.com/ [yahoo]: http://www.yahoo.com/ 5 列表5.1 普通无序列表 123- 列表文本前使用 [减号+空格]+ 列表文本前使用 [加号+空格]* 列表文本前使用 [星号+空格] 5.2 普通有序列表 1231. 列表前使用 [数字+空格]2. 我们会自动帮你添加数字7. 不用担心数字不对，显示的时候我们会自动把这行的 7 纠正为 3 5.3 列表嵌套 12345678910111213141516171. 列出所有元素： - 无序列表元素 A 1. 元素 A 的有序子列表 - 前面加四个空格2. 列表里的多段换行： 前面必须加四个空格， 这样换行，整体的格式不会乱3. 列表里引用： &gt; 前面空一行 &gt; 仍然需要在 &gt; 前面加四个空格4. 列表里代码段：前面四个空格，之后按代码语法 ``` 书写​``` 或者直接空八个，引入代码块 6 引用6.1 普通引用 12&gt; 引用文本前使用 [大于号+空格]&gt; 折行可以不加，新起一行都要加上哦 6.2 引用里嵌套引用 123&gt; 最外层引用&gt; &gt; 多一个 &gt; 嵌套一层引用&gt; &gt; &gt; 可以嵌套很多层 6.3 引用里嵌套列表 123&gt; - 这是引用里嵌套的一个列表&gt; - 还可以有子列表&gt; * 子列表需要从 - 之后延后四个空格开始 6.4 引用里嵌套代码块 12345&gt; 同样的，在前面加四个空格形成代码块&gt; &gt; &gt; 或者使用 ``` 形成代码块&gt; `` 7 图片7.1 跟链接的方法区别在于前面加了个感叹号 !，这样是不是觉得好记多了呢？ 1![图片名称](http://图片网址) 7.2 当然，你也可以像网址那样对图片网址使用变量 1234这个链接用 1 作为网址变量 [Google][1].然后在文档的结尾位变量赋值（网址） [1]: http://www.google.com/logo.png 也可以使用 HTML 的图片语法来自定义图片的宽高大小 1&lt;img src=&quot;htt://example.com/sample.png&quot; width=&quot;400&quot; height=&quot;100&quot;&gt; 8 换行如果另起一行，只需在当前行结尾加 2 个空格 12在当前行的结尾加 2 个空格 这行就会新起一行 如果是要起一个新段落，只需要空出一行即可。 9 分隔符如果你有写分割线的习惯，可以新起一行输入三个减号-。当前后都有段落时，请空出一行： 12345前面的段落---后面的段落 高级技巧1 行内 HTML 元素目前只支持部分段内 HTML 元素效果，包括 ，如 键位显示 1使用 &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;Alt&lt;/kbd&gt;+&lt;kbd&gt;Del&lt;/kbd&gt; 重启电脑 代码块 1使用 &lt;pre&gt;&lt;/pre&gt; 元素同样可以形成代码块 粗斜体 1&lt;b&gt; Markdown 在此处同样适用，如 *加粗* &lt;/b&gt; 2 符号转义如果你的描述中需要用到 markdown 的符号，比如 _ # * 等，但又不想它被转义，这时候可以在这些符号前加反斜杠，如 \\_ \\#``\\* 进行避免。 12\\_不想这里的文本变斜体\\_\\*\\*不想这里的文本被加粗\\*\\* 3 扩展支持** jsfiddle、gist、runjs、优酷视频**，直接填写 url，在其之后会自动添加预览点击会展开相关内容。 1234http://&#123;url_of_the_fiddle&#125;/embedded/[&#123;tabs&#125;/[&#123;style&#125;]]/https://gist.github.com/&#123;gist_id&#125;http://runjs.cn/detail/&#123;id&#125;http://v.youku.com/v_show/id_&#123;video_id&#125;.html 4 公式当你需要在编辑器中插入数学公式时，可以使用两个美元符 $$ 包裹 TeX 或 LaTeX 格式的数学公式来实现。提交后，问答和文章页会根据需要加载 Mathjax 对数学公式进行渲染。如： 12345$$ x = &#123;-b \\pm \\sqrt&#123;b^2-4ac&#125; \\over 2a&#125;. $$$$x \\href&#123;why-equal.html&#125;&#123;=&#125; y^2 + 1$$ 同时也支持 HTML 属性，如： 12345$$ (x+1)^2 = \\class&#123;hidden&#125;&#123;(x+1)(x+1)&#125; $$$$(x+1)^2 = \\cssId&#123;step1&#125;&#123;\\style&#123;visibility:hidden&#125;&#123;(x+1)(x+1)&#125;&#125;$$ 总结markdown语法写多了自然就会了，网上有很多markdown语法编辑器，比如有道云、马克飞象、Typora等。我目前使用的是Typora编辑器，使用起来比其他的更简单、舒适，方便。","categories":[],"tags":[{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"}]},{"title":"博客建成第一天","slug":"博客建成第一天","date":"2017-03-07T05:30:26.000Z","updated":"2021-05-05T03:15:25.760Z","comments":true,"path":"博客建成第一天/","link":"","permalink":"https://mx-go.github.io/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E6%88%90%E7%AC%AC%E4%B8%80%E5%A4%A9/","excerpt":"","text":"经过几天的努力，自己的博客终于搭建起来了，打心里很开心。 这不是贴吧，不是豆瓣，不是CSDN，这是我自己在互联网上的一小点领地。 从开始博客基本样式，到域名，自己一步一步摸索搭建起来的，我相信自己可以做的更好，加油!","categories":[{"name":"生活","slug":"生活","permalink":"https://mx-go.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://mx-go.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"About","slug":"about","date":"2017-03-07T01:00:07.000Z","updated":"2021-05-05T15:01:56.098Z","comments":true,"path":"about/","link":"","permalink":"https://mx-go.github.io/about/","excerpt":"","text":"​ ​ 喜欢新鲜的事物，钻研技术，热爱互联网行业🍭。 ​ 做自己喜欢做的事。 ​ 菜鸟程序猿一只，欢迎分享知识。 ​ From 🌈彩虹马","categories":[],"tags":[]}],"categories":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/"},{"name":"设计","slug":"架构/设计","permalink":"https://mx-go.github.io/categories/%E6%9E%B6%E6%9E%84/%E8%AE%BE%E8%AE%A1/"},{"name":"监控","slug":"监控","permalink":"https://mx-go.github.io/categories/%E7%9B%91%E6%8E%A7/"},{"name":"后端","slug":"后端","permalink":"https://mx-go.github.io/categories/%E5%90%8E%E7%AB%AF/"},{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"Linux","slug":"Linux","permalink":"https://mx-go.github.io/categories/Linux/"},{"name":"安装","slug":"Linux/安装","permalink":"https://mx-go.github.io/categories/Linux/%E5%AE%89%E8%A3%85/"},{"name":"踩坑记录","slug":"踩坑记录","permalink":"https://mx-go.github.io/categories/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"},{"name":"中间件","slug":"中间件","permalink":"https://mx-go.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"组件","slug":"组件","permalink":"https://mx-go.github.io/categories/%E7%BB%84%E4%BB%B6/"},{"name":"基础","slug":"Linux/基础","permalink":"https://mx-go.github.io/categories/Linux/%E5%9F%BA%E7%A1%80/"},{"name":"数据库","slug":"数据库","permalink":"https://mx-go.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"方法论","slug":"方法论","permalink":"https://mx-go.github.io/categories/%E6%96%B9%E6%B3%95%E8%AE%BA/"},{"name":"杂谈","slug":"杂谈","permalink":"https://mx-go.github.io/categories/%E6%9D%82%E8%B0%88/"},{"name":"前端","slug":"前端","permalink":"https://mx-go.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"生活","slug":"生活","permalink":"https://mx-go.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"架构","slug":"架构","permalink":"https://mx-go.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"java","slug":"java","permalink":"https://mx-go.github.io/tags/java/"},{"name":"docker","slug":"docker","permalink":"https://mx-go.github.io/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"https://mx-go.github.io/tags/nginx/"},{"name":"bug","slug":"bug","permalink":"https://mx-go.github.io/tags/bug/"},{"name":"spring","slug":"spring","permalink":"https://mx-go.github.io/tags/spring/"},{"name":"tips","slug":"tips","permalink":"https://mx-go.github.io/tags/tips/"},{"name":"grafana","slug":"grafana","permalink":"https://mx-go.github.io/tags/grafana/"},{"name":"工具","slug":"工具","permalink":"https://mx-go.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"cache","slug":"cache","permalink":"https://mx-go.github.io/tags/cache/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://mx-go.github.io/tags/RocketMQ/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://mx-go.github.io/tags/MongoDB/"},{"name":"redis","slug":"redis","permalink":"https://mx-go.github.io/tags/redis/"},{"name":"mysql","slug":"mysql","permalink":"https://mx-go.github.io/tags/mysql/"},{"name":"pg","slug":"pg","permalink":"https://mx-go.github.io/tags/pg/"},{"name":"tools","slug":"tools","permalink":"https://mx-go.github.io/tags/tools/"},{"name":"mybatis","slug":"mybatis","permalink":"https://mx-go.github.io/tags/mybatis/"},{"name":"随笔","slug":"随笔","permalink":"https://mx-go.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"sql","slug":"sql","permalink":"https://mx-go.github.io/tags/sql/"},{"name":"tomcat","slug":"tomcat","permalink":"https://mx-go.github.io/tags/tomcat/"},{"name":"jvm","slug":"jvm","permalink":"https://mx-go.github.io/tags/jvm/"},{"name":"移动端","slug":"移动端","permalink":"https://mx-go.github.io/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF/"}]}